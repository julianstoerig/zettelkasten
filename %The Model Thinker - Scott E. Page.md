[[Fachgebiet]] [[2021-01-16]]

---

## Metadaten

Autor(-en): [[Scott E. Page]]

Veröffentlichungsjahr: [[2018]]

Bibliographische Referenz (APA): (Zotero Referenz einfügen)

Allgemeines Thema: [[Mathematische Modelle]] [[Denken]]

Hypothese: [[Mathematischer Modelle sind gute Entscheidungshilfen in Alltagssituationen]]

## Methodik



## Ergebnisse



## Zusammenfassung der wichtigsten Punkte




## Kontext (wie das Buch im Verhältnis zu anderen Arbeiten im Feld steht; wie es zu Schlüsselproblemen und Ergebnissen des Feldes durch andere und dich selbst steht)




## Signifikanz (in Relation zum Feld und eigener Arbeit)




## Wichtige Grafiken und Tabellen



## Referenzen im Buch (Die offensichtlich mit eigener Arbeit in Verbindung stehen und die oft in anderen Buchs zum Thema zitiert werden)



## Kommentare

Published by Basic Books, an imprint of Perseus Books, LLC, a subsidiary of Hachette Book Group, Inc. The Basic Books name and logo is a trademark of the Hachette Book Group. 

The Hachette Speakers Bureau provides a wide range of authors for speaking events. To find out more, go to [http://www.hachettespeakersbureau.com](http://www.hachettespeakersbureau.com) or call (866) 376-6591. 

The publisher is not responsible for websites (or their content) that are not owned by the publisher. 

---

Library of Congress Control Number: 2018942802 

ISBNs: 978-0-465-09462-2 (hardcover); 978-0-465-09463-9 (ebook) 

E3-20181019-JV-PC 

---

# CONTENTS 

 Cover Title Page Copyright Dedication Epigraph 

 Prologue 1 The Many-Model Thinker 2 Why Model? 3 The Science of Many Models 4 Modeling Human Actors 5 Normal Distributions: The Bell Curve 6 Power-Law Distributions: Long Tails 7 Linear Models 8 Concavity and Convexity 9 Models of Value and Power 

10 Network Models 

11 Broadcast, Diffusion, and Contagion 

12 Entropy: Modeling Uncertainty 

13 Random Walks 

---

14 Path Dependence 

15 Local Interaction Models 

16 Lyapunov Functions and Equilibria 

17 Markov Models 

18 Systems Dynamics Models 

19 Threshold Models with Feedbacks 

20 Spatial and Hedonic Choice 

21 Game Theory Models Times Three 

22 Models of Cooperation 

23 Collective Action Problems 

24 Mechanism Design 

25 Signaling Models 

26 Learning Models 

27 Multi-Armed Bandit Problems 

28 Rugged-Landscape Models 

29 Opioids, Inequality, and Humility 

 About the Author Notes Bibliography Index 

---

### To Michael D. Cohen 

### (1945–2013) 

---

It can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience. 

 —ALBERT EINSTEIN 

---

# Prologue 

_To me success means effectiveness in the world, that I am able to carry my ideas and values into the world—that I am able to change it in positive ways._ 

 —Maxine Hong Kingston 

This book began as the result of a chance meeting with Michael Cohen in 2005 near the flower garden in the mall adjacent to the University of Michigan’s West Hall. Michael, a scholar known for his generosity, made a comment that altered my teaching career. With a twinkle in his eyes, Michael said, “Scottie, I once taught a course called Introduction to Modeling for Social Scientists, based on a book written by Charles Lave and James March. You should resurrect the course. It needs you.” It needed me? I returned to my office a little confused, so I chased down an old course syllabus. I discovered that Michael had misled me. The course did not need me. I needed it. I had been wanting to develop a course that would introduce students to the core ideas of complex systems—networks, diversity, learning, large events, path dependence, tipping points—that would be relevant to their daily lives and future careers. By teaching modeling, I could make students better thinkers while introducing them to complexity. I could teach them tools that would improve their abilities to reason, explain, predict, design, communicate, act, and explore The course’s motivating idea would be that we must confront the complexity of the modern world with multiple models. At semester’s end, rather than see the world from a particular angle, students would see the world through many lenses. They would be standing 

---

in houses with many windows, able to look in multiple directions. My students would be better prepared for the complex challenges before them—improving education, reducing poverty, creating sustainable growth, finding meaningful work in an age of artificial intelligence, managing resources, and designing robust financial, economic, and political systems. The next fall, I resurrected the course. I contemplated rebranding it as Thirty-Two Models That Will Turn You into a Genius, but the culture at Michigan frowns on hyperbole, so I stuck with Michael’s title: An Introduction to Modeling. Lave and March’s book proved to be a brilliant introduction. However, modeling had made huge advances in the intervening decades. I needed an updated version that included models of long-tailed distributions, networks, rugged landscapes, and random walks. I needed a book that discussed complexity. So I began to write. For two years, the ground proved rocky. My plow moved at a slow place. One spring day, I again ran into Michael, this time in the arch-way underneath West Hall. I had been questioning the course, which was now drawing twenty students. Were models too abstract for undergraduates? Should I teach a different course on a specific issue or policy domain? Michael offered up a smile, noting that any endeavor worth pursuing merited questioning. As we parted, Michael commented on the importance and value of helping people think clearly. He told me not to give up, that he took joy in my challenges. In the fall of 2012, the ground under the course shifted. Vice Provost Martha Pollack asked me to teach an online version—what is now called a MOOC. With a tablet computer, a $29 camera, and a $90 microphone, Model Thinking was born. With assistance from too many people at Michigan, Coursera, and Stanford University to thank properly (a quick shout-out to Tom Hickey, who did yeoman’s work), I reorganized my lectures into a form suitable for an online course, dividing each subject into modules and removing all copyrighted material. With my dog Bounder as an audience, I taped and retaped lectures. The first offering of Model Thinking drew 60,000 students. That 

---

number now approaches a million. The popularity of the online course led me to abandon the book. I thought the project unnecessary, but, over the next two years, my email inbox began to fill with requests for a book to complement the online lectures. Then Michael Cohen lost his battle with cancer, and I felt that I needed to finish the book. I reopened the manuscript folder. Writing a book requires large blocks of time and spaces that allow for clear thought. The poet Wallace Stevens wrote, “Perhaps the truth depends on a walk around the lake.” I relied on a close analog: mind-clearing swims across Winans Lake, where my family spends our summers. Throughout the writing process, the continuous life I share with the love of my life, Jenna Bednar, our sons, Orrie and Cooper, and our enormous dogs, Bounder, Oda, and Hildy, has brought laughter, comfort, and opportunities—among them Orrie having one week to correct the penultimate draft’s mathematical errors and Jenna having two weeks to identify instances of unclear writing, logical flaws, and muddled thinking. As has been true of most of my written work, this manuscript might be best described as an original draft by Scott Page with substantial revision by Jenna Bednar. During the seven-year period of writing this book, my children have transitioned from pre-teens to young adults. Orrie is now off to college. Cooper follows next year. In the interval between sketching the initial outline and submitting the final version, my family has consumed copious amounts of bibimbap, pasta carbonara, and oatmeal chocolate chip cookies, taken the saws and loppers to scores of fallen branches and limbs, repaired dozens of breaks in the backyard fence, embarked on numerous failed initiatives to reduce the entropy in the basement and garage, and wished and hoped for the ice on the lake to be suitable for skating. We have also had to accept loss. Midway through the project, my mother, Marilyn Tamboer Page, died from a sudden heart attack while enjoying the bliss of her routine daily walk with her dog. Not a day goes by when I do not reflect on the love she showered on her family and the support she gave to others. The book before you is as complete as it can be at this moment in 

---

time. Doubtless, new models will be created, and old models will find new uses creating gaps in this current offering. As I humbly send the manuscript out into the world, I feel that my efforts will have been repaid if you, the reader, find the models and ideas within to be useful and generative, and that you are able to carry them out into the world and change it in positive ways. If one day, when sitting in some professor’s or graduate student’s office, preferably at a college or university in my beloved Midwest, I scan the bookshelves and find this book leaning, as it has during its writing, on a well-worn copy of Lave and March, then my efforts will have been all the sweeter. 

---

# 1. The Many-Model Thinker 

_To become wise you’ve got to have models in your head. And you’ve got to array your experience—both vicarious and direct—on this latticework of models._ 

 —Charlie Munger 

This is a book about models. It describes dozens of models in straightforward language and explains how to apply them. Models are formal structures represented in mathematics and diagrams that help us to understand the world. Mastery of models improves your ability to reason, explain, design, communicate, act, predict, and explore. This book promotes a _many-model thinking_ approach: the application of ensembles of models to make sense of complex phenomena. The core idea is that many-model thinking produces wisdom through a diverse ensemble of logical frames. The various models accentuate different causal forces. Their insights and implications overlap and interweave. By engaging many models as frames, we develop nuanced, deep understandings. The book includes formal arguments to make the case for multiple models along with myriad real-world examples. The book has a pragmatic focus. Many-model thinking has tremendous practical value. Practice it, and you will better understand complex phenomena. You will reason better. You exhibit fewer gaps in your reasoning and make more robust decisions in your career, community activities, and personal life. You may even become wise. Twenty-five years ago, a book of models would have been 

---

intended for professors and graduate students studying business, policy, and the social sciences along with financial analysts, actuaries, and members of the intelligence community. These were the people who applied models and, not coincidentally, they were also the people most engaged with large data sets. Today, a book of models has a much larger audience: the vast universe of knowledge workers, who, owing to the rise of big data, now find working with models a part of their daily lives. Organizing and interpreting data with models has become a core competency for business strategists, urban planners, economists, medical professionals, engineers, actuaries, and environmental scientists among others. Anyone who analyzes data, formulates business strategies, allocates resources, designs products and protocols, or makes hiring decisions encounters models. It follows that mastering the material in this book—particularly the models covering innovation, forecasting, data binning, learning, and market entry timing—will be of practical value to many. Thinking with models will do more than improve your performance at work. It will make you a better citizen and a more thoughtful contributor to civic life. It will make you more adept at evaluating economic and political events. You will be able to identify flaws in your logic and in that of others. You will learn to identify when you are allowing ideology to supplant reason and have richer, more layered insights into the implications of policy initiatives, whether they be proposed greenbelts or mandatory drug tests. These benefits will accrue from an engagement with a variety of models—not hundreds, but a few dozen. The models in this book offer a good starting collection. They come from multiple disciplines and include the Prisoners’ Dilemma, the Race to the Bottom, and the SIR model of disease transmission. All of these models share a common form: they assume a set of entities—often people or organizations—and describe how they interact. The models we cover fall into three classes: simplifications of the world, mathematical analogies, and exploratory, artificial constructs. In whatever form, a model must be tractable. It must be simple enough that within it we can apply logic. For example, we cover a 

---

model of communicable diseases that consists of infected, susceptible, and recovered people that assumes a rate of contagion. Using the model we can derive a contagion threshold, a tipping point, above which the disease spreads. We can also determine the proportion of people we must vaccinate to stop the disease from spreading. As powerful as single models can be, a collection of models accomplishes even more. With many models, we avoid the narrowness inherent in each individual model. A many-models approach illuminates each component model’s blind spots. Policy choices made based on single models may ignore important features of the world such as income disparity, identity diversity, and 

interdependencies with other systems.^1 With many models, we build logical understandings of multiple processes. We see how causal processes overlap and interact. We create the possibility of making sense of the complexity that characterizes our economic, political, and social worlds. And, we do so without abandoning rigor—model thinking ensures logical coherence. That logic can be then be grounded in evidence by taking models to data to test, refine, and improve them. In sum, when our thinking is informed by diverse logically consistent, empirically validated frames, we are more likely to make wise choices. 

---

### Models in the Age of Data 

The appearance of a book on models may seem out of place in the era of big data. Today, data exists in unprecedented dimensionality and granularity. Customer purchase data, which used to arrive in monthly aggregates on printed paper, now streams instantaneously with geospatial, temporal, and consumer tags. Student academic performance data now includes scores on every homework, paper, quiz, and exam, as opposed to semester-end summary grades. In the past, a farmer might mention dry ground at a monthly Grange meeting. Now, tractors transmit instantaneous data on soil conditions and moisture levels in square-foot increments. Investment firms track dozens of ratios and trends for thousands of stocks and use naturallanguage processing tools to parse documents. Doctors can pull up page upon page of individual patient records that can include relevant genetic markers. A mere twenty-five years ago, most of us had access to little more than a few bookshelves’ worth of knowledge. Perhaps your place of work had a small reference library, or at home you had a collection of encyclopedias and a few dozen reference books. Academics and government and private-sector researchers had access to large library collections, but even they had to physically visit the material. As late as the turn of the millennium, academics could be found shuttling back and forth between card catalog rooms, microfiche collections, library stacks, and special collections in search of information. That has all changed. Content that had been paper-bound for centuries now flows in tiny packets through the air. So too does the information about the here and now. News that arrived on our doorsteps on newsprint once a day now flows in a continuous digital stream into our personal devices. Stock prices, sports scores, and news of political events and cultural happenings can all be accessed with a swipe or query. As impressive as the data may be, it is no panacea. We now 

---

know what has happened and is happening, but, owing to the complexity of the modern world, we may be less capable of understanding why it happened. Empirical findings may be misleading. Data on piece-rate work often shows that the more people are paid per unit of output, the less they produce. A model in which pay depends on work conditions can explain those data. If conditions are poor so that producing output is difficult, per unit pay may be high. If conditions are good, per unit pay may be low. Thus, higher pay does not lead to less productivity. Instead, more difficult 

work conditions require higher per unit pay.^2 In addition, most of our social data—that is, data about our economic, social, and political phenomena—documents only moments or intervals in time. It rarely tells us universal truths. Our economic, social, and political worlds are not stationary. Boys may outscore girls on standardized tests in one decade and girls may outscore boys the next. The reasons people vote today may differ from the reasons they vote in coming decades. We need models to make sense of the fire-hose-like streams of data that cross our computer screens. Thus, it is because we have so much data that this might also be called the age of many models. Look across the academy, government, the business world, and the nonprofit sector, and you struggle to find a domain of inquiry or decision not informed by models. Consulting giants McKinsey and Deloitte build models to formulate business strategies. Financial firms such as BlackRock and JPMorgan Chase apply models to select investments. Actuaries at State Farm and Allstate use models to calibrate risk when pricing insurance policies. The people team at Google builds predictive analytic models to evaluate its more than three million job applicants. College and university admissions officers construct predictive models to select from among tens of thousands of applicants. The Office of Management and Budget constructs economic models to predict the effects of tax policies. Warner Brothers applies data analytics to create models of audience responses. Amazon develops machine learning models to make product 

---

recommendations. Researchers funded by the National Institutes of Health build mathematical models of human genomics to search for and evaluate potential cures for cancer. The Gates Foundation uses epidemiological models to design vaccination strategies. Even sports teams use models to evaluate draft prospects and trade opportunities and to formulate within-game strategies. By relying on models to select players and strategies, the Chicago Cubs won a World Series championship after more than a century of failures. To people who use models, the rise of model thinking has an even simpler explanation: _models make us smarter_. Without models, people suffer from a laundry list of cognitive shortcomings: we overweight recent events, we assign probabilities based on reasonableness, and we ignore base rates. Without models, we have limited capacity to include data. With models, we clarify assumptions and think logically. And, we can leverage big data to fit, calibrate, and test causal and correlative claims. With models, we think better. In head-to-head competitions between models and 

people, models win.^3 

---

### Why We Need Many Models 

In this book we advocate using not just one model in a given situation but many models. The logic behind the many-model approach builds on the age-old idea that we achieve wisdom through a multiplicity of lenses. This idea traces back to Aristotle, who wrote of the value of combining the excellences of many. A diversity of perspectives was also a motivation for the great-books movement, which collected 102 important transferable ideas in _The Great Ideas: A Syntopicon of Great Books of the Western World_. The approach finds a modern voice in the work of Maxine Hong Kingston, who wrote in _The Woman Warrior_ , “I learned to make my mind large, as the universe is large, so that there is room for paradoxes.” It is also the basis for pragmatic actions in the world of business and policy. Recent books argue that if we want to understand of international relations, we should not model the world exclusively as a group of self-interested nations with well-defined objectives, or only as an evolving nexus of multinational corporations and intergovernmental organizations. We should do both.^4 As commonsensical as the many-model approach may seem, keep in mind that it runs counter to how we teach models and the practice of modeling. The traditional approach—the one taught in high school—relies on a one-to-one logic: one problem requires one model. For example: now we apply Newton’s first law; now we apply the second; now the third. Or: here we use the replicator equation to show the size of the rabbit population in the next period. In this traditional approach, the objective is to (a) identify the one proper model and (b) apply it correctly. Many-model thinking challenges that approach. It advocates trying many models. Had you used manymodel thinking in ninth grade, you might have been held back. Use it now, and you will move forward. Academic papers, for the most part, follow the one-to-one approach as well, even though they use those single models to explain complex phenomena: Trump voters in the 2016 election were 

---

those who had been left behind economically. Or: the quality of a child’s second-grade teacher determines how economically 

successful that child will be as an adult.^5 A stream of best-selling nonfiction titles present cures for our ills based on single-model thinking: Educational success depends on grit. Inequality results from concentrations of capital. Our nation’s poor health is due to sugar consumption. Each of these models may be true, but none is comprehensive. To confront the complexity of these challenges, to create a world of broader educational achievement, will require lattices of models. By learning the models in this book, you can begin to build your own lattice. The models originate from a broad spectrum of disciplines, addressing phenomena as varied as the causes of income inequality, the distribution of power, the spread of diseases and fads, the conditions that precede social uprisings, the evolution of cooperation, the emergence of order in cities, and the structure of the internet. The models vary in their assumptions and their structure. Some describe small numbers of rational, self-interested actors. Others describe large populations of rule-following altruists. Some describe equilibrium processes. Others produce path dependence and complexity. The models also differ in their uses. Some help predict and explain. Others guide actions, inform designs, or facilitate communication. Still others create artificial worlds for our minds to explore. The models share three common characteristics: First, they simplify, stripping away unnecessary details, abstracting from reality, or creating anew from whole cloth. Second, they formalize, making precise definitions. Models use mathematics, not words. A model might represent beliefs as probability distributions over states of the world or preferences as rankings of alternatives. By simplifying and making precise, they create tractable spaces within which we can work through logic, generate hypotheses, design solutions, and fit data. Models create structures within which we can think logically. As Wittgenstein wrote in his _Tractatus Logico-Philosophicus_ , “Logic takes care of itself; all we have to do is to look and see how it does 

---

it.” The logic will help to explain, predict, communicate, and design. But the logic comes at a cost, which leads to their third 

characteristic: _all models are wrong_ , as George Box noted.^6 That is true of all models; even the sublime creations of Newton that we refer to as laws hold only at certain scales. Models are wrong because they simplify. They omit details. By considering many models, we can overcome the narrowing of rigor by crisscrossing the landscape of the possible. To rely on a single model is hubris. It invites disaster. To believe that a single equation can explain or predict complex real-world phenomena is to fall prey to the charisma of clean, spare mathematical forms. We should not expect any one model to produce exact numerical predictions of sea levels in 10,000 years or of unemployment rates in 10 months. We need many models to make sense of complex systems. Complex systems like politics, the economy, international relations, or the brain exhibit ever-changing emergent structures and patterns that lie between ordered and random. By definition, complex phenomena are difficult to explain, evolve, or predict.^7 Thus, we confront a disconnect. On the one hand, we need models to think coherently. On the other hand, any single model with a few moving parts cannot make sense of high-dimensional, complex phenomena such as patterns in international trade policy, trends in the consumer products industry, or adaptive responses within the brain. No Newton can write a three-variable equation that explains monthly employment, election outcomes, or reductions in crime. If we hope to understand the spread of diseases, variation in educational performance, the variety of flora and fauna, the effect of artificial intelligence on job markets, the impact of humans on the earth’s climate, or the likelihood of social uprisings, we must come at them with machine learning models, systems dynamics models, game theory models, and agent-based models. 

---

### The Wisdom Hierarchy 

To sketch the argument for many-model thinking, we begin with a query from poet and dramatist T. S. Eliot: “Where is the wisdom we have lost in knowledge? Where is the knowledge we have lost in information?” To that we might add, where is the information we have lost in all this data? Eliot’s questioning can be formalized as the _wisdom hierarchy_. At the bottom of the hierarchy lie _data_ : raw, uncoded events, experiences, and phenomena. Births, deaths, market transactions, votes, music downloads, rainfall, soccer matches, and speciation events. Data can be long strings of zeros and ones, time stamps, and linkages between pages. Data lack meaning, organization, or structure. _Information_ names and partitions data into categories. Examples clarify the distinction between data and information. Rain falling on your head is data. Total rainfall for the month of July in Burlington, Vermont, and Lake Ontario’s water level are information. The bright red peppers and yellow corn on farmers’ stands surrounding the capitol in Madison, Wisconsin, on market Saturdays are data. The farmers’ total sales are information. 

Figure 1.1: How Models Transform Data into Wisdom We live in an age of abundant information. A century and a half ago, knowing information brought great economic and social status. Jane Austen’s Emma asks if Frank Churchill is “a young man of information.” Today she would not care. Churchill, like everyone else, would have a smartphone. The question is whether he could put that information to use. As Fyodor Dostoyevsky writes in _Crime and Punishment_ , “We’ve got facts, they say. But facts aren’t everything; 

---

at least half the battle consists in how one makes use of them!” Plato defined _knowledge_ as justified true belief. More modern definitions refer to it as understandings of correlative, causal, and logical relationships. Knowledge organizes information. Knowledge often takes model form. Economic models of market competition, sociological models of networks, geological models of earthquakes, ecological models of niche formation, and psychological models of learning all embed knowledge. Those models explain and predict. Models of chemical bonds explain why metallic bonds prevent us from putting our hands through steel doors while hydrogen bonds 

yield to our weight when we dive into a lake.^8 Atop the hierarchy lies _wisdom_ , the ability to identify and apply relevant knowledge. Wisdom requires many-model thinking. Sometimes, wisdom consists of selecting the best model, as if drawing from a quiver of arrows. Other times, wisdom can be achieved by averaging models; this is common when making predictions. (We discuss the value of model averaging in the next section.) When taking actions, wise people apply multiple models like a doctor’s set of diagnostic tests. They use models to rule out some actions and privilege others. Wise people and teams construct a dialogue across models, exploring their overlaps and differences. Wisdom can consist of selecting the correct knowledge or model; consider the following physics problem: A small stuffed cheetah falls from an airplane’s hold at 20,000 feet. How much damage will it do upon landing? A student might know a gravity model and a terminal velocity model. The two models give different insights. The gravity model predicts that the stuffed animal would tear through a car’s roof. The terminal velocity model predicts that the toy cheetah’s speed tops out at around 10 mph.^9 Wisdom consists of knowing to apply the terminal velocity model. A person could stand on the ground and catch the soft cheetah in her hands. To quote the evolutionary biologist J. B. S. Haldane, “You can drop a mouse down a thousand-yard mine shaft; and, on arriving at the bottom, it gets a slight shock and walks away, provided that the ground is fairly soft. A rat is killed, a man is broken, a horse splashes.” 

---

In the stuffed-cheetah problem, arriving at the correct solution requires information (the weight of the toy), knowledge (the terminal velocity model), and wisdom (selecting the correct model). Business and policy leaders also rely on information and knowledge to make wise choices. On October 9, 2008, the value of Iceland’s currency, the króna, began a free fall. Eric Ball, then treasurer of software giant Oracle, was faced with a decision. A few weeks prior he had dealt with the domestic repercussions of the home mortgage crisis. Iceland’s situations posed an international concern. Oracle held billions of dollars in overseas assets. Ball considered network contagion models of financial collapse. He also thought of economic models of supply and demand in which the magnitude of a price change correlates with the size of the market shock. In 2008, Iceland had a GDP of $12 billion, or less than six months’ revenues for McDonald’s Corporation. Ball recollected thinking, “Iceland is smaller 

than Fresno. Go back to work.”^10 The key to understanding this event, and many-model thinking generally, lies in recognizing that Ball did not search among many models to find one that supported an action that he had already decided to take. He did not use many models to find one that justified his action. Instead, he evaluated two models as possibly useful and then chose the better one. Ball had the right information (Iceland is small), chose the right model (supply and demand), and made a wise choice. We next show how to create a dialogue among multiple models by reconsidering two historical events: the 2008 global financial market collapse, which reduced total wealth (or what had been thought to be wealth) by trillions of dollars, resulting in a four-year global recession, and the 1961 Cuban missile crisis, which nearly resulted in nuclear war. The 2008 financial collapse has multiple explanations: too much foreign investment, over-leveraged investment banks, lack of oversight in the mortgage approval process, blissful optimism among home-flipping consumers, the complexity of financial instruments, a misunderstanding of risk, and greedy bankers who knew the bubble existed and expected a bailout. Superficial evidence aligns with each 

---

of these accounts: money flowed in from China, loan originators wrote toxic mortgages, investment banks had high leverage ratios, financial instruments were too complex for most to understand, and some banks expected a bailout. With models we can adjudicate between these accounts and check the internal consistency of these accounts: Do they make logical sense? We can also calibrate the models and test the magnitude of the effects. The economist Andrew Lo, exercising many-model thinking, evaluates twenty-one accounts of the crisis. He finds each to be lacking. It does not make sense that investors would contribute to a bubble that they knew would lead to a global crisis. Hence, the extent of the bubble must have been a surprise to many. Financial firms may well have assumed the other firms had done due diligence when in fact they had not. Second, what were, in retrospect, clearly toxic (low-quality) bundles of mortgages found buyers. Had global collapse been a foregone conclusion, the buyers would not have existed. And while leverage ratios had increased since 2002, they were not much higher than they had been in 1998. And as for the notion that the government would bail out the banks, Lehman Brothers collapsed on September 15, 2008; with over $600 billion in holdings, it was the largest bankruptcy in US history. The government did not intervene. Lo finds that each account contains a logical gap. The data, such as it is, privileges no single explanation. As Lo summarizes: “We should strive at the outset to entertain as many interpretations of the same set of objective facts as we can, and hope that a more nuanced and internally consistent understanding of the crisis emerges in the fullness of time.” He goes on to say, “Only by collecting a diverse and often mutually contradictory set of narratives can we eventually develop a more complete understanding of the 

crisis.” No single model suffices.^11 In _Essence of Decision_ , Graham Allison undertakes a manymodel approach to explain the Cuban missile crisis. On April 17, 1961, a CIA-trained paramilitary group landed on the shores of Cuba in a failed attempt to overthrow Fidel Castro’s communist regime, 

---

increasing tensions between the United States and the Soviet Union, Cuba’s ally. In response, Soviet premier Nikita Khrushchev moved short-range nuclear missiles to Cuba. President John F. Kennedy responded by blockading Cuba. The Soviet Union backed down, and the crisis ended. Allison interprets events with three models. He applies a rationalactor model to show that Kennedy had three possible actions: start a nuclear war, invade Cuba, or impose a blockade. He chose the blockade. The rational-actor model assumes that Kennedy draws a game tree with each action followed by the possible responses by the Soviets. Kennedy then thinks through the Soviets’ optimal response. If, for example, Kennedy launched a nuclear attack, the Soviets would strike back, resulting in millions dead. If Kennedy imposed a blockade, he would starve the Cubans. The Soviet Union could either back down or launch missiles. Given that choice, the Soviet Union should back down. The model reveals the central strategic logic at play and provides a rationale for Kennedy’s bold choice to blockade Cuba. Like all models, though, it is wrong. It ignores relevant details, allowing it to initially appear a better explanation than it really is. The model neglects to add a stage in which the Soviets put the missiles in Cuba. If the Soviets had been rational, they should have drawn the same tree as Kennedy and realized that they would have to remove the missiles. The rational-actor model also fails to explain why the Soviets did not hide the missiles. Allison applies an organizational process model to explain these inconsistencies. A lack of organizational capacity explains the Soviets’ failure to hide the missiles. The same model can explain Kennedy’s choice to blockade. At the time, the United States Air Force lacked the capacity to wipe out the missiles in a single strike. If even a single missile remained, it could kill millions of Americans. Allison deftly combines the two models. An insight from the organizational model changes the payoffs in the rational-choice model. Allison adds a governmental process model. The other two models reduce countries to their leaders: Kennedy acts for the 

---

United States and Khrushchev for the Soviet Union. The government process model recognizes that Kennedy had to contend with Congress and that Khrushchev needed to maintain a political base of support. Thus, Khrushchev’s placing of the missiles in Cuba signaled strength. Allison’s book shows the power of models alone and in dialogue. Each model clarifies our thinking. The rational-actor model identifies possible actions once the missiles have arrived and allows us to see the implications of those actions. The organizational model draws our attention to the fact that organizations, not individuals, carry out those actions. The governmental process model highlights the political cost of invasion. By evaluating events through all three lenses, we gain a broader and deeper understanding. All models are wrong; many are useful. In both examples, the different models explicate distinct causal forces. Multiple models can also focus on different scales. In an oftrepeated tale, a child claims that the Earth rests on the back of a giant elephant. A scientist asks the child what the elephant stands on, to which the child replies, “A giant turtle.” Anticipating what’s about to come next, the child quickly adds, “Don’t even ask. It’s 

turtles all the way down.”^12 If the world were turtles all the way—if the world were self-similar—then a model of the top level would apply at every level. But the economy, the political world, and society are not turtles all the way down, nor is the brain. At the sub-micron level, the brain is made up of molecules that form synapses, which in turn form neurons. The neurons combine in networks. The networks overlap in elaborate ways that can be studied with brain imaging. These neuronal networks exist on a scale below that of functional systems such as the cerebellum. Given that the brain differs at each level, we need multiple models, and those models differ. The models that characterize the robustness of neuronal networks bear little resemblance to the molecular biology models used to explain brain cell function, which in turn differ from the psychological models used to explain cognitive biases. The success of many-model thinking depends on a degree of 

---

separability. In analyzing the 2008 financial crisis, we rely on separate models of foreign purchases of assets, of the bundling of assets, and of increased leverage ratios. Allison drew implications from the game theoretic model without considering the organizational model. In studying the human body, doctors separate the skeletal, muscular, limbic, and nervous systems. That said, many-model thinking does not require that these distinct models divide the system into independent parts. Confronted with a complex system, we cannot, to paraphrase Plato, carve the world at its joints. We can partially isolate the major causal threads and then explore how they are interwoven. In doing so, we will find that the data produced by our economic, political, and social systems exhibits coherence. Social data is more than sequences of incomprehensible hairballs that might have been spit up by the family cat. 

---

### Summary and Outline of the Book 

To summarize, we live in a time awash in information and data. The same technological advances generating those data shrink time and distance. They make economic, political, and social actors more agile, capable of responding to economic and political events in an instant. They also increase connectedness, and therefore complexity. We face a technologically induced paradox: we know more about the world, but that world is more complex. In light of that complexity, any single model will be more likely to fail. We should not though abandon models. To the contrary, we should privilege logical coherence over intuition and double, triple, and even quadruple down on models and become many-model thinkers. Becoming a many-model thinker requires learning multiple models of which we gain a working knowledge; we need to understand the formal descriptions of the models and know how to apply them. We need not be experts. Hence, this book balances accessibility and depth. It can function both as a resource and as a guide. The formal descriptions are isolated in stand-alone boxes. It avoids line after line of equations, which overwhelm even the most dedicated readers. The formalism that remains should be engaged and absorbed. Modeling is a craft, mastered through engagement; it is not a spectator sport. It requires deliberate practice. In modeling, mathematics and logic play the role of an expert coach. They correct our flaws. The remainder of the book is organized as follows: Chapters 2 and 3 motivate the many-model approach. Chapter 4 discusses the challenges of modeling people. The next twenty or so chapters cover individual models or classes of models. By considering one type of model at a time, we can better wrap our heads around its assumptions, implications, and applications. This structure also means that we can pull the book from our bookshelves or open it in our browsers and find self-contained analyses of linear models, prediction models, network models, contagion models, and models 

---

of long-tailed distributions, learning, spatial competition, consumer preferences, path dependence, innovation, and economic growth. Interspersed throughout the chapters are applications of manymodel thinking to a variety of problems and issues. The book concludes with two deeper dives into the opioid epidemic and income inequality. 

---

# 2. Why Model? 

_Knowing reality means constructing systems of transformations that correspond, more or less adequately, to reality._ 

 —Jean Piaget 

In this chapter, we define types of models. Models are often described as simplifications of the world. They can be, but models can also take the form of analogies or be fictional worlds mined for ideas and insights. We also describe the uses of models. In school, we apply models to explain data. In practice, we can also use models to predict, design, and take actions. We can use models to explore ideas and possibilities. And we can use models to communicate ideas and understandings. The value of models also resides in their ability to reveal conditions under which results hold. Most of what we know holds only in some cases: the square of the longest side of a triangle equals the sum of the squares of the other sides only if the longest side is opposite a right angle. Models reveal similar conditions for our intuitions. With models we can parse out when diseases spread, when markets work, when voting leads to good outcomes, and when crowds make accurate predictions. None of those is a sure thing. This chapter consists of two parts. In the first, we describe the three types of models. In the second, we cover the uses of models: to reason, explain, design, communicate, act, predict, and explore. These form the acronym REDCAPE, a notso-subtle reminder that many-model thinking endows us with superpowers.^1 

---

### Types of Models 

When constructing a model, we take one of three approaches. We can aim for realism and follow an _embodiment approach_. Such models include the important parts and either strip away unnecessary dimensions and attributes or lump them together. Models of ecological glades, legislatures, and traffic systems take this approach, as do climate models and models of the brain. Or we can take an _analogy approach_ and abstract from reality. We can model crime spreading like a disease and the taking of political positions as choices on a left-right continuum. The spherical cow is a favorite classroom example of the analogy approach: to make an estimate of the amount of leather in a cowhide, we assume a spherical cow. We do so because the integral tables in the back of calculus textbooks include tan(x) and cos(x) but not cow(x).^2 While the embodiment approach stresses realism, the analogy approach tries to capture the essence of a process, system, or phenomenon. When a physicist assumes away friction but otherwise makes realistic assumptions, she takes the embodiment approach. When an economist represents competing firms as different species and defines product niches, she makes an analogy. She does so using a model developed to embody a different system. No bright line differentiates the embodiment approach from the analogy approach. Psychological models of learning that assign weights to alternatives lump together dopamine responses and other factors; they also invoke the analogy of a scale on which we balance alternatives. A third approach, the _alternative reality approach,_ purposely does not represent or capture reality. These models function as analytic and computational playgrounds in which we can explore possibilities. This approach allows us to discover general insights that apply outside our physical and social world. They help us to understand the implications of real-world constraints: What if energy could be sent safely and efficiently through the air? And they allow us to run 

---

impossible experiments: What if we tried to evolve a brain? This book contains a few such models, notably the Game of Life, which consists of a checkerboard whose squares are classified as either alive (black) or dead (white) that switch between alive and dead according to fixed rules. Though unrealistic, the model produces insights into self-organization, complexity, and, some argue, even life itself. Whether embodying a more complex reality, creating an analogy, or building a made-up world for exploring ideas, a model must be _communicable_ and _tractable_. We should be able to write the model in a formal language such as mathematics or computer code. When describing a model, we cannot toss out terms like _beliefs_ or _preferences_ without providing a formal description. Beliefs can be represented as a probability distribution over a set of events or priors. Preferences can be represented in several ways such as a ranking over a set of alternatives or as a mathematical function. How tractable something is means how amenable it is to analysis. In the past, analysis relied on mathematical or logical reasoning. A modeler had to be able to prove each step in an argument. This constraint led to an aesthetic that valued stark models. English friar and theologian William of Ockham (1287–1347) wrote, “Plurality must never be posited without necessity.” Einstein summed up this principle, known as _Ockham’s Razor,_ as follows: _everything should be made as simple as possible, but not simpler._ Today, when we run up against the constraint of analytic tractability, we can turn to computation. We can build elaborate models with many moving parts without concern for analytic tractability. Scientists take this approach when constructing models of the global climate, the brain, forest fires, and traffic. They still pay heed to Ockham’s advice, but recognize that “as simple as possible” might require a lot of moving parts. 

---

### The Seven Uses of Models 

The academic literature describes dozens of uses of models. Here, we focus on seven categories of uses: to _reason, explain, design, communicate, act, predict,_ and _explore._ 

---

## The Uses of Models (REDCAPE) 

[[The Uses of Models (REDCAPE)]]

# 3. The Science of Many Models 

_Nothing is less real than realism. Details are confusing. It is only by selection, by elimination, by emphasis that we get to the real meaning of things._ 

 —Georgia O’Keeffe 

In this chapter, we take a scientific approach to motivate the manymodel approach. We begin with the Condorcet jury theorem and the diversity prediction theorem, which make quantifiable cases for the value of many models in helping us act, predict, and explain. These theorems may overstate the case for many models. To show why, we introduce categorization models, which partition the world into boxes. Using categorization models shows us that constructing many models may be harder than we expect. We then apply this same class of model to discuss model granularity—how specific our models should be—and help us decide whether to use one big model or many small models. The choice will depend on the use. When predicting, we often want to go big. When explaining, smaller is better. The conclusion addresses a lingering concern. Many-model thinking might seem to require learning a lot of models. While we must learn some models, we need not learn as many as you might think. We do not need to master a hundred models, or even fifty, because models possess a one-to-many property. We can apply any one model to many cases by reassigning names and identifiers and modifying assumptions. This property of models offers a counterpoise to the demands of many-model thinking. Applying a model in a new domain requires creativity, an openness of mind, and 

---

skepticism. We must recognize that not every model will appropriate to every task. If a model cannot explain, predict, or help us reason, we must set it aside. The skills required to excel at one-to-many differ from the mathematical and analytic talents many people think of as necessary for being a good modeler. The process of one-to-many involves creativity. It is to ask: _How many uses can I think of for a random walk?_ To provide a hint of the forms that creativity takes, at the end of the chapter we apply the geometric formula for area and volume as a model and use it to explain the size of supertankers, to criticize the body mass index, to predict the scaling of metabolisms, and to explain why we see so few women CEOs. 

---

### Many Models as Independent Lies 

We now turn to formal models that help reveal the benefits of manymodel thinking. Within those models, we describe two theorems: the Condorcet jury theorem and the diversity prediction theorem. The _Condorcet jury theorem_ is derived from a model constructed to explain the advantages of majority rule. In the model, jurors make binary decisions of guilt or innocence. Each juror is correct more often than not. In order to apply the theorem to collections of models instead of jurors, we interpret each juror’s decision as a classification by a model. These classifications could be actions (buy or sell) or predictions (Democratic or Republican winner). The theorem then tells us that by constructing multiple models and using majority rule we will be more accurate than if we used one of the constituent models. The model relies on the concept of a _state of the world,_ a full description of all relevant information. For a jury, the state of the world consists of the evidence presented at trial. For models that measure the social contribution of a charitable project, the state of the world might correspond to the project’s team, the organizational structure, the operational plan, and the characteristics of the problem or situation the project would address. 

---

## Condorcet Jury Theorem 

 [[Condorcet Jury Theorem]]

## Diversity Prediction Theorem 

 [[Diversity Prediction Theorem]]

## Categorization Models 

 [[Categorization Models]]

## R^2 : Percentage of Variance Explained 

 [[R^2  Percentage of Variance Explained]]

## Model Error Decomposition Theorem 

 [[Model Error Decomposition Theorem]]

## Bagging and Many Models 

[[Bagging and Many Models]]

# 4. Modeling Human Actors 

_It is not possible yet to point to a single theory of human behavior that has been successfully formulated and tested in a variety of settings._ 

 —Elinor Ostrom 

In this chapter, we address a question that lies at the core of this book: How do we model people? In many of the models that follow, people will be the fundamental unit of analysis. We will construct models of people who vote, cooperate, start uprisings, participate in fads, invest in retirement accounts, and become addicted to drugs. Within each model, we will have to make assumptions about people. What are their objectives? Do they only care about themselves or are they altruistic? What are their potential actions? How do they choose what action to take, or do they not even have a choice? We could make ad hoc assumptions for each model. But to do so would invite confusion and miss an opportunity. We would be left with an idiosyncratic set of constructions. Each new model would require new thinking about how people act. The resulting heterogeneity would limit our ability to think across and combine models. We could not be effective many-model thinkers. The approach we follow stresses coherence along with variety. We will model people as either _rule-based actors_ or _rational actors_. Within the set of rule-based actors, we consider those who act based on _simple fixed rules_ and those who act based on _adaptive rules_. Someone acting based on an adaptive rule can change her behavior based upon information or past success or because she watches others. As we shall discuss, no bright lines distinguish these cases 

---

from one another; an adaptive rule can sometimes be interpreted as a fixed rule, and sometimes rational actions will take the form of simple rules. How we choose to model people will depend on the context and on our goals. Are we predicting or explaining? Are we evaluating policy actions? Are we trying to design an institution? Or are we exploring? In low-stakes environments, such as modeling what color coat people buy or whether they stand for an ovation after a show, we will most often assume that people apply fixed rules. When people decide whether or not to cooperate in a venture or to trust another person, we will assume that people learn and adapt. Finally, in high-stakes environments, we will assume that informed, sophisticated people make optimal choices. Before describing our approach in more detail, we first address some common misconceptions. Many people first encounter formal models of social phenomena in introductory economics courses. Those models often rely on a rudimentary rational-actor model in which everyone is self-interested and capable of optimizing. The model may also assume everyone has the same preferences and income level. Economists then solve for equilibria within these models, enabling them to evaluate the effects of shocks to a market or policy changes. These models, though based on incorrect assumptions, are useful. They help economists to communicate and students to understand. Based on this experience, many people infer that formal modeling requires a narrow, unrealistic view of human nature, in which people are self-interested and never make mistakes. That is not the case. In fact, not even economists think that to be true. The frontiers of economics consist of models with imperfectly informed, heterogeneous actors who adapt in response to what they learn, and who sometimes, though not always, care about the payoffs to others. The extent to which people exhibit other-regarding preferences also depends on the situation; when donating to charity or volunteering, for example, a person may be more other-regarding than when buying a house. Nevertheless, the unfortunate impression persists that modeling 

---

assumes selfish, unrealistically rational people. We must disabuse ourselves of that view. As an analogy, if you only wade a few steps into the ocean, you might infer that it is shallow. As you swim out farther, you begin to sense the depth. Here, we start near the shore. At times we venture further out and show how models can accommodate other-focused, boundedly rational people. Whatever assumptions we do make, we cannot escape their implications. We are tied to the mast of logical coherence. We cannot manufacture implications. If we assume strong social influences in consumer choices, our model will produce a handful of products with large market shares. If we assume people obtain information through networks, then people who fill structural holes will possess power. The remainder of the chapter begins with an overview of some challenges of modeling people: we are diverse, socially influenced, mistake-prone, purposive, adaptive, and possessed of agency. We cannot include all of these characteristics in a single model without creating a complicated mess, so we must pick and choose. If heterogeneity matters little, perhaps we assume identical agents. If the problem is simple or the people sophisticated, perhaps we assume people do not make mistakes. We next describe the rational-actor model and discuss its theoretical underpinnings and the justifications for its use despite its descriptive inaccuracy. We conclude that whether the rational-actor model functions as a gold standard, a straw man, or somewhere in between depends on our model’s purpose. The rational actor will be less successful at predicting human behavior than as a tool for communicating, evaluating actions, and designing policies. We then show how we can add psychological biases and altruistic preferences onto the standard rational-actor model. The choice of whether to include a bias or a concern for others rests again on what we are studying. Some human biases such as loss aversion and presentist bias—caring more about delays today than in the future— may be necessary to include in some instances. For example, those assumptions may be important for models of retirement savings or riots. The assumptions may be less important for models of driving 

---

behavior or disease transmission. In the fourth section, we describe rule-based behavior. This category of models has the advantage of being both flexible—any behavior we can write down as a rule is fair game—and tractable. We need only encode that behavior in a computer program, an agent-based model, and watch what unfolds. That freedom comes with responsibility. As we can choose any behavioral rule, we must guard against ad hoc assumptions. In some cases, behavioral rules can be justified as optimal behavior given an objective function, though this will not always be the case. The chapter concludes with a reconsideration of the value of rationality as a benchmark behavior. Even if people do not optimize, they do adapt to changing circumstances and new knowledge. That observation produces a conundrum of sorts. If we design an institution or policy based on the assumption that people have a bias or that they act in ways not in their self-interest, we run the risk that people will change their behaviors. People may be fooled once, but they may be harder to fool two or three times. We need not conclude that rationality is the only plausible assumption, but the logic does argue for rationality as a relevant benchmark. Logic also supports considering simple rules of behavior as well, as a lower bound on rationality. And, in modeling any given situation, we might apply any number of adaptive and psychological rules as a way for us to explore the giant space in between those extremes. 

---

### The Challenge of Modeling People 

Modeling people presents a challenge because while models require low-dimensional representations, people defy simple characterizations. People are _diverse,_ we are _socially influenced,_ we are _error-prone,_ we are _purposive,_ and we _learn_. In addition, people _possess agency_ —we have the capacity to act. By way of contrast, physical objects, such as carbon atoms and billiard balls, exhibit none of these six properties. Carbon atoms lack diversity (though they can occupy heterogeneous positions within compounds, such as in propane). Carbon atoms never violate the laws of physics nor do the lead purposive lives. They do not change their behaviors based on past experiences. They lack agency; they do not decide to lead uprisings or switch careers. Hence the oftrepeated quip by social scientists: how difficult physics would be if electrons could think. Physics would be even harder if electrons could write models. We can start with the problems created by diversity. People differ in our preferences, in our capacity to act, in the social networks we form, in our levels of altruism, and in the level of cognitive attention we allocate to actions. Modeling would be easier if everyone were the same. Sometimes we rely on statistical logic and assume that the behavioral diversity cancels. For example, we might construct a model that predicts charitable donations as a function of income. For a given income level and tax rate, some people may be more altruistic than we assume and others may be less. If the deviations from the model average out (and in Chapter 5 we cover models of distributions that explain why they might), then our model may be accurate. This canceling out of diversity will not occur unless actions are independent. When behavior is socially influenced, extreme actions can create spillovers. This occurs when political activists energize voters. We will encounter this effect of diversity when we model riots. Whether or not mistakes cancel in the aggregate depends on the 

---

context. Errors that result from a lack of cognitive attachment may be random and independent. Errors that arise from cognitive biases may be systematic and correlated. For example, people may overweight recent events and recall narratives better than statistics. A shared bias like this will not cancel out. The next challenge relates to what people desire. A central challenge in writing models of people will be making an accurate assessment of their goals and objectives. Some people desire wealth and fame. Others want to contribute to the betterment of their communities and the world. In the rational-actor model, we represent a person’s payoff directly in the form of a function. In rule-based models, purposes are more implicit. A behavioral rule in which people seek to live in an integrated neighborhood but move out of a neighborhood if the percentage of people who share their racial identity falls below 10% embeds certain beliefs about what people desire. The final challenge to modeling people results from the fact that people have agency: the ability to take action, to change what we do, and to learn. That said, in some contexts, people may be better characterized as creatures of habit. Actions may be outside our control. Few people choose to be addicted to opioids or to be poor. Yet people take actions that produce those outcomes. Often, when people take actions that produce bad outcomes, they adapt their behavior. We can capture this by including learning in our models. How people learn varies by context. When learning how many hours they need to study for an exam in order to get a good grade, or how many times a week they need to exercise, people may learn based on individual experiences and introspection. When learning what grocery store to visit or whether to contribute to a charity, people may learn through observing others. In Chapter 26 , we show how in non-strategic contexts, learning generally works. People learn the best action. We also show that in strategic contexts, which we model as games, all bets are off. Neither individual nor social learning necessarily produces good outcomes. Each of these six characteristics are potential model features. If we include a feature, we must decide how much of it to include. How 

---

diverse do we make our actors? How much social influence do we include? Do people learn from others? How do we define objectives? How much agency do people possess? We may possess less agency than we believe. Jonathan Haidt describes our lack of agency with his metaphor of the rider and the elephant. “The image I came up with for myself, as I marveled at my weakness, was that I was a rider on the back of an elephant. I’m holding the reins in my hands, and by pulling one way or the other I can tell the elephant to turn, to stop, or to go. I can direct things, but only when the elephant doesn’t have desires of his own. When the elephant really wants to 

do something, I’m no match for him.”^1 Sometimes we do ride the elephant. Sometimes we do not. No single approach to modeling humans will be appropriate in all settings, so we model humans in a variety of ways. 

---

### The Rational-Actor Model 

The _rational-actor model_ assumes that people make optimal choices given a payoff or utility function. These actions can be _decisions,_ where the payoff depends only on the individual’s own action, or they can take place within a _game,_ where payoffs depend on what others do. In a game with simultaneous choices or with incomplete information, the rational-actor model also specifies _beliefs_ about what the other actors will do. 

---

## Rational-Actor Model 

 [[Rational-Actor Model]]

## A Rational-Actor Model of Consumption 

 [[A Rational-Actor Model of Consumption]]

## Arguments for Rational Choice 

 [[Arguments for Rational Choice]]

## Prospect Theory: Example 

 [[Prospect Theory Example]]

## El Farol Model: Adaptive Rules 

 [[El Farol Model Adaptive Rules]]

## The Lucas Critique 

 [[The Lucas Critique]]

# 5. Normal Distributions: The Bell Curve 

_I couldn’t claim that I was smarter than sixty-five other guys—but the average of sixty-five other guys, certainly._ 

 —Richard Feynman 

Distributions constitute part of the core knowledge base for any modeler. Later, we use distributions to construct and analyze models of path dependence, random walks, Markov processes, search, and learning. We also require a working knowledge of distributions to measure inequality in power, income, and wealth and to perform statistical tests. Our treatment of distributions unfolds over two short chapters—one each for normal and power law (long-tailed) distributions—in which we take the perspective of modelers rather than statisticians. As modelers, we are interested in two big questions: Why do we see the distributions we do, and why do distributions matter? To address the first big question, we need to reacquaint ourselves with what distributions are. A _distribution_ mathematically captures variation (differences within a type) and diversity (difference across types) by representing them as probability distributions defined over numerical values or categories. A _normal distribution_ takes the familiar bell curve shape. Heights and weights of most species satisfy normal distributions. They are symmetric around their means and do not include particularly large or small events. We do not encounter many six-foot-long ants or four-pound elk. We can rely on the central limit theorem to explain the prevalence of normal distributions. It tells us that when we add up or average random variables, we can expect to obtain a normal distribution. Many 

---

empirical phenomena, in particular any aggregate like sales data or vote totals, can be written as sums of random events. Not all event sizes are normal. Earthquakes, war deaths, and book sales exhibit _long-tailed distributions_ : they consist mostly of tiny events but include the occasional whopper. Californians experience over 10,000 earthquakes each year. Unless you are staring at the quivering petals of a jasmine blossom, you would not notice them. Occasionally, though, the earth opens up, highways collapse, and cities tremble. Knowing whether a system produces a normal or long-tailed distribution matters for any number of reasons. We want to know whether a power grid will suffer massive outages, or whether a market system will produce a handful of billionaires and billions of poor people. With knowledge of distributions, we can predict the likelihood of floodwaters that exceed a levee’s walls, the probability that Delta flight 238 arrives in Salt Lake City on time, and the odds that a transportation hub costs double its budgeted amount. Knowledge of distributions is also relevant in design. Normal distributions imply no large deviations, so airplane designers need not create leg space for the eighteen-foot human. An understanding of distributions can also guide actions. As we learn later, preventing riots depends less on reducing average levels of discontent than on appeasing people at the extreme. In this chapter, we adopt a _structure-logic-function_ organization. We define normal distributions, describe how they arise, and then ask why they matter. We apply our knowledge of distributions to explain why good things come in small samples, to test for significance of effects, and to explain Six Sigma process management. We then go back to the logic question and ask what happens if we multiply rather than add random variables. We learn that we obtain a _lognormal distribution_. Lognormal distributions include larger events and are not symmetric about their means. It follows that multiples of effects lead to more inequality, an insight that has implications for how policies for increasing salaries affect income distributions. 

---

### The Normal Distribution: Structure 

A distribution assigns probabilities to events or values. The distribution of daily rainfall, test scores, or human height assigns a probability to every possible value of the outcomes. Statistical measures condense the information contained in a distribution into single numbers, such as the _mean_ , the average value of the distribution. The mean height of a tree in Germany’s Black Forest might be eighty feet, and the mean time spent in the hospital following open-heart surgery might be five days. Social scientists rely on means to compare economic and social conditions across countries. In 2017, the United States per capita GDP of $57,000 exceeded that of France, which equaled $42,000, while mean life expectancy in France exceeds that of the United States by three years. A second statistic, _variance,_ measures a distribution’s dispersion: the average of the squared distance of the data to the mean.^1 If every point in a distribution has the same value, the variance equals zero. If half of the data have value 4 and half have value 10, then, on average, each point lies distance 3 from the mean, and the variance equals 9. The _standard deviation_ of a distribution, another common statistic, equals the square root of the variance. The set of possible distributions is limitless. We could draw any line on a piece of graph paper and interpret it as a probability distribution. Fortunately, the distributions we encounter tend to belong to a few classes. The most common distribution, the normal distribution, or bell curve, is shown in figure 5.1. 

 Figure 5.1: Normal Distribution with Standard Deviations 

---

Normal distributions are _symmetric_ about their mean. If the mean equals zero, the probability of a draw larger than 3 equals the probability of a draw less than -3. A normal distribution is characterized by its mean and standard deviation (or, equivalently, its variance). In other words, graphs of normal distribution all look identical, with approximately 68% of all outcomes within one standard deviation of the mean, 95% of all outcomes within two standard deviations, and more than 99% lying within three standard deviations. Normal distributions allow for any size outcome or event, though large events are rare. An event five standard deviations from the mean occurs about once in every 2 million draws. We can exploit the regularity of normal distributions to assign probabilities to ranges of outcomes. If houses in Milwaukee, Wisconsin, have a mean square footage equal to 2,000 with a standard deviation of 500 square feet, then 68% of houses have between 1,500 and 2,500 square feet and 95% have between 1,000 and 3,000 square feet. If the 2019 fleet of Ford Focuses can travel, on average, 40 miles per gallon with a standard deviation of 1 mile per gallon, then more than 99% of Focuses will get between 37 and 43 miles per gallon. As much as a consumer might hope, her new Focus will not run 80 miles on a gallon of gasoline. 

---

### The Central Limit Theorem: Logic 

No end of phenomena exhibit normal distributions: physical sizes of flora and fauna, student test scores on exams, daily sales at convenience stores, and the life spans of sea urchins. The _central limit theorem_ , which states that adding or averaging random variables produces a normal distribution, explains why (see box). 

---

## Central Limit Theorem 

 [[Central Limit Theorem]]

## The Square Root Rules 

 [[The Square Root Rules]]

# 6. Power-Law Distributions: Long Tails 

_Every fundamental law has exceptions. But you still need the law or else all you have is observations that don’t make sense. And that’s not science. That’s just taking notes._ 

 —Geoffrey West 

In this chapter, we cover power-law distributions. Often described as longor heavy-tailed distributions, when graphed these distributions produce a long tail running along the horizontal axis corresponding to large events. The distributions of city populations, species extinctions, the number of links on the World Wide Web, and firm sizes all have long tails, as do the distributions of videos downloaded, books sold, academic citations, war casualties, and floods and earthquakes. In other words, all of these distributions include large events: Tokyo has 33 million residents, J. K. Rowling’s Harry Potter books have sold in the neighborhood of half a billion copies, and the great Mississippi flood of 1927 covered an area larger than the state of West Virginia under thirty feet of water.^1 Contemplating a power-law distribution of human heights reveals how much power-law distributions differ from normal distributions. If human heights were distributed by a power law similar to that of city populations, and if we calibrate the mean height at 5 feet 9 inches, then the United States would include one person the height of the Empire State Building, over 10,000 people taller than giraffes, and 

180 million people less than 7 inches tall.^2 To produce a long-tailed distribution requires non-independence, often in the form of positive feedbacks.^3 Book sales, forest fires, and city populations, unlike trips to the grocery store, are not 

---

independent. When one person buys a Harry Potter book, she induces others to buy it. When a single tree catches on fire, that fire can spread to neighboring trees. When a city increases in population, it adds amenities and job opportunities, making it more attractive to others. The sociologist Robert Merton referred to the tendency for those who have more to also receive more as the _Matthew effect_ : “For unto every one that hath shall be given, and he shall have abundance: but from him that hath not shall be taken even that which he hath” (Matthew 25:29). Given the variety of domains in which we find power-law distributions, it would be remarkable if a single mechanism could explain them all, and none does. It would be even more remarkable if each instance of a power-law distribution had a unique explanation. That is also not true. Instead, we possess a collection of distinct models that produce power laws, each capable of explaining different phenomena. In this chapter, we focus on two models: the preferential attachment model, which explains city sizes, book sales, and web links, and the self-organized criticality model, which explains traffic jams and war deaths, as well as earthquake, fire, and avalanche sizes. In Chapter 12 when we cover entropy, we learn a third model in which a power-law maximizes uncertainty given a fixed mean. And in Chapter 13 , we show that return times in a random walk model also satisfy a power law. Still other models show that power laws result from optimal encodings, random stopping rules, and 

combining distributions.^4 The remainder of the chapter covers the structure, logic, and functions of power-law distributions, followed by a discussion. The discussion reconsiders the implications of large events and describes the limits of our ability to prevent and plan for them. 

---

### Power Laws: Structure 

In a _power-law distribution_ , the probability of an event is proportional to its size raised to a negative exponent. So for example, the familiar function describes a power law. In a power-law distribution, the probability of an event is inversely related to its size: the larger the event, the less likely it occurs. Power-law distributions, therefore, have many more small events than large ones. 

---

## Power-Law Distributions 

 [[Power-Law Distributions]]

## Zipf’s Law 

 [[Zipf’s Law]]

## Preferential Attachment Model 

 [[Preferential Attachment Model]]

## Self-Organized Criticality: Forest Fire Model 

 [[Self-Organized Criticality Forest Fire Model]]

## Search and Opportunity 

[[Search and Opportunity]]

# 7. Linear Models 

_I’m lying, yes, but why do you force me to give a linear explanation; linear explanations are almost always lies._ 

 —Elena Ferrante 

Often models posit specific functional relationships between variables. That relationship could be linear, concave, convex, or Sshaped, or it could include threshold effects. Of these, linear models are the simplest, the most widely used, and the focus of this chapter. The effects of education on income, of gains in life expectancy from exercise, and of income on voter turnout can all be measured using linear models. We begin the chapter with a refresher on linear functions with a single variable. We then show how regression fits data to a linear function, revealing the sign, magnitude, and significance of effects. We also discuss why errors, noise, and heterogeneity mean that data do not fall exactly on the regression line. We then expand the linear model to allow for more variables and discuss how to fit multivariable linear models. To build intuition for multiple variable models, we describe a model of success as a linear function of skill and luck. The chapter concludes with an observation of how relying on data and regressions to guide action limits mistakes but can also produce marginal, conservative actions. This big-coefficient thinking can stifle innovation. To identify more innovative options, we might consider constructing other, more speculative models. 

---

### Linear Models 

In a linear relationship, the amount of change in one variable due to a change in a second variable does not depend on the value of the second variable. If the height of a tree is linear with the tree’s age, the tree grows by the same amount each year. If the value of a house increases linearly in its square footage, a 200-square-foot addition increases a house’s value by double that of a 100-squarefoot addition. A 400-square foot addition increases the house by four times as much. 

---

## Linear Models 

 [[Linear Models]]

## Sign, Significance, and Magnitude 

 [[Sign, Significance, and Magnitude]]

## The Success Equation 

[[The Success Equation]]

## The Big Coefficient vs. the New Reality 

 [[The Big Coefficient vs. the New Reality]]

## Binary Classifications of Data 

[[Binary Classifications of Data]]

# 8. Concavity and Convexity 

_To say nonlinear science is akin to saying non-elephant zoology._ 

 —John von Neumann 

We now introduce nonlinear models and nonlinear functions. Nonlinear functions can curve downward or upward, they can form S-shapes, they can kink, jump, and squiggle. In time, we cover all of these possibilities. We start here with models that rely on convexity and concavity. We show how growth and positive feedbacks produce convexity and how diminishing returns and negative feedbacks produce concavity. Most disciplines contain models of both types. Economic production models assume that delivery and inventory costs decrease with a firm’s size, making profits per unit sold a convex function of a firm’s size, which explains why Walmart earns such large profits.^1 Economic models of consumption assume that the utility (or value) is concave, that we enjoy the fifth piece of pizza less than the first. In ecosystems, when a new species invades and confronts no predators, its population grows at a constant rate, producing a convex function. As that population grows, it has less food. Fitness, as a function of population size, is therefore concave. The chapter consists of three parts. The first part covers models of population growth and decay. The second part covers concavity. In it, we see how concavity implies risk aversion and a preference for variety. In the third part, we study a series of growth models from economics that combines concave functions and linear functions. 

---

### Convexity 

Convex functions have an increasing slope: the function’s value increases by a larger amount as we increase a variable’s value. The number of possible pairs of people is a convex function of the group size. A group of three people includes three unique pairs. A group of four people includes six unique pairs, and a group of five includes ten unique pairs. Each increase in group size increases the number of pairs by a larger amount. Similarly, each time a chef adds a new spice to his repertoire, he increases the number of spice combinations by a larger amount. Our first model of convexity, the _exponential growth model_ , describes the amount of a variable, often a population or a resource, as a function of its initial value, a growth rate, and the number of periods. 

---

## Exponential Growth Model 

 [[Exponential Growth Model]]

## Rule of 72 

 [[Rule of 72]]

## Half-Life Model 

 [[Half-Life Model]]

## Cobb-Douglas Model 

 [[Cobb-Douglas Model]]

## Simple Growth Model 

 [[Simple Growth Model]]

## Solow* Growth Model 

 [[Solow Growth Model]]

## Japanese Chinese Economic Dominance 

[[Japanese Chinese Economic Dominance]]

# 9. Models of Value and Power 

_Your value will be not what you know; it will be what you share._ 

 —Ginni Rometty 

In this chapter, we cover models that quantify the value and power of individual actors. Some cases are easy. When a group produces output equal to the sum of individual contributions, each individual’s value equals her contribution. When the collective output cannot be separated into individual components, such as when a team of computer programmers writes a software program or a group of entrepreneurs proposes creative uses for a new technology, assigning credit becomes difficult. Assigning power to political parties creates similar problems; the number of seats a party controls correlates with power, but not perfectly. In this chapter, we define two measures of value and power: laston-the-bus value, which equals an actor’s marginal contribution given that the group has already formed, and Shapley value, which equals an actor’s average marginal contribution across all possible sequences of adding people to a group. In a group of three people, we average a person’s added value when she joins the group first, second, and third. We define these measures within the structure of cooperative game models, which consist of a set of players along with a value function that assigns a collective payoff to every possible subset of the players. The chapter consists of four parts. In the first part, we define cooperative game models, last-on-the-bus value, and Shapley value, and work through some examples. In the second part, we describe axiomatic foundations for the Shapley value. We show it to be the 

---

unique measure satisfying four conditions. One condition is that a player who never adds value must be assigned value zero. A second condition is that the sum of the player’s values must equal the total value of the game. In the third part, we apply Shapley value to a group performing a creative task. Each person thinks up ideas. We show how in this context, the measure produces an intuitive measure of value. In the fourth part, we consider the special case of applying the Shapley value to voting games. We use it to distinguish between voting power and vote percentage. We find that they need not always agree. A party might hold 20% of the seats and have no power in one case and a third of the total power in another. 

---

### Cooperative Games 

A _cooperative game_ consists of a set of players and a _value function_ that assigns a value to every possible subset, often called a coalition, of players. Cooperative games are meant to capture collective work and joint projects. In the model, we assume that people participate so that we can focus attention on how to assign value to their participation. 

---

## Cooperative Games 

 [[Cooperative Games]]

## Shapley Value 

 [[Shapley Value]]

## Shapley Value: Axiomatic Basis 

[[Shapley Value Axiomatic Basis]]

# 10. Network Models 

_Network theory is a whole branch of science, but it’s relatively new in terms of the last 20 or 30 years. We haven’t had a chance to take all that theory out of the universities and apply it to ask: “What kinds of networks should we build, and for what purposes?”_ 

 —Anne-Marie Slaughter 

In this chapter, we cover models of networks. A comprehensive study of networks would require multiple books. We have more modest goals. We want to understand the basics of networks, to be able to name their parts, and to ask why they matter for modeling. The answer we arrive at will be that networks almost always matter. Any model we construct, be it of a market, the spread of a disease, or the transmission of information, can be enriched by embedding the actors in a network.^1 Networks are ubiquitous. People talk of trade networks, terrorist networks, and networks of volunteers. Species organize into food webs, a form of network. Firms build supply chain networks. As already noted, the financial system is usefully thought of as a network of promises to pay. Networks have always been important to understanding social relations. During much of human history, social networks were constrained by geography and difficult to map. Due to technological advances, many social interactions and economic transactions now take place over virtual networks which can be analyzed using models. The organization of this chapter follows the same structure-logicfunction format we applied to distributions. We first characterize the structure of networks using statistical measures of degree, path 

---

length, clustering coefficient, and community structure. Then we discuss common classes of networks: random networks, hub-andspoke networks, geographic networks, small-world networks, and power-law networks. After that we turn to the logic of how networks form. We construct micro-level processes that produce the network structures we see. Last, we take up function, the question of why network structure matters. Here we focus on five implications. We begin with the friendship paradox, and then describe the six degrees of separation phenomenon and the strength of weak ties property. Last, we take up the robustness of networks to node or edge failure and the aggregation of information over networks. The chapter concludes with a discussion of how networks influence model outcomes. 

---

### Network Structure 

A network consists of _nodes_ and _edges_ that connect them. We refer to nodes connected by an edge as _neighbors_ and to a network as _connected_ if it is possible to get from any one node to any other along edges. Networks can be represented as graphs, as lists of edges, or as matrices of zeros and ones, where a one in row _A_ and column _B_ denotes an edge between node _A_ and node _B_. Though people prefer graphical representations of networks, lists and matrices are better for representations for calculating network statistics. The edges in a network can be _directed_ —that is, pointing from one node to another. In an information network, a directed edge denotes that one person gets information from another. In an ecosystem network, a directed edge from a red-tailed hawk to a gray squirrel represents that the hawk eats the squirrel. Edges can also be _undirected_. Edges that connect friends are drawn in this way. In an undirected network, the _degree of a node_ equals the number of edges that connect to it. Networks are characterized by a set of network statistics. For each statistic, we can compute the network average and the distribution across all nodes. The _average degree_ of a friendship network tells us, on average, how many friends each person has. The _degree distribution_ tells us if some nodes are more connected than others. Social networks have more equal distributions than the World Wide Web, the internet, and citation networks, all of which have long tails. 

---

## Network Statistics 

 [[Network Statistics]]

## Monte Carlo Method for Random Networks 

 [[Monte Carlo Method for Random Networks]]

## Quality and Degree Network Formation Model 

 [[Quality and Degree Network Formation Model]]

## The Friendship Paradox 

 [[The Friendship Paradox]]

## Six Degrees of Separation 

 [[Six Degrees of Separation]]

## Myerson Value and Burt’s Structural Holes 

[[Myerson Value and Burt’s Structural Holes]]

# 11. Broadcast, Diffusion, and Contagion 

_As contagion of sickness makes sickness, contagion of trust can make trust._ 

 —Marianne Moore 

In this chapter, we model the spread of information, technologies, behaviors, beliefs, and diseases throughout a population using models of broadcast, diffusion, and contagion. These models play central roles in communication, marketing, and epidemiology. All three models partition the population into people who know or have some thing and those who do not. Over time, people move between those two groups. Someone moves from being susceptible to a disease to being infected, or from being uninformed about a new product or idea to being informed. Empirical plots of the number of people who over time catch a disease, buy a product, or know a piece of information (the _adoption curve_ ) tend to be either concave or S-shaped. How people learn the information or catch the disease—that is, whether it spreads by broadcast or diffusion—determines the shape of that graph. One contribution of this chapter will be to link the micro-level processes of how ideas and diseases spread to the shape of these adoption curves. The chapter begins with an analysis of the broadcast model, which applies when people hear of an idea or catch a disease from a single source. This model produces plots with an r-shape. We then cover the diffusion model, in which spread occurs from contact, as when a disease spreads from person to person. This model produces an S-shaped curve. Many products, programs, ideas, and pieces of information 

---

spread by both broadcast and word of mouth. We can model these environments by allowing for both broadcast and diffusion. The resulting model, known as the Bass model, plays a central role in marketing. Whether it produces more of an r-shape or S-shape depends on the strengths of the two processes. The last model we cover, the SIR model of contagion from epidemiology, includes a rate of recovery. This assumption could capture an immune system fighting off a disease, behaviors or styles dropping out of fashion, or information becoming less worthy of passing on to others. The SIR model produces a tipping point, where small changes in the attributes of the product or a disease spell the difference between failure and success. A slight reduction in virulence can transform a mass infection into a minor outbreak. A small increase in the probability of spreading word of a hot new band can be the difference between the Beatles and a band that played pubs in Liverpool for a few months in the 1960s. 

---

### The Broadcast Model 

All of the models we cover in this chapter assume a _relevant population_ , denoted by _N_ POP. This consists of those people who 

could potentially catch the disease, learn the piece of information, or adopt the product. The relevant population is not the entire population of, say, a city or country. If we are modeling the spread of a continuous aortic suture method, the relevant population is heart surgeons, not everyone in the city of Philadelphia. At any moment in time, some people have the disease, know the information, or adopt the behavior. We refer to these people as either the _infected_ or the _informed_ (denoted by _It_ ). The remaining members 

of the relevant population are _susceptible_ (denoted by _St_ ). These 

people could catch the disease or learn the information or behavior.^1 The relevant population equals the sum of the number of people infected (or informed) plus the number of susceptible people: _N_ POP = 

_It_ + _St_. 

---

## Broadcast Model 

[[Broadcast Model]]

## Fitting the Broadcast Model to Data 

 [[Fitting the Broadcast Model to Data]]

## Diffusion Model 

 [[Diffusion Model]]

## Bass Model 

[[Bass Model]]

## SIR Model 

 [[SIR Model]]

## R 0 : The Basic Reproduction Number 

[[R 0  The Basic Reproduction Number]]

## R 0 , Superspreaders, and Degree Squaring 

[[R 0 , Superspreaders, and Degree Squaring]]

# 12. Entropy: Modeling Uncertainty 

_Information is the resolution of uncertainty._ 

 —Claude Shannon 

In this chapter, we introduce _entropy_ , a formal measure of uncertainty. With it, we can show an equivalence between uncertainty, information content, and surprise. Low entropy corresponds to low uncertainty and little information being revealed. When an outcome occurs in a low-entropy system, such as the sun rising in the east, we experience little surprise. In high-entropy systems, say the drawing of numbers in a lottery, the outcomes are uncertain and when realized, they reveal information. We experience surprise. Using entropy, we can compare disparate phenomena. We can say whether election outcomes in New Zealand are more uncertain than outcomes of United Nations votes on censure. We can compare the uncertainty of stock prices to the uncertainty of outcomes of sporting events. We can also use entropy to distinguish between the four classes of outcomes: equilibrium, periodicity, complexity, and randomness. We can distinguish complex patterns that appear random from true randomness and discern whether what appears to be a pattern is, in fact, random. We can also use entropy to characterize distributions. In the absence of a controlling or regulating force, some populations may drift toward maximal entropy. Given constraints, such as a fixed mean or variance, we can solve for maximum entropy distributions. Maximal entropy results can also guide our modeling choices by justifying some distributions over others. 

---

The chapter has five parts. In the first part, we provide intuition for and define information entropy. In the second part, we describe Shannon’s axiomatic foundations for a general class of entropy measures. In the third part, we discuss how to use entropy to distinguish equilibrium, order, randomness, and complexity. In the fourth part, we investigate systems that produce maximal entropy given constraints. We conclude by discussing why, sometimes, we prefer complexity to equilibrium. 

---

### Information Entropy 

Entropy measures the uncertainty associated with a probability distribution over outcomes. It therefore also measures surprise. Entropy differs from variance, which measures the dispersion of a set or distribution of numerical values. Uncertainty correlates with dispersion, but the two differ. Distributions with high uncertainty have nontrivial probabilities over many outcomes. Those outcomes need not have numerical values. Distributions with high dispersion take on extreme numerical values. The distinction can be seen in stark relief by comparing a distribution that has maximal entropy with one that has maximal variance. Given outcomes that take values 1 through 8, the distribution that maximizes entropy places equal weight on each outcome.^1 The distribution that maximizes variance takes value 1 with probability and value 8 with probability , as shown in figure 

12.1. 

Figure 12.1: Maximal Entropy and Maximal Variance Entropy is defined over probability distributions. It can therefore be applied to distributions over nonnumerical data such as the species of birds in a forest or the market shares of flavors of jam. The formal expression for entropy is written as minus the sum of products of probabilities and their logarithms. That sounds complicated, but it will become intuitive. We begin with the special case of _information entropy,_ which measures uncertainty in terms of number of random flips of a fair coin. Suppose that every family has exactly two children and that 

---

boys and girls are equally likely. The sexes of a family’s children (listed by birth order) are equivalent to two coin flips. The distribution over outcomes therefore has an information entropy of 2 because it corresponds to 2 random events. The information content also equals 2 because we could learn the outcomes by asking 2 yes-orno questions. Similarly, the sexes of the children in families of size three are equivalent to 3 coin flips. To learn about a family’s children, we would need to ask 3 questions. The same logic applies for any number of children. In the general case, to learn the sexes of _N_ children, we would need to ask _N_ questions. 

Notice that those _N_ questions distinguish among 2 _N_ possible birth orders. That mathematical relationship is the key to understanding the entropy measure: _N_ binary random events produce 2 _N_ possible outcome sequences, and, equivalently, we could learn the outcome sequence by asking _N_ questions. For this reason, information entropy assigns an uncertainty level (and an information content) of 

_N_ to an equal distribution over 2 _N_ outcomes. To capture that relationship in formal mathematics, we first note that each of the outcome sequences has a probability of. To convert this to _N_ requires the rather complicated expression 

.^2 We can generalize this construction to arbitrary probabilities. If an outcome sequence arises with probability _p_ , then we assign an uncertainty log 2 ( _p_ ) which approximates the number of 

yes-or-no questions required to identify the sequence To compute the information entropy of a distribution, we average the expected number of questions across all outcomes, or, as in the example, sequences of outcomes. 

---

## Information Entropy 

 [[Information Entropy]]

## Axiomatic Foundations: Entropy 

 [[Axiomatic Foundations Entropy]]

## Maximal Entropy Distributions 

 [[Maximal Entropy Distributions]]

# 13. Random Walks 

_A drunk man will find his way home, but a drunk bird may get lost forever._ 

 —Shizuo Kakutani 

In this chapter, we learn two classic models from probability and statistics: the Bernoulli urn model and the random walk model.^1 Both models describe random processes even if it may appear that they are producing complex structures. Randomness can be hard to discern without gathering data. We often think we see patterns in election outcomes, stock prices, and scoring in sporting events, but instead, to borrow Nassim Taleb’s lovely phrase, we are being fooled 

by randomness.^2 The Bernoulli urn model describes random processes that produce discrete outcomes, like the flip of a coin or the roll of a die. Developed centuries ago to explain the odds of winning at gambling, it now occupies a central position in probability theory. The random walk model builds on that model by keeping running totals of the number of heads and tails. The model can capture the movement of particles in liquids and gases, the movement of animals in physical space, and growth in human height from birth to childhood.^3 The chapter begins with brief coverage of the Bernoulli urn model along with an analysis of the length of streaks. We then describe the random walk model. We learn that one-dimensional and twodimensional random walks return to their starting point infinitely often, while a three-dimensional random walk need not return home at all. We also learn that the time between returns to zero for a onedimensional random walk will follow a power-law distribution. This 

---

finding, which we might be tempted to dismiss as a mathematical curiosity, can explain the life spans of species and firms. In the final section, we use the random walk model to evaluate the efficient market hypothesis and to determine the size of a network. 

---

### The Bernoulli Urn Model 

The _Bernoulli urn model_ consists of an urn containing gray and white balls. Draws from the urn represent the outcomes of random events. Each draw is independent of previous and future draws, so we can apply the _law of large numbers_ : in the long run, the proportion of balls drawn of each color will converge to its proportion in the urn. That does not mean that a thousand draws from an urn containing seven white balls and three gray balls will produce exactly seven hundred white outcomes, only that the proportion of white balls will converge to 70%.^4 

---

## Bernoulli Urn Model 

 [[Bernoulli Urn Model]]

## A Simple Random Walk 

 [[A Simple Random Walk]]

# 14. Path Dependence 

_No man ever steps in the same river twice, for it’s not the same river and he’s not the same man._ 

 —Heraclitus 

In this chapter, we cover models of path dependence. In any domain in which people base their behavior on the actions of others, be it international affairs, art, music, sports, business, religion, technology, or politics, we should expect some degree of path dependence. A college student’s choice of courses point her toward some career paths over others. An endorsement of a candidate may launch a political career. A friendship may lead to other social connections. The clothes we wear, the books we read, the movies we watch, and the activities that consume our time all exhibit some degree of path dependence. Path dependence also exists on grander scales. Common-law rulings establish and reinforce precedents, influencing future rulings.^1 Early institutional forms impact later institutional choices. The decision in the United States to provide health insurance through private firms resulted in a large private health insurance industry, health maintenance organizations, and a mix of public and 

private hospitals.^2 Institutions also induce behavioral patterns, such as selfish or cooperative tendencies, that can in turn influence the efficacy of future institutions.^3 In this chapter, we build dynamic urn models that produce sequences of outcomes that exhibit path dependence. These models extend the Bernoulli urn model by allowing the distribution of balls within the urn to change as a function of past outcomes. With these 

---

models to structure our thinking, we then provide a formal definition of path dependence and distinguish path-dependent outcomes from path-dependent equilibria. These formal definitions differentiate path dependence from tipping points, which are more abrupt changes in outcomes. The chapter consists of four parts. The first two cover the Polya process and the balancing process. The Polya process assumes positive feedbacks and produces both path-dependent outcomes and equilibria. Many of the canonical examples of path dependence, including the growth of the QWERTY typewriter, are based on positive feedbacks, also known as increasing returns. The balancing process assumes negative feedbacks and produces path-dependent outcomes but not path-dependent equilibria. The third part defines a measure of path dependence based on entropy. The final section discusses further applications of the models. 

---

### Polya Process 

The _Polya process_ captures positive feedbacks using an extension of the Bernoulli urn model in which we add a ball to the urn that matches the ball chosen. This process generates _outcome path dependence_ , where outcomes in each period depend on previous outcomes. It will also be true that the long-run distribution over outcomes— _equilibrium path dependence_ —depends on outcomes.^4 The distinction between these two types of path dependence will be central to what follows. A process that is equilibrium path dependent must be outcome path dependent. If outcomes in the long run depend on the path, then so must outcomes along the way. A process can be outcome path dependent but not equilibrium path dependent. What happens now could depend on the past, but the long-run equilibrium might be determined at the outset. 

---

## The Polya Process 

 [[The Polya Process]]

## The Balancing Process 

 [[The Balancing Process]]

## Value at Risk and Volatility 

[[Value at Risk and Volatility]]

# 15. Local Interaction Models 

_Every generation laughs at the old fashions, but follows religiously the new._ 

 —Henry David Thoreau 

In this chapter, we study two models of local interactions, the _local majority model_ and the _Game of Life_. These models both take place on a checkerboard consisting of cells that can be in one of two states. Otherwise, the models could not be more different. In the local majority model, cells update by matching the state of the majority of their neighbors. In the Game of Life, cells rely on a more complicated rule with multiple thresholds. The outcomes of the models also differ. The local majority model always converges to an equilibrium, while the Game of Life, depending on its initial configuration, can produce any class of outcome: equilibria, cycles, complexity, or randomness. The local majority model can be used to explain and predict realworld outcomes in social and physical systems. It can represent discrete choices by conforming individuals or capture physical systems such as spin glasses, where magnetic entities align with neighbors. In contrast, the Game of Life is purely exploratory. It was developed to explore how simple rules can aggregate to produce complex phenomena. In the Game of Life, the periodic patterns, complex sequences, and randomness emerge from the interactions. The model shows how the whole can be different in kind from the parts. As a crude analogy, the human brain also produces emergent phenomena such as emotion, cognition, and consciousness from much simpler parts. 

---

We begin by analyzing the local majority model. We show how a standard coordination game provides microfoundations for the behavioral rule assumed in the model. We can thus interpret the actors in the model as either rule-following agents or rational actors applying a best-response strategy. We then describe the Game of Life and show how it produces complexity from simple rules. The discussion at the end of the chapter highlights the value of exploring with local interaction models. 

---

### The Local Majority Model 

The _local majority model_ assumes cells arrayed on a checkerboard.^1 Each cell is in one of two states, which we refer to as _on_ or _off_. Initially we assign states randomly; thereafter, a cell’s state depends on the states of its neighbors. The neighbors can be defined in several ways. We take the neighbors of cell _C_ to be the four cells to the north, south, east, and west as well as the four diagonally adjacent cells, creating a neighborhood of size eight. 

---

## Local Majority Model 

 [[Local Majority Model]]

## Pure Coordination Games 

[[Pure Coordination Games]]

## The Paradox of Coordination 

 [[The Paradox of Coordination]]

## The Game of Life 

 [[The Game of Life]]

# 16. Lyapunov Functions and Equilibria 

_The beauty of mathematics only shows itself to more patient followers._ 

 —Maryam Mirzakhani 

In this chapter, we learn Lyapunov functions, which provide conditions for a model to achieve equilibrium. Lyapunov functions are real-valued functions defined over the configuration system that are indexed by time. In each time step, a Lyapunov function assigns a value to the configuration. If the configuration changes—that is, if the model is not at an equilibrium—then the Lyapunov function’s value decreases by a fixed amount. A Lyapunov function also has a minimum value, which means that eventually its value must stop decreasing. When that happens the model reaches an equilibrium. We can use Lyapunov functions to show, for example, why the local majority model converges. The key takeaway from this chapter will be that if we can construct a Lyapunov function for a model, the model must go to an equilibrium. We cannot get a periodic orbit, randomness, or complexity. Even more, we can also bound the time to convergence to that equilibrium as we show when we construct a Lyapunov function for the local majority model. The chapter has six parts. We first define Lyapunov functions and then apply them in the Race to the Bottom Game. We then construct Lyapunov functions for the local majority model and a model of ordering activities. In the fourth part, we show why we can construct Lyapunov functions for some exchange markets, and why we cannot for others. We then see why the Game of Life lacks a Lyapunov 

---

function as well. We then discuss a deceptively vexing mathematics problem that always goes to an equilibrium for which no Lyapunov function has been found. The chapter concludes by returning to the question of whether equilibria are desirable. 

---

### Lyapunov Functions 

A _discrete dynamical system_ consists of a space of possible _configurations_ —think of these of as multidimensional states of the world such as an initial collection of live and dead cells in the game of the life—along with a _transition rule_ that maps the configuration at time _t_ into a configuration at time _t_ + 1. A _Lyapunov function_ maps configurations into the real numbers and satisfies two assumptions. First, if the transition function is not at an equilibrium, the value of the Lyapunov function falls by a fixed amount (more on that in a moment). And second, the Lyapunov function has a minimum value. If both assumptions hold, then the dynamical system must attain an equilibrium. 

---

## Lyapunov Theorem 

 [[Lyapunov Theorem]]

## The Race to the Bottom Game 

 [[The Race to the Bottom Game]]

## Self-Organizing Activities Model 

 [[Self-Organizing Activities Model]]

# 17. Markov Models 

_History is a cyclic poem written by time upon the memories of man._ 

 —Percy Bysshe Shelley 

_Markov models_ capture systems that transition probabilistically between a finite set of states. A political system might transition between democratic and dictatorial, a market between volatile and stable regimes, or a person between happy, contemplative, anxious, and sad. In a Markov model, the movements between states occur according to fixed probabilities. The probability that a country transitions from authoritarian to democratic in a given year might be 5%; the probability that a person transitions from anxious to tired within an hour may be 20%. If, in addition, the system can move from any one state to any other through a sequence of transitions and if there exists no simple cycle of back and forth, a Markov model attains a unique _statistical equilibrium_. In a statistical equilibrium, individual entities continue to move between states but the probability distribution across the states remains fixed. A statistical equilibrium in a Markov model of ideology would allow for people to transition between liberal, conservative, and independent, but the proportions of people of each ideology would remain unchanged. When applied to a single entity, a statistical equilibrium means that long-run probability of the entity being in each state does not change. A person could be in a statistical equilibrium in which he is happy 60% of the time and sad 40% of the time. The person’s mental state could change from hour to hour, but his long-run distribution across those states does not. The unique statistical equilibrium implies that long-run 

---

distributions of outcomes cannot depend on the initial state or on the path of events. In other words, initial conditions do not matter, and history does not matter. Nor can interventions that change the state matter. As time marches on, a process that satisfies the assumptions inexorably heads to its unique statistical equilibrium and then stays there. Here again, a model reveals conditional logic: if the world fits the assumptions of a Markov model, history does not matter in the long run. The Markov model does not say that history can never matter. First, the model allows for outcome path dependence—what happens next will depend on the current state. Second, it allows for history to model in the long run as well, but for that to be the case, one of the model’s assumptions must be violated. Markov models have myriad applications. They can be used to interpret dynamic phenomena such as democratic transitions, buildups to war, and the success of drug interventions. They can also be used to rank webpages, academic journals, and sports teams. They can even be used to adjudicate authorship of books and articles. In this chapter, we cover each of these applications. We begin with two examples and then state a general theorem for a statistical equilibrium to exist. Then, in the third section, we turn to the applications. In the discussion at the end of the chapter, we reengage the question of how and when history matters in light of our knowledge of Markov models. 

---

### Two Examples 

A Markov model consists of a set of _states_ and _transition probabilities_ between those states. In our first example, we characterize a person’s mood on a given day as either mentally engaged or bored. These are formally represented as the two states of the model. The transition probabilities then characterize the probability of moving between states. For example, as shown in the diagram below, we assume that when mentally engaged, a person has a 90% chance of remaining in that state and a 10% chance of becoming bored, and that when bored, a person has a 70% chance of remaining bored and a 30% chance of becoming mentally engaged. 

Figure 17.1: A Markov Process Suppose that these transition probabilities hold for 100 students taking a biology class. Initially half of the students are engaged and half are bored, as shown in 17.1. Applying the transition probabilities described above, we expect that on the next day, 5 (10%) of the mentally engaged students will become bored, and 15 (30%) of the bored students will become mentally engaged. This results in 60 mentally engaged students and 40 bored students. The day following that, 6 of the 60 mentally engaged students should become bored and 12 of the bored students should become mentally engaged, resulting in 66 mentally engaged students and 34 bored students. As we continue to apply the transition rules, the process converges to a statistical equilibrium with 75 mentally engaged students and 25 bored students. In that equilibrium, students continue to move between the two states but the number of students in each state 

---

does not change. If instead the process begins with all 100 students mentally engaged, the next day only 90 students will be mentally engaged. On the following day, that number falls to 84. If we continue to iterate the process, we find that in the long run 75 students will be mentally engaged and 25 students will be bored. The model attains the same statistical equilibrium. In our second example, we categorize countries into three states: free, partly free, or not free. Figure 17.2 shows the percentage of countries in each of the three categories over the thirty-five-year period ending in 2010 based on Freedom House data. The figure shows a clear trend toward increased democratization. Over the past thirty-five years, the percentage of free countries has risen by 20%. If that linear trend continues, by 2040 two-thirds of all countries would be free, and by 2080 eight out of nine countries would be free. A Markov model leads to a different prediction. To make the predictions, we set the length of a period to five years and loosely calibrate transition probabilities based on the past data (see table 

17.1).^1 

 Table 17.1: Markov Transition Probabilities for Democratization 

If we initialize the model using the percentages of countries in each category in 1975, the calibrated model (as we would expect) almost perfectly matches the 2010 distribution: 48% of countries are free, 31% are partly free, and 21% are not free. The actual percentages in 2010 were 46%, 30%, and 24%. If we continue to run the model, it predicts that in 2080, 62.5% of countries will be free, 25% partly free, and 12.5% not free. 

---

Figure 17.2: Freedom House: % Free, Partly Free, and Not Free The less rosy prediction of the Markov model stems from the fact that a linear projection fails to take into account that free countries can transition to being partly free and also to being not free. As more countries become free, the number of free countries becoming partly free increases. The reasons for this are manifold. For one, operating a democracy requires fiscal authority and institutions capable of implementing policies. To borrow the phrasing of Flores and Nooruddin, democracy may not easily take root in some places.^2 In those places, we should expect transitions from free to partly free. The Markov model captures these. 

---

### The Perron-Frobenius Theorem 

Both of our examples converge to unique statistical equilibria. That was not by chance. Any Markov model with a finite set of states, fixed transition probabilities between them, the potential to move from any state to any other in a series of transitions, and no fixed cycles between states converges to a unique equilibrium. The theorem implies that if those four assumptions are satisfied, the initial state, history, and interventions that change the state cannot change the long-run equilibrium. If nations move between dictatorships and democracies according to fixed probabilities, then interventions that impose or encourage democracies in some countries have no long-term effects. If fluctuations in dominant political ideologies satisfy the assumptions, then history cannot influence the long-run distribution over ideologies. And if a person’s mental state can be represented as a Markov model, then words of encouragement or supportive gestures have no long-run impact. 

---

## Perron-Frobenius Theorem 

 [[Perron-Frobenius Theorem]]

## The Sales-Durability Paradox 

[[The Sales-Durability Paradox]]

## Markov Decision Models 

[[Markov Decision Models]]

# 18. Systems Dynamics Models 

_The principles governing the behavior of systems are not widely understood._ 

 —Jay Wright Forrester 

In this chapter, we cover systems dynamics models.^1 These models analyze systems with feedbacks and interdependencies. They are used to model ecologies and economies, supply chains and production processes. They improve our capacity to think through logical chains that include negative and positive feedbacks. A systems dynamics model consists of sources, sinks, stocks, flows, rates, and constants. Sources produce inputs into the system. Sinks absorb outputs. Stocks keep track of levels of variables, and flows capture feedbacks between levels of stocks. Rates and constants apply to the flows, which can be fixed or change over time. Systems dynamics models can include both positive and negative feedbacks. Positive feedbacks, such as the Matthew effect covered in Chapter 6 , occur when an increase in a variable or attribute produces an additional increase in that same variable. Success breeds success, sales lead to more sales, and, in the case of academic papers and patents, citations generate more citations. Negative feedbacks dampen trends. We must be careful not to infer normative implications from the word _negative_. Negative feedbacks often produce desirable properties. They can prevent bubbles and crashes. When we eat, our brain receives signals to stop eating. When a company’s profits increase beyond normal economic returns, competitors enter, reducing those profits and preventing the company from exploiting customers. When a species 

---

proliferates, its members compete for food, reducing population growth. In each case, negative feedbacks contribute to system-level robustness. Using systems dynamics models, we can often identify the causes of complexity. When a system includes both positive and negative feedbacks, it can produce complexity. That was true of the Game of Life in which existing cells caused new cells to come to life but overcrowding caused cells to die. 

Figure 18.1: The Components of Systems Dynamics Models Systems dynamics models that represent flows and stock levels as mathematical functions can be calibrated to explain past values of stocks, to predict future values, and to estimate the effects of an intervention. We can then use the models to explain, predict, and guide action. Systems dynamics models can also be qualitative. We 

can label each arrow with a plus or a minus to clarify logic.^2 The remainder of the chapter consists of five parts. To introduce terminology, we build a qualitative model of a bakery. We then construct a predator-prey model based on the Lotka-Volterra equations. Our version assumes interacting populations of foxes and hares and embeds both negative and positive feedbacks. We next show how by using systems dynamics models we can anticipate vicious cycles. We then describe the WORLD3 model, a large model of the global economy. We conclude with a discussion of how systems dynamics models often produce counterintuitive results, which demonstrates the limits of human reasoning and the value of models as logical aids. 

---

### The Parts of a Systems Dynamics Model 

A _systems dynamics model_ consists of sources, sinks, stocks, and flows. A _source_ produces a _stock,_ the amount or level of some variable. A _flow_ describes how the level of a stock changes. A _sink_ catches the output of a flow from a stock. Sinks and sources are placeholders for processes not included in the model. The level of a stock changes over time based on sources and flows. In a systems dynamics model of an amusement park, for example, the number of people at the park (a stock) increases as people arrive (a source). The rate of increase could in turn depend on other parameters such as the weather, the amount of advertising, or the price of admission. 

Figure 18.2: A Systems Dynamics Model of a Bakery Systems dynamics models use the representational system shown in figure 18.1. Sources and sinks are represented by clouds. Stocks are represented by boxes, and flows by arrows identified by a plus or a minus sign. Variable flows are represented by inverted triangles and constant flows by circles bisected by the flow arrow. A positive arrow represents a positive feedback, where more begets more. A negative arrow represents a negative feedback from one variable to another. To build familiarity, we first construct a basic systems dynamics model of a bakery that consists of a baker, bread, and customers. The baker makes bread and customers buy it. If the rate at which the baker produces bread exceeds the rate at which customers purchase bread, the stock of bread grows, and the bakery fills with bread. Alternatively, if the rate of sales exceeds the baker’s production rate, the bakery will perpetually sell out. To make the model more realistic, we can allow the baker to adjust the rate of bread production as a function of the stock of the bread as shown in figure 18.3, which includes a flow (an arrow) from the stock of bread 

---

to the rate at which the baker produces bread. We place a negative sign on the arrow to denote that the rate decreases as the stock of bread increases. If the adjustment rate is set properly, the model will produce an equilibrium where the rate at which loaves are baked equals the rate at which customers buy bread so that inventories equilibrate. To make the model even more realistic, we can add a second stock, _line,_ that equals the number of people waiting outside the bakery, as well as a second source, _potentials,_ which adds people to the line. A short to moderate line may attract customers, while a long line could turn customers away. To capture the variable effect of the length of the line on the rate of arrival from the source, we write (+ _/_ −) above the arrow. We also include a plus sign above the arrow from the stock of line to the rate at which customers buy bread, assuming that with more people in line, people decide faster. 

Figure 18.3: A More Elaborate Model of the Bakery This model could be calibrated to data. We could estimate the rates at which people join the line based on its length. The baker could then determine an optimal rate of adjustment for baking as a function of the stock of bread and the length of the line. That rate would provide a starting point from which a better rate might be learned. Even without calibration, the act of writing the model adds value. The baker realizes the importance of line length to his overall sales. 

---

### The Predator-Prey Model 

We now introduce the _predator-prey model,_ an ecological model that captures the relationship between the number of hares (the prey) and the number of foxes (the predator). The model include two positive feedbacks: hares produce hares, and foxes produce foxes. It also includes a negative feedback: foxes eat hares. The model assumes that if the level of hares is high, foxes produce more offspring. Figure 18.4 qualitatively represents these assumptions but does not quantify the relationships. From the figure we see that as the number of foxes increases, the number of hares decreases, which in turn results in fewer foxes. As the number of foxes falls, hares should proliferate, leading to more foxes. The logic suggests the possibility of a cycle, or perhaps an equilibrium. We cannot be sure. To gain insight into what occurs, we need to construct a quantitative version of the model. We assume linear flows that depend on the stock levels. Absent any foxes, the number of hares grows at a fixed rate, and absent any hares, the number of foxes decreases at a fixed rate owing to a lack of food. The model will assume that the probability of a hare and a fox meeting is proportional to the number of foxes times the number of hares. To capture foxes eating hares when these interactions occur, we assume that foxes grow at a constant rate times that product and that hares decrease at a constant rate times that product. The resulting equations are known as the _Lotka-Volterra equations_. 

 Figure 18.4: A Systems Dynamics Model of the Predator-Prey Model 

---

## Lotka-Volterra Model 

 [[Lotka-Volterra Model]]

# 19. Threshold Models with Feedbacks 

_Integration of racial, ethnic, and other groups that mark significant lines of social inequality is a vital ideal for a democratic society._ 

 —Elizabeth Anderson 

In this chapter, we cover models of threshold-based behaviors. Threshold-based behavior occurs when people’s actions change when an external variable exceeds or falls below a threshold. Threshold-based behavior occurs when a person buys a coat when the price falls below $100 or joins a social movement when its membership reaches 1,000 people. Threshold-based behavior is intuitive and easy to analyze, and it often produces counterintuitive results, such as when tolerant behavior produces segregation. Threshold-based models can often produce tipping points. For example, when a person’s decision to join a social movement depends on the number of people already in the movement, as more people join the movement the total number of participants is more likely to exceed other people’s thresholds to join, creating a tip. The models in this chapter can be classified as _agent-based models_ —computer programs that model each agent individually. Agent-based models allow for more granularity than systems dynamics models, which represent an entire population by a single stock variable. Agent-based models position agents in space and can include behavioral diversity. Those added degrees of freedom offer advantages, but we must keep in mind that too much detail undermines some of our reasons for modeling. We should not, for example, model each neuron in a person’s head when building a model of how people choose whether to join a social movement. The 

---

optimal level of granularity will depend on the purpose of the model. The chapter begins with Granovetter’s model of riots, followed by a double riot version that models the growth process for start-ups. We then cover two segregation models. The first considers people moving between rooms at a party. The second considers segregation at the scale of cities. Next we introduce the ping-pong model, which includes negative feedbacks and can produce a cycle or an equilibrium. In the discussion at the end of the chapter, we again return to the Game of Life and see how the double-threshold rule creates a combination of positive and negative feedbacks. Positive feedbacks create correlated behaviors that negative feedbacks dampen. We also return to the topic of model granularity. 

---

### Granovetter’s Riot Model 

In a threshold-based model, an individual takes one of two actions, depending on whether an aggregate variable exceeds a threshold. If the variable’s value exceeds the threshold, the individual takes one action. Otherwise, she takes the other action. Our first model captures riots and social movements. In it, each person makes a choice to either join the riot or hang back. The decision hinges on the number of people involved in the riot. The model does not take a normative position. The social movement or uprising could be a justifiable revolt against a despot or soccer hooligans destroying property. The model applies to both cases. The _riot model_ assigns each person a threshold. A person joins the riot when the number of joiners exceeds that threshold.^1 Initially, only those who have a threshold of zero join. For the purposes of this discussion, we assume a social movement rather than a riot, so in this case joining may involve standing in a central square or marching. Suppose that on the first day, 200 people with a threshold of zero start a movement. On day two, those 200 people continue to protest, and they are joined by those whose participation threshold lies below 200. If this consists of an additional 500 people, then on day three, people with thresholds above 700 join. This could be several thousand people. 

---

## Riot Model 

 [[Riot Model]]

## Schelling’s Party Model 

 [[Schelling’s Party Model]]

## Schelling’s Segregation Model 

 [[Schelling’s Segregation Model]]

## Ping-Pong Model 

 [[Ping-Pong Model]]

## Algorithmic Riots 

[[Algorithmic Riots]]

# 20. Spatial and Hedonic Choice Models 

_Our theory is, if you need the user to tell you what you’re selling, then you don’t know what you’re selling, and it’s probably not going to be a good experience._ 

 —Marissa Mayer 

In this chapter, we cover models of individual choice over alternatives represented by their attributes. These models were developed to capture consumer choices. A person buying a house takes into account its square footage, the number of bedrooms and bathrooms, and the quality of construction. These can also be applied to college deans of admissions or hiring directors as they select among applicants or to voters as they decide between candidates. An admissions dean considers an applicant’s SAT scores, grade point average, and extracurriculars. A voter evaluates candidates based on their positions on education, infrastructure, crime, and taxes. In addition to helping us understand individual choices, these models provide insights into why we have the choices we do—for example, why we have so many choices of breakfast cereals. In the models we cover, we characterize some attributes as _spatial_ and others as _hedonic_. A spatial attribute, such as the color of a jacket or the thickness of a slice of bread, has no best value. Each individual prefers a particular amount of the attribute: a consumer of baby back ribs has a preferred level of spiciness, and an amateur downhill skier has a preferred angle of descent on a slope. The model assumes that the closer a product’s attributes are to a person’s ideal point, the more the person values the product. These 

---

ideal points vary across people: one person may prefer spicier ribs than another. On hedonic attributes, more (or in some cases less) is always better. People prefer longer battery life in a smartphone, more square footage in a house, more durability in the soles of shoes, and better gas mileage in their cars. Most product choices are hybrids— they contain both spatial hedonic attributes. A car’s color will be a spatial attribute. Its gas mileage is a hedonic attribute. Throughout the chapter, we assume that people choose the alternative that they value the most. We do this for reasons mentioned in Chapter 4 , on modeling human behavior: rational behavior provides a benchmark, is analytically tractable, makes a unique prediction, and fits empirically when the situation is repeated and the stakes are large. Models of spatial and hedonic competition are widely used in economics and political science in part because they can be taken to 

data.^1 In this chapter, we get a hint of their applicability. We begin with a spatial model of product competition. We then apply the model to politics and show how it can be used to analyze status quo effects, agenda power, and the influence of veto players. We then cover the hedonic attribute model and a hybrid model to reveal insights into price competition. Along the way, we show how to take data to the models to infer the positions of candidates and judges based on their votes on bills and legal cases and to infer implicit prices for unpriced attributes such as cleaner air or a shorter commute.^2 

---

### The Spatial Competition Model 

The _spatial competition model_ assumes alternatives defined by a set of attributes and consumers defined by ideal points. The simplest version of the model considers products with a single attribute. In Hotelling’s original spatial model, that attribute was geographic location.^3 

Figure 20.1: Hotelling’s Geographic Model of Ice Cream Vendors on a Beach Hotelling’s model assumes a collection of consumers spread along a beach, represented by circles in figure 20.1, along with two ice cream vendors, denoted by _A_ and _B_. Each customer buys one ice cream from the nearer vendor. The _cut point_ is an equal distance between the two vendors and determines who buys from whom. The seven consumers to the left of the cut point buy from vendor _A_ , and the six consumers to the right of the cut point buy from vendor _B_. Given the idea of consumers preferring closer goods, we can reinterpret distance more abstractly. For example, we could imagine the ice cream vendors being in the same location but offering different levels of butterfat in their ice cream. The same figure can represent vendor _B_ offering a creamier product than _A_. In the reinterpretation, the consumers’ locations are not physical position on the beach but preferred levels of butterfat. We can again apply one-to-many model thinking and use this same model to analyze political competition. The _Downsian model_ reinvents Hotelling’s geographic space as an ideological continuum from left to right. We can reinterpret figure 20.1 as follows: vendor _A_ 

---

represents a liberal political candidate, vendor _B_ a more conservative candidate, and the circles represent the ideological ideal points of voters. To extend the analogy, we assume voters prefer nearer candidates. The shift from geographic locations of firms and product attributes to political ideologies involves a transition from physical attributes such as location and butterfat level to the more abstract concept of ideology. While we have clear measures of physical attributes, assigning ideologies requires a method for translating the actions of candidates into numbers. If the candidates have voting records, we can assign ideologies by first gathering all of the votes the candidate has cast. We should ignore all votes that lack an ideological component—unanimous proclamations establishing National Milk Day and the like. On all other votes, we can rely on expert opinion to assign a liberal position and a conservative position. A candidate’s spatial location on the interval can be set equal to the percentage of 

the time she votes the conservative position.^4 A candidate who always takes the conservative position is placed to the far right. A candidate who votes conservative half of the time and liberal half of the time is placed in the center. With this model, we can adjudicate claims that American political parties have become more ideologically distinct by empirical tests. One analysis, shown in figure 20.2, reveals a marked and increasing polarization of the average ideal points in each party. This does not prove that polarization has increased, but it provides evidence. The analysis also reveals that the polarization is mostly due to a Republican shift to the right. 

 Figure 20.2: Increasing Ideological Polarization in Congress 

---

### Increasing the Number of Attributes 

The general spatial competition model includes an arbitrary number of attributes. A couch can be represented by physical dimensions: length, width, and depth, type of construction, and type of upholstery. The value (or utility) that a consumer obtains from a product depends on the product’s distance to her ideal point across these same dimensions. We can write this value function as a constant term minus the distance between the alternative and her ideal point.^5 

---

## Spatial Competition Model 

 [[Spatial Competition Model]]

## Hedonic Competition Model 

 [[Hedonic Competition Model]]

## Many Models of Value 

[[Many Models of Value]]

# 21. Game Theory Models Times Three 

_Deductive reasoning travels from the most abstract to the least abstract. It begins with a set of axioms and uses the laws of logic and mathematics to manipulate them to form predictions about the world._ 

 —Rachel Croson 

Game theory models strategic interactions. Many of the models that follow, including our models of cooperation, signaling, mechanisms, and collection action, involve games. We do not take up the analysis of games in much depth because entire books are devoted to the subject. Our goal will be to provide a gentle introduction. To that end, we present examples of the three main classes of games: normalform games, in which players choose from a discrete set of actions (typically two); sequential games, in which players choose actions sequentially; and continuous-action games, in which players can choose actions of any magnitude or effect size. These examples introduce the main concepts, help us to understand later models, and add value in their own right. The remainder of the chapter has four parts. We begin by covering 2-by-2 zero-sum games. In a zero-sum game, each of two players chooses among two actions. No matter what actions the players choose, the amount won by one player is exactly offset by the losses of the other. We use zero-sum games to define the basic terminology of game theory, to distinguish between strategies and actions, and to introduce the concept of iterated elimination of dominated strategies. We then study the Market Entry Game, a sequential game, in which an entrant competes against an existing 

---

firm, and we replicate that game many times to create what is known as the chain store paradox. In the third part, we consider an effort game in which individuals choose effort levels to win a prize of a fixed amount. Increasing effort improves a player’s chances of winning the prize. The chapter concludes with a brief discussion of the value of game theory models generally. 

---

### Normal-Form Zero-Sum Games 

In this section we analyze two-player _normal-form zero-sum games_. In both games, each player chooses an action and receives a payoff that depends on the player’s own action and the other player’s action. In addition, the players’ payoffs sum to zero. In the first game, _Matching Pennies_ shown in figure 21.1, each player chooses one of two actions: heads or tails. The row player wants to match the other player’s choice, and the column player wants to mismatch. Payoffs are shown in the matrix below: 

Figure 21.1: The Matching Pennies Game A strategy is a rule for how to play the game. It could be a choice of a single action, a randomization between actions, or, as we see in the next section, a sequence of actions. A _Nash equilibrium_ of a game is a pair of strategies such that each player’s strategy is optimal given the strategy of the other player. In Matching Pennies, in the unique equilibrium strategy both players randomize equally between the two actions. To prove randomization is an equilibrium, we need to show that if each player randomizes, the other player cannot do better than randomizing. This is straightforward. If the row player (actions and payoffs in bold) plays heads with probability and tails with probability , then the column player earns zero regardless of her action. Therefore, randomizing is also an optimal strategy for the column player. By symmetry, randomization is optimal for the row player as well. This optimality of randomization has implications for behavior in strategic settings. Sports are zero-sum: one team (or player) wins and one loses. During penalty kicks, a striker wants to randomize 

---

between aiming for the left or right corner. In tennis, a server wants to randomize serving to the inside or outside. On fourth and goal in football, an offense wants to randomize between run and pass. In each case, the opponent also wants to randomize their planned responses. Any non-randomness can be exploited. The same holds in card games such as poker. A good poker player bluffs randomly. If she always bluffed, her opponents would learn her strategy and stay in the game. She would then lose every time she bluffed. Similarly, if she never bluffed, her opponents would learn to fold. Optimal bluffing makes her opponents uncertain whether to stay or fold. In our second game, the _Minimize Risk Game_ shown in figure 21.2 each player can take a risky action or a safe action. This is an asymmetric zero-sum game. The payoffs depend not just on the actions but also on which player takes which action. In this game, the row player has a _dominant strategy_ to play safe. No matter what action the column player chooses, the row player earns a higher payoff by choosing safe. The column player does not have a dominant strategy. If the row player chooses risky, the column player should choose risky. If the row player chooses safe, the column player should choose safe. 

Figure 21.2: The Minimize Risk Game By thinking through the incentives for the row player, the column player can deduce that the row player will never choose risky because risky is dominated by safe. Therefore, the column player knows that the row player will choose safe. Given that, the column player should also choose safe. This type of reasoning in which one player rules out dominated strategies for the other player is known as _iterative elimination of dominated strategies_. In this game, using iterative elimination of dominated strategies shows that both players 

---

choosing safe is the unique Nash equilibrium. 

---

### Sequential Games 

In a _sequential game,_ players take actions in a specific order, as shown on a _game tree,_ which consists of nodes and edges. Each node corresponds to a moment when a player must take an action. Each edge from that node denotes one of the possible actions. At the end branches of a game tree, we write the payoffs associated with following that path of actions. The game tree in figure 21.3 shows the Market Entry Game. 

Figure 21.3: The Market Entry Game The _Market Entry Game_ involves two players: a potential entrant and an existing firm. If the entrant chooses not to enter the market (the left branch of the tree), it earns no payoff and the existing firm earns a profit of 5. If the entrant enters the market, the existing firm must choose between accepting the new entrant and seeing its profits fall from 5 to 2 or competing with the new firm and driving its profits to zero and the entrant’s profits negative. We assume the entrant’s profits to be negative because it has to pay for the cost of entering. In a sequential game, a strategy corresponds to an action choice at each node. Suppose that the existing firm chooses to compete if the entrant enters. If the entrant knows this, the entrant would not enter, as doing so would produce negative profits. This set of actions, the entrant choosing to not enter and the existing firm planning to compete if the entrant did enter, are a Nash equilibrium. However, this is not the only Nash equilibrium, nor is it the most likely outcome. There is a second equilibrium in which the entrant chooses to enter the market and the existing firm accepts the entrants move and does not compete. 

---

To select among these two equilibria, we apply a refinement criterion. In sequential games, a common refinement chooses the _subgame perfect equilibrium_. We solve for the subgame equilibrium using _backward induction_ : we start at the end nodes and choose the optimal action at each. We then work backward up the game tree assuming that each player chooses the best action given the actions of the other player at subsequent nodes. In the Market Entry Game, we start at the end node for the existing firm. It has an optimal action: to accept. We then move up the game tree and see that the entrant has an optimal strategy to enter. This game becomes even more interesting when replicated. Imagine that the firm exists in many markets. Perhaps it is a chain store with franchises in dozens of cities. Suppose also that there exists a sequence of potential entrants. The firm is going to play one Market Entry Game after another in sequence. If the firm reasons using backward induction starting from the last market, it will accept the entrant in that last market, as that is the payoff maximizing action. Continuing with the same logic, the firm will accept the second-to-last entrant. It will also accept every other entrant. It follows that in the unique subgame perfect equilibrium of the sequence of games, all of the potential entrants choose to enter, and the firm accepts all of them. Though entrance and acceptance in every market is the unique subgame perfect equilibrium. In practice, it may not occur. Imagine we are on the board of directors of the existing firm and we are confronting the first entrant, who (having studied game theory) enters the market. We may want to compete to try to deter entry in the other markets. Competing would be an intelligent strategy if it is credible, that is, if we can build a reputation as willing to compete. The outcome we hope to create differs from the subgame perfect equilibrium. Game theorists refer to the disconnect in this game between what game theory predicts and what actual players would try to produce as the _chain store paradox._ It is one example where what game theory considers to be optimal behavior may not be the behavior chosen by a sophisticated player when the stakes are large. The 

---

example does not disprove game theory or undermine the rational choice assumption, so much as it reveals why we must always challenge assumptions. 

---

### Continuous Action Games 

We now study a game in which players choose from a continuum of possible actions. In the game, actions correspond to effort levels. By choosing greater effort, a player increases her probability of winning a prize. This game allows us to model any number of players. The derived expression for equilibrium effort reveals a number of insights. As we would expect, individual effort increases with the size of the prize. Also, in equilibrium, total effort will be less than the value of the prize. That too would be expected given that we assume players optimize. Players should put forth effort to win, but not an unreasonable amount. 

---

## The Effort Game 

 [[The Effort Game]]

## The Identification Problem 

[[The Identification Problem]]

# 22. Models of Cooperation 

_No one has ever become poor by giving._ 

 —Anne Frank 

Experts asked to name the most important scientific questions produce a limited set of responses: How did the universe form? How does consciousness emerge? Can we find a cure for cancer? One question experts identify spans the social and biological sciences: How does cooperation arise?^1 Cooperation entails taking an action that is not in one’s self-interest, which suggests that we should not expect to see much of it. And yet we see cooperation in myriad domains and at multiple scales. Cells cooperate through adhesion, where one cell produces extracellular material to which others can attach. We see cooperation among ants, bees, humans, organizations of humans, and even nations, which cooperate in the creation of treaties and international laws. In this chapter, we use models to take up the questions of how cooperation emerges, how it is maintained, and how we might create more of it. These models cannot explain in full the variety of cooperation that exists in the world—why ravens share their discoveries of carrion, why naked mole rats collectively defend against predators, why climbing vines lay down fewer roots when planted adjacent to kin, why termites and bees build elaborate nests, and why ants lock appendages to form bridges for the carrying of 

food—but they will produce insights.^2 Although we see many examples of cooperation within and across species, we also see failures. The extent of cooperation depends on the circumstances. Federations gain and then lose 

---

members; Britain participated in the creation of the European Union and then exited from it. The same people who volunteer labor for a school fundraiser may cut in line at the supermarket or cheat on their taxes. A lion who hunts water buffalo in a pack may secrete away a warthog kill. And not every species cooperates. The roots of black walnut trees release juglone, an herbicide, into the soil, to inhibit the growth of nearby plants. The diversity of behaviors of cooperating entities—cells, roots, ravens, people, business firms, and nations—obliges a many-model approach. We might best model cells and plants as following fixed rules; ravens, ants, and lions as using more rules that condition on the environment or on past outcomes; and people, business firms, and nations as looking ahead and performing cost-benefit calculations. The first key takeaway from this chapter will be that cooperation can emerge and be maintained through a variety of mechanisms. We highlight four mechanisms that enable cooperation: _repetition, reputation, local clustering,_ and _group selection_. These mechanisms all enable cooperation without external intervention or management. They can apply to cooperating mole rats, bees, and humans alike. Humans also have other more formal ways to induce and maintain cooperation. In the discussion at the end of the chapter, we describe institutional solutions such as paying people to cooperate, punishing them if they do not, and legally mandating cooperative behavior. The second takeaway will be that the efficacy of any one of these mechanisms depends on the behavioral repertoires of those cooperating. Some mechanisms, notably repetition, work for almost any behavior. Reputations and norms require forward-looking behavior and information sharing. They will be most effective for more sophisticated actors. The effect of clustering, on the other hand, depends on the model. Cooperation among actors who are selected for or against by evolutionary forces emerges most often on sparse networks. Cooperation through norms requires dense networks. The efficacy of group selection depends in a nuanced way on the ability of the actors to be forward-looking and on their speed of adaptation. 

---

Making actors more forward-looking enhances the power of group selection. Allowing them to adapt more quickly can hinder it. To explore these questions and to unpack the interplay between behavioral assumptions and cooperation, we rely on the familiar Prisoners’ Dilemma game as well as a cooperative action model. The second model allows us to capture actions that benefit multiple players as well as to model cooperation on networks. The remainder of the chapter takes the following form. We begin with a description of the Prisoners’ Dilemma and show how cooperation can be maintained among rational actors. We then show how repetition also can induce cooperation between rule-based actors and why evolving cooperation is more difficult than maintaining it. We then consider less sophisticated biological actors and show how kin selection and local clustering can promote cooperation. The last two sections cover group selection and the question of how we use these models to produce more cooperation. 

---

### The Prisoners’ Dilemma 

The name _Prisoners’ Dilemma_ derives from a story of two people accused of jointly committing a crime. The authorities have circumstantial evidence so they offer each person a chance to confess. The accused confront a dilemma. If neither confesses, each receives a minor sentence based on the evidence. If only one confesses, then that person receives no punishment while the other is punished severely. If both confess, both receive harsh punishment, though not as extreme as in the case where only one confesses. Figure 22.1 represents this story as a two-player game. Each player can either _cooperate_ (C) or _defect_ (D). The gray numbers represent the payoff to the column player and the black numbers the payoff to the row player. Each player has a dominant strategy to defect: whatever the action of the other player, defecting produces a higher payoff. However, if both players defect, each receives a lower payoff than if both cooperated. Thus, self-interest leads to actions that are collectively worse. 

Figure 22.1: An Example of a Prisoners’ Dilemma Game The Prisoners’ Dilemma captures the core incentives of many real-world contexts. It can model the arms race between the United States and the former Soviet Union, where defecting corresponds to spending money on weapons and cooperating to economic development. It can model political campaigning and whether to go negative (defect) or to run positive campaign ads (cooperate). It can even explain why male peacocks have such long tails: each peacock has an incentive to appear stronger and more robust than the others. Some instances of the Prisoners’ Dilemma can only be 

---

recognized after the fact. The first adopters of many technologies, such as banks that moved early into ATM machines, saw their profits increase. When others followed, profits fell from increased competition. Choosing to put in ATM machines proved to be an 

analog of the choice to defect.^3 

Figure 22.2: The Prisoners’ Dilemma The general form of the Prisoners’ Dilemma, shown in figure 22.2, assumes a baseline payoff of zero if both players defect. The game can then be expressed with three variables: a _reward_ , _R_ , from cooperating, a _temptation_ , _T_ , to defect, and a _sucker’s payoff_ , _S_ , from being exploited (see box). The inequalities shown in the box ensure that choosing defect is a dominant strategy and cooperating produces the efficient outcome. 

---

### Cooperation Through Repetition and Reputation 

We first show how repetition of the game and the building of reputations can maintain cooperation among rational actors. The fact that cooperation can be maintained does not guarantee that it will be realized; it says only that if cooperation happens to emerge, rational players can sustain it. To prove that repetition maintains cooperation, we construct a _repeated game model_ in which after each play of the game, with probability _P_ , the game will be played again. In theory, play could go on forever. The players apply repeated game strategies, which give an action based on the history of past play. Here we consider a repeated game strategy known as _Grim Trigger,_ which cooperates in the first play of the game and cooperates in any future play of the game so long as the other player has never defected. If the other player ever defects, Grim Trigger defects forever. It is unforgiving. If both players use the Grim Trigger strategy, both cooperate forever. To prove Grim Trigger maintains cooperation in the repeated game, we need only show that if one player chooses Grim Trigger, then the other player receives the highest possible payoff by also playing Grim Trigger. Given that a deviation by the second player produces endless defection by the first player, the second player need only compare the expected payoff from always cooperating to the expected payoff from the one-time benefit of defecting plus the payoff when both players defect thereafter.^4 Whether of not Grim Trigger produces the higher payoff depends on the extent of temptation, the reward from cooperating, and the probability that the game repeats. 

---

## Repetition Maintains Cooperation 

 [[Repetition Maintains Cooperation]]

## Connectedness and Reputation 

[[Connectedness and Reputation]]

## Cooperative Action Model 

 [[Cooperative Action Model]]

## Clustering Bootstraps Cooperation 

[[Clustering Bootstraps Cooperation]]

# 23. Collective Action Problems 

_Managing environmental resources sustainably has always been difficult, ever since_ Homo sapiens _developed modern inventiveness, efficiency, and hunting skills by around 50,000 years ago._ 

 —Jared Diamond 

In this chapter, we cover _collective action problems_ : situations in which self-interest does not align with the collective interest. These problems arise in matters small and large. At airports, travelers individually benefit by standing as near as possible to the baggage carousel, but collectively everyone would be better off if people stood back a few feet. In a democracy, people have little incentive to become informed voters given the very low probability of a single vote turning an election, yet a democracy performs better with an informed citizenry. Collective action problems can be thought of as many-player Prisoners’ Dilemmas: each person has an incentive to defect, but collectively, everyone does better by cooperating. People often study collective action models in the context of historical examples such as the management of the Scottish commons or the lobster habitats along the coasts of Newfoundland and Maine.^1 History also contains dramatic failures. Among the most famous is the collapse of the Polynesians on Easter Island, 

described by Jared Diamond.^2 Easter Island lies over two thousand miles west of Chile in the South Pacific, with no other inhabitable island within a thousand miles in any direction. Given that location, Easter Islanders have always had to manage for themselves. For over a thousand years they lived well. Some estimate that by the early seventeenth century, Easter Island’s population exceeded 

---

fifteen thousand people. In the sixteenth century, the Easter Islanders marshaled sufficient resources to free up labor to build giant stone heads, called _maoi,_ that weigh up to eighty tons. While the Easter Islanders were busy constructing maoi, they were not cooperating in the management of their forests. By 1722, when Europeans first landed on the island, food was relatively scarce and the population had dropped to around two thousand. Few trees over ten feet tall remained. Many species of birds and animals had gone extinct. To use Diamond’s phrasing, the civilization collapsed. The collapse became complete when viruses carried by the Europeans killed nearly all of the remaining population. According to Diamond’s account, the collapse of the civilization on Easter Island, as well as the collapses of the Mayans in Central America, the Anasazi in the American Southwest, and the Vinlanders on Greenland, resulted from a combination of overharvesting of natural resources (caused by institutional and cultural failures) and climatic changes. The Vinlanders grazed animals on marginal land and tore up fragile sod to make houses. In short order, the land became barren from overuse, and the Vinlanders starved. Like the Easter Islanders, the Vinlanders had failed to manage a common pool resource. By chopping down too many trees and using up too much turf, they produced a collapse. Though evocative and compelling, these examples lead many to see collective action problems as something of relevance only in the past. That framing is unfortunate. As the world becomes more interconnected and complex, collective action problems are far more relevant today. We confront collective action problems at almost every scale of human organization. The provision of public education, physical and mental health care, infrastructure, public safety, a justice system, and national defense are all collective action problems, as are managing global fisheries, combating climate change, and in particular reducing the amount of carbon in the atmosphere. In addition, as work becomes more team-based, it necessarily produces collective action problems. Workers have incentives to free ride on the work of others. They also have incentives to overdemand shared workspaces to ensure space for 

---

their teams to work. The chapter is organized as follows: We first define a generic collective action problem, and then analyze three specific types. We start with public goods provision problems, in which individuals contribute money to fund roads, schools, and social services or time and effort to clean a park or watershed. We then study congestion problems, where individuals must restrict use of a resource such as a road system, beach, or park. We finish with renewable resource extraction problems, where individuals consume a resource that can regrow, such as fish, lobster, and trees. Congestion problems reset each day. If too many cars clog London’s streets, the city can increase the fee on cars entering the city and solve the problem, and so past overuse has no long-term effects. However, an overharvested forest or fishery takes decades to regrow. We pay consequences for past failures to cooperate. In each of the three specific models, the nature of the misalignment between individual incentives and collective goals differs, so solutions differ as well. We can solve public goods problems through taxes, and in some cases through sorting. Congestion problems can be solved with fees or usage restrictions. Solving renewable resource problems requires more elaborate monitoring and sanctions as well as conflict resolution mechanisms. The solutions we offer here provide foundational insights that must be tailored to a local context. Any real-world situation includes layers of complexity that our models leave out. Balinese water temples solve a water allocation problem that is a sequential congestion problem, with upriver people drawing the resource first. International fishing rights that limit access solve a common pool resource problem with a moveable resource, as Norway’s solution to coastal fishing could be undermined by overfishing in the nearby 

waters of Sweden, Russia, and Denmark.^3 Real-world solutions rely in part on the mechanisms discussed in Chapter 22 for building cooperation in the Prisoners’ Dilemma: repetition, reputation, network structure, and group selection. Group selection enters indirectly: communities and nations that succeed in solving these 

---

problems will thrive, and their successes will be copied by others. 

---

### Collective Action Problems 

In a _collective action problem,_ each person has a choice between contributing and free riding. Free riding is in the individual’s best interest. It earns her a higher payoff. Yet when everyone contributes, people receive greater benefits. 

---

## A Collective Action Problem 

 [[A Collective Action Problem]]

## A Public Good Provision Problem 

 [[A Public Good Provision Problem]]

## Public Good Provision Among Altruists 

 [[Public Good Provision Among Altruists]]

## A Congestion Model 

 [[A Congestion Model]]

## Multiple Congestible Goods 

 [[Multiple Congestible Goods]]

## Renewable Resource Extraction Model 

 [[Renewable Resource Extraction Model]]

# 24. Mechanism Design 

_Institutions are designed to alter human behavior. To remain effective over time, institutions need to adapt to changes in the environment or the society the institution is meant to regulate._ 

 —Jenna Bednar 

In this chapter, we show how to use models to design political and economic institutions. An institution consists of a means through which people communicate information as well as a procedure for making decisions, reallocating resources, or producing outputs based on the information revealed. In markets, people and firms communicate through prices to execute trades and make production decisions. In hierarchies, people communicate through written language to organize work plans. And in democracies, people communicate preferences through votes. Voting rules then decide policies. Well-designed institutions induce communications and actions that produce desirable outcomes. Ineffective institutions do not. In this chapter, we present a framework for modeling institutions known as _mechanism design_. This framework highlights four aspects of real institutions: _information,_ what the participants know and should be revealed to them; _incentives,_ the benefits and costs of taking particular actions; _aggregation,_ how the individual actions translate into collective outcomes; and _computational costs,_ the cognitive demand placed on participants. The origins of mechanism design lie in the analysis of general questions about the allocation of goods, and in particular whether market mechanisms or central planning best allocates goods. Early 

---

models posited behavioral rules such as price-taking in a market or voting truthfully. The modeler then worked through the implications of those behaviors, for example, how they aggregated. That approach was abandoned in favor of one that assumed optimizing behavior, making the constructions amenable to game theoretic reasoning. Mechanism designers then solve for Nash equilibria and compare institutions based on rational behavior. The framework has proved useful. It can be used to find flaws in existing rules and procedures, to explain why institutions succeed or fail, and to predict outcomes. It has also been used to design a variety of institutions, including the spectrum auctions described in Chapter 2 , as well as many online markets, governmental voting systems, and even the procedures that allocate space for projects on 

space shuttle voyages.^1 Our treatment consists of six parts. We first describe the mechanism design framework using the Mount-Reiter diagram. In the second part, we study the problem of three people choosing between two alternatives. In the third part, we analyze three auction mechanisms and find that all yield identical results. In the fourth part, we show that this was not a coincidence and describe a foundational result, the revenue equivalence theorem, which shows that any auction mechanism that satisfies certain assumptions produces the same outcome. In the fifth part, we compare a majority rule voting mechanism with a pivot mechanism as ways to decide on whether to undertake a public project. We conclude by broadening our discussion of mechanisms along the lines introduced in our criticism of Nash equilibria. 

---

### The Mount-Reiter Diagram 

A mechanism consists of six parts: an _environment_ (the relevant features of the world), a set of _outcomes,_ a set of _actions_ (called the _message space_ ), a _behavioral rule_ that people follow to produce actions, an _outcome function_ that maps the actions into outcomes, and a _social choice correspondence_ that maps the environment into a set of hoped-for outcomes. The social choice correspondence commonly consists of either the outcome that maximizes the sum of the participants’ utilities or of the set of _Pareto efficient_ allocations. An outcome is Pareto efficient if and only if no other outcome exists that everyone prefers. Pareto efficiency is a low bar. 

---

## Pareto Efficiency 

 [[Pareto Efficiency]]

## Revenue Equivalence Theorem 

 [[Revenue Equivalence Theorem]]

## A Public Project Decision Problem 

 [[A Public Project Decision Problem]]

## Majority-Vote Equal Sharing 

 [[Majority-Vote Equal Sharing]]

## The Pivot Mechanism 

 [[The Pivot Mechanism]]

# 25. Signaling Models 

_Honest people don’t hide their deeds._ 

 —Emily Brontë 

In this chapter, we study _signaling models_. These models identify conditions under which people send costly signals to reveal information or their type. A person might signal wealth by purchasing an expensive piece of art, physical stamina by climbing a mountain, or empathy by posting support for causes on social media. Signaling to reveal status has always been a part of human nature. In the nineteenth century, Thorstein Veblen refined our understanding of signaling with his development of the concept of conspicuous consumption: he observed that rather than buy goods that bring direct enjoyment or practical utility, people often make choices to signal their social status. Veblen would take delight in our modern icons of conspicuous consumption, such as the Maybach Landaulet, an automobile that retailed for nearly $1.5 million, ten-year-old bottles of Cristal that sell for over $1,500 a bottle, and Leica cameras that sell for tens of thousands of dollars. Conspicuous consumption endures because we care what others think of us, and what we consume signals our status to others.^1 We do not see others in their entirety, so we rely on what they wear, drive, and consume to make inferences about their hidden attributes. If we see someone driving an expensive car, we can infer that she has wealth. A person donating to a charitable organization signals generosity—no selfish person would take such an action. A person announcing her PhD in theoretical biology on social media signals her intelligence and work ethic. Almost all actions have some degree 

---

of signaling. When politicians vote whether to go to war or to impose sanctions on another country, they signal ideologies. Politicians with longer-term goals, such as running for president, may cast votes that send the best signals rather than those that produce the best policy. In this chapter, we first study a discrete signaling model, in which an individual can either send a signal or not. Individuals differ in their costs of sending the signal. For signals to function, they must be costly or verifiable. That will be a central take-away from this chapter. For example, an employer may have a plum assignment in Barcelona, Spain, for the summer and want to select from a collection of new hires, all of whom list Spanish-language skills on their resumes. Claiming to speak Spanish is a _costless signal_. Instead, the employer could create a language badging program where earning the badge entails giving an hour-long presentation in Spanish. For the employees who can speak Spanish, this signal (the presentation) has low cost. For those employees not fluent in Spanish, the costs of preparing an hour-long talk would be prohibitive. In the formal language of signaling models, the badge _separates_ the people who speak Spanish from those who do not. We then cover a continuous signaling model, in which signals can vary in their magnitude. A summer camp may have only one position for a lead kayaker and want someone with incredible stamina. The camp director might then ask two applicants for the position to kayak as far as they can over the next ten hours. The stronger of the two kayakers could choose a distance that the weaker kayaker cannot achieve, guaranteeing that the test separates. Both models give us conditions for when signals will separate and when they will not. They therefore give us deeper insights than anecdotal accounts of people, animals, politicians, and governments signaling, by providing explicit characterizations of when they signal and how costly those signals are. For example, the models will make clear why students work so hard to signal their worthiness for college and medical school. In the conclusion, we discuss the contributions of signaling models as well as some other implications. We also discuss how signaling occurs in ecology, anthropology, and business. 

---

### Discrete Signals 

We begin with a _discrete signaling model,_ in which a person decides whether to take an action or not. You can buy an expensive watch to prove wealth. You can major in physics to prove your intelligence. You can swim the English Channel to prove your physical health. You cannot go halfway: you either send or do not send the signal. The model assumes two types of people, denoted as _strong_ and _weak_. The types could correspond to physically fit or unfit marine recruits, or monolingual and bilingual employees. The cost of sending the signal, which might be engaging in a fitness regimen for a month for a potential marine or the aforementioned presentation in Spanish for the job applicants, depends on a person’s type. Strong potential marines find it less costly to complete the fitness regimen. In the model, we assume that everyone who sends the signal shares equally in the total benefit. This assumption can be interpreted in either of two ways. In some cases a resource might be split among those who send the signal. For example, everyone who donates $1,000 to a school (a signal of generosity) may get their name on the wall. In other cases, such as for the marines and job applicants, the winner(s) of some prize may be randomly chosen from the set of people who send the signal. The model supports three types of outcomes: _pooling,_ where everyone sends the same signal; _separating,_ where each type sends a unique signal; and _partial pooling,_ where some types separate and others do not. 

---

## Discrete Signals Model 

 [[Discrete Signals Model]]

## Separation with Continuous Signals 

 [[Separation with Continuous Signals]]

# 26. Learning Models 

_The most important attitude that can be formed is that of desire to go on learning._ 

 —John Dewey 

In this chapter, we study models of individual and social learning. We apply each in two contexts. The first setting involves learning the best choice in a set of alternatives. In that setting, both types of learning, individual and social, converge on the optimal choice. The choice of learning rule only affects the rate of convergence. We then apply the learning rules to actions in games. In a game, an action’s payoff depends on the action of the other player or players. In that setting, both learning rules favor risk-averse equilibrium outcomes over efficient ones. We also find that individual and social learning need not produce the same result and that neither performs better in all environments. These findings bolster our many-model approach to representing behavior. Learning models lie in between the rational-choice models, which assume that people think through the logic of situations and games and take optimal actions, and rule-based models that assign behaviors. Learning models do assume that people follow rules, but those rules enable behavior to change. In some cases, the behavior converges to optimal behavior. In those cases, learning models can be used to justify the assumption that people optimize. However, learning models need not also converge to equilibria; they might produce cycles or complex dynamics. If the models do converge, they may select some equilibria more than others. The chapter begins by describing a reinforcement learning model 

---

and applies it to the problem of choosing the best alternative. The model reinforces actions with higher rewards. Over time, the learner takes only the best action. This is a baseline model that proves ideal for learning about learning. It also fits quite well with experimental data, and not just for humans. Sea slugs, pigeons, and mice all reinforce successful actions. It may be a better model of sea slugs, which possess fewer than 20,000 neurons, than of humans, who have more than 85 billion. That extra capacity allows humans to consider counterfactuals when learning, a phenomenon left out of the reinforcement learning model. We then introduce social learning models, where individuals learn from their own choices and the choices of others. Individuals copy the actions or strategies that are most prevalent or that are performing above average. Social learning requires observation or communication. Some species create social learning through _stigmergy_ : a process in which successful actions leave a trace or residue that others can follow, such as when goats who roam a mountain range leave trampled grass, reinforcing routes to water or food. In the third section, we apply both types of learning models to games. As already noted, games present a more complicated learning environment. The same action might produce a high payoff in one period and a low payoff the next. As might be expected, we find that both social and individual learning models can fail to converge to efficient equilibria. They can also produce different outcomes. We conclude with a discussion of more sophisticated 

learning rules.^1 

---

### Individual Learning: Reinforcement 

In _reinforcement learning_ , an individual chooses actions based on the weights of those actions. Actions with a lot of weight are chosen more often than actions with little weight. The weight assigned to an action depends on the reward (payoff) that a person has received from taking that action in the past. This reinforcement of high-reward payoffs leads to better actions being taken. The question we explore is whether reinforcement learning converges to only choosing the alternative with the highest reward. At first, it may seem that to choose the most rewarding alternative is a trivial task. If the rewards are expressed in numerical form, such as money or time, we would expect people to choose the best. In Chapter 4 , we invoked that line of thinking to argue that a person choosing a route to work in Los Angeles would settle on the shortest one. If rewards do not take numerical form, which is generally the case, people must rely on memory. We grab lunch at a Korean restaurant. We find the kimchi delicious, so we are more likely to eat there again. On Monday, we eat an oatmeal cookie an hour before running and find we can sustain a strong pace for ten kilometers. If prior to Wednesday’s run we again grab an oatmeal cookie and perform well, we add weight to that action. We learn that cookies improve our performance. Other species do the same. Edward Thorndike, an early psychologist who studied learning, conducted an experiment in which cats who pulled a lever to escape a box were rewarded with fish. When returned to the box, the cats pulled the lever within seconds. Thorndike’s data revealed a process of continued experimentation. He found that cats (and people) learned faster when he increased the reward. He called this the _law of effect_.^2 This finding has a neurological explanation. Repetition of an activity builds neurological pathways that induce that same behavior in the future. Thorndike also found that more surprising rewards, rewards that far 

---

exceeded past or expected outcomes, produced faster learning in 

people, a phenomenon known as the _surprise principle_.^3 In our reinforcement learning model, the weight assigned to a chosen alternative is adjusted based on how much the reward from that alternative exceeds our expectations (our _aspiration level_ ). This construction embeds both the law of effect (we take actions that produce higher rewards more often) and the surprise principle (the amount of weight we add to a choice depends on how much its reward exceeds the aspiration level).^4 

---

## A Reinforcement Learning Model 

 [[A Reinforcement Learning Model]]

## Reinforcement Learning Works 

[[Reinforcement Learning Works]]

## Replicator Dynamics 

 [[Replicator Dynamics]]

## Replicator Dynamics Learns the Best 

[[Replicator Dynamics Learns the Best]]

## The Spiteful Man and the Magic Lamp 

 [[The Spiteful Man and the Magic Lamp]]

## The Generous/Spiteful Game 

 [[The GenerousSpiteful Game]]

## Does Culture Trump Strategy? 

[[Does Culture Trump Strategy]]

# 27. Multi-Armed Bandit Problems 

_There’s one thing I’m really good at, and that’s hitting the ball over a net, in a box. I’m excellent._ 

 —Serena Williams 

In this chapter, we add uncertainty to the problem of learning the best alternative to create a class of models known as _multi-armed bandit problems_. In bandit problems, rewards from alternatives are distributions rather than fixed amounts. Bandit problems apply to a wide variety of real-world situations. Any choice among actions that has an uncertain payoff—pharmaceutical drug trials, choice of where to place advertisements, choice among technologies, decisions as to whether to allow laptops in the classroom—can be modeled as bandit problems; so too can the problem of choosing a profession at which we can excel.^1 A person facing a bandit problem must experiment with alternatives to learn the payoff distributions. This feature of bandit problems creates a trade-off between exploration (searching for the best alternative) and exploitation (choosing the alternative that has performed best so far). Finding an optimal balance in the explore

exploit trade-off requires sophisticated rules and behaviors.^2 The chapter consists of two parts followed by a discussion on the value of applying models. In the first part of the chapter, we describe a special class of Bernoulli bandit problems, in which each alternative is a Bernoulli urn with unknown proportions of gray and white balls. We describe and compare heuristic solutions, and then show how these solutions can improve comparison tests of drug treatments, advertising plans, and teaching strategies. In the second 

---

part, we describe a more general model, where the reward distributions can take any form and the decision-maker has a prior distribution over their types. In that part, we also show how to solve for the Gittins index, which determines the optimal choice. 

---

### Bernoulli Bandit Problems 

We begin with a subclass of bandit problems in which each alternative has a fixed probability of producing a successful outcome. This first class of bandit problems is equivalent to deciding among a set of Bernoulli urns, each containing different proportions of gray and white balls. Therefore, we refer to these as _Bernoulli bandit problems_. These are also called _frequentist problems_ because the decision-maker knows nothing about the distributions. As the decision-maker tries alternatives (explores), she learns about those distributions. 

---

## Bernoulli Bandit Problems 

 [[Bernoulli Bandit Problems]]

## Bayesian Multi-Armed Bandit Problems 

 [[Bayesian Multi-Armed Bandit Problems]]

## The Gittins Index: Example 

[[The Gittins Index Example]]

## Presidential Elections 

[[Presidential Elections]]

# 28. Rugged-Landscape Models 

_Amazing the things you find when you bother to search for them._ 

 —attributed to Sacagawea 

In this chapter, we study the rugged-landscape model. Like spatial and hedonic models, the rugged-landscape model defines an entity as a collection of attributes. Each set of attributes maps to a value. The goal is to modify attributes to construct an entity of highest value. This model originated in ecology to study evolution. It is now also used to study problem solving, competition among firms, and innovation. That will be our focus here. We apply the model to reveal how interdependence in the effects of attributes makes innovation difficult and leads to path dependence in the solutions found and also leads to a greater variety of solutions. We also see how more difficult problems benefit from a greater diversity of problem solving approaches. The chapter consists of three parts followed by a discussion of how to extend the model to capture competition. In the first part, we describe the ecological model of a fitness landscape and show how we can reinterpret it as a model of problem solving and innovation. In the second part, we discuss the implications of ruggedness within a one-dimensional model. In the third part, we present the NK model of rugged landscapes, which extends the one-dimensional model to an arbitrary number of binary dimensions. 

---

### The Fitness Landscape 

The _fitness landscape model_ assumes species have features or traits that contribute to their fitness, loosely defined as their reproductive potential, and that individual members of a population differ in how much they have of a particular trait. If we plot the amount of the trait on the horizontal axis and the fitness of species on the vertical axis, we produce a graph known as a fitness landscape in which points of high elevation correspond to high fitness. To draw a landscape in which the trait corresponds to the length of a coyote’s tail, we hold all other attributes of a coyote the same, vary the length of the tail, and measure the effect on fitness. To draw the graph, we need to know how the tail contributes to fitness. Suppose that a coyote’s tail helps to balance the coyote when it jumps, and that it signals happiness, fear, or aggression. We begin at the left of the horizontal axis with a tail of length zero. It cannot carry out either function, so it has a fitness of zero. As the tail becomes longer both balance and signaling improve. Thus, fitness increases with tail length. At some point, say eighteen inches, the tail may be an ideal length for contributing to balance. If the tail becomes longer, the coyote will be less agile. Longer tails may continue to improve signaling value, so perhaps a tail of length twenty inches produces the most overall fitness. Once the tail becomes longer than twenty inches, fitness falls. The resulting graph, shown in figure 28.1, has a single peak. 

Figure 28.1: A Mount Fuji Landscape This landscape is known as a _Mount Fuji_. Such landscapes often occur in the real world. Mount Fuji problems are considered easy. 

---

We expect that evolution or learning will always find the peak when encountering one. Imagine a population of coyotes with different lengths of tails. Selective pressure would result in coyotes with tails of approximately twenty inches. Coyotes with tails of that length optimally blend balance and signaling. They have the highest fitness and produce the most offspring, resulting in more coyotes with twenty-inch tails. If we think of this as an optimization problem, we see that any hill-climbing algorithm would locate the peak. We can apply one-to-many thinking and reinterpret this as a problem of product design—specifically, the problem of designing a coal shovel. Suppose that we have already decided on the length of the handle and the shape of the pan. The remaining design decision is how large to make the pan. Pan area will correspond to the trait on the horizontal axis. On the vertical axis, we plot how much coal a worker could shovel in an hour given that pan size. As before, we start at the far left, which corresponds to a shovel pan with zero surface area. The technical term for a zero-surfacearea shovel is “stick.” A stick cannot shovel coal and has value zero. As we increase the pan—say, to the size of a teaspoon, then a tablespoon, then a toy shovel—we make the shovel more and more effective. The graph of shovel fitness slopes up. At some point, the pan area becomes too large. Lifting the shovel becomes a chore, and the amount of coal that a person can shovel in an hour decreases with further increases in pan size. When the pan area becomes sufficiently large, no one would be able to lift the shovel and fitness will be zero. Once again, we have a Mount Fuji landscape. And once again, we should expect to be able to find the peak, the ideal pan size for our shovel. The idea of plotting the efficiency of shovels as a function of pan size to determine the optimal shovel was developed by Frederick Taylor. In the 1890s, Taylor and others ushered in an era of scientific management in which manufacturing decisions—how fast to move the assembly line, how strong to make the weld, how many breaks to give workers—were modeled as rugged-landscape problems. Many of the great industrialists of the twentieth century including Henry Ford, John D. Rockefeller, and Andrew Carnegie contributed to this 

---

movement toward efficiency, or what now is commonly called Taylorism. The move away from artisans making individual and distinct products to large-scale manufacturing, in which processes were broken into parts and each part was optimized and then routinized, led to increases in efficiency but also, in the eyes of many, the dehumanization of labor. Herein lies a welcome reminder about the need for multiple models. Any single model simplifies the world and highlights only some dimensions. Scientific management models focused on process efficiency. This led to criticism. Making decisions based on efficiency of output caused other objectives, such as the happiness and well-being of workers, to fall by the wayside. The landscape model may seem to be a relatively obvious idea: plot the fitness, efficiency, or value of a characteristic as a function of a trait or attribute and then climb up the hill to find the optimal amount of the trait. Thinking of solving a problem as climbing up a hill may also seem little more than a metaphor. The validity of these critiques is not in question. However, by constructing a formal landscape model we will produce nontrivial insights. 

---

### Rugged Landscapes 

When we allow for multiple attributes and for the contribution of one attribute to interact with those of others, we produce a rugged landscape—that is, a landscape with multiple peaks. Consider designing a couch in which we must choose the thickness of the cushions and the width of the arms. Let the value of a design equal its expected sales in the market, which correlates with aesthetic quality. If the couch has thick cushions, then wide arms may create a more appealing aesthetic. If the cushions are thin, then the ideal couch may have thin arms. A two-dimensional plot of expected sales as a function of arm length and cushion thickness will have two peaks. One peak corresponds to a couch with thin arms and thin cushions. The other will have thick arms and thick cushions. Interdependent effects between variables create ruggedness on the landscape. Ruggedness has several implications. First, different approaches to finding the highest point on a rugged landscape may locate different peaks. So too may different starting points. Thus, ruggedness creates sensitivity to initial conditions and the possibility of path dependence. Each of these implies that landscape ruggedness contributes to outcome diversity. Ruggedness also implies the possibility of suboptimal outcomes. These are represented as _local peaks_ on the landscape. Figure 28.2 shows a rugged landscape with five peaks. Four of these peaks are local peaks, points whose neighboring points all have lower values, and one is the _global peak,_ the point with the highest value. To see how search could land on a local peak that depends on the initial point, imagine beginning from a point and then climbing uphill. This is known as a _gradient heuristic_ or a _hill-climbing algorithm_. On a rugged landscape, gradient heuristics get stuck on a local peak. If the starting point is at the far left, the gradient heuristic would locate local peak 1, which is not optimal. If the gradient heuristic starts in the region denoted by Basin 2 in figure 28.2, then it locates 

---

local peak 2. Each of the other peaks, including the global peak, has a region such that if the gradient heuristic begins in that region, it will locate that local peak. These regions are called _basins of attraction_ and are identified in figure 28.2. The global peak has the smallest basin of attraction. If we were to choose a random starting point and apply the gradient heuristic, the global peak is the least likely to be found. The basins of attraction depend on the heuristic. A different heuristic may produce different basins. For example, consider the heuristic _go to the right_ which moves to the right until finding a local peak. This heuristic produces identical local peaks as the gradient heuristic, but those peaks have different basins of attraction, as can be seen by comparing figure 28.3 with figure 28.2. 

Figure 28.2: A Rugged Landscape with Five Peaks To find an optimal or near-optimal peak on a rugged landscape requires either diversity or sophistication. The value of diversity should be self-evident. If distinct heuristics locate different peaks, then applying multiple, diverse heuristics to a problem will produce multiple, diverse local peaks, and one can choose the best from 

among these.^1 The same result will occur if one applies the same heuristic from different starting points: distinct local optima will be found and the best among them can be chosen. Note also that the ruggedness of the landscape, as measured by the number of peaks, correlates with problem difficulty. However, a problem can be difficult to solve yet not have a rugged landscape. The problem of finding a gold coin in a cornfield would be represented by a flat landscape with a single peak at the coin’s location. The landscape would not be rugged, but the coin would be very difficult to find. 

---

### The NK Model 

We now describe the _NK model_ , which allows us to formalize the connection between interactions and ruggedness.^2 The model represents objects, or what we might call alternative solutions, as binary strings of length _N_. The value of an object equals the sum of the contributions of each bit on the string. The _K_ term in the model refers to the number of other bits that interact with each bit to determine its value. If _K_ equals zero, the value function is linear. If _K_ equals _N_ − 1, then every bit interacts with every other and the value of each string is random. Thus, we can think of increasing _K_ as tuning the ruggedness of the landscape to somewhere between Mount Fuji and random. 

 Figure 28.3: Basins of Attraction Produced by the “Go to the Right” Heuristic 

---

## NK Model 

 [[NK Model]]

## Do We Patent Knowledge? 

[[Do We Patent Knowledge]]

# 29. Opioids, Inequality, and Humility 

_Everything is complicated; if that were not so, life and poetry and everything else would be a bore._ 

 —Wallace Stevens 

In this final chapter, we apply many-model thinking to two salient policy issues: the opioid epidemic and economic inequality. We show how by engaging multiple models, we can better reason through these issues and better communicate why both have proven so difficult to solve. We can also see how, particularly in the case of opioids, experts might have used multiple models to anticipate the crisis before it occurred. That said, we do not want to oversell the potential for models to avoid disaster. Our treatment of the opioid epidemic is superficial, meant only as a template for how to apply many models when reasoning through a proposed policy or action. We do not gather data or calibrate any models. Rather, we apply the models qualitatively to gain insights. Our analysis of income inequality, on the other hand, includes more detail and connects more tightly to the academic literature. It represents the other extreme of many-model thinking, where we deeply engage a variety of models. In both cases, thinking with many models makes us more knowledgeable and wiser. The chapter concludes with a brief comment on the need for humility. Models can make us wiser, but complex systems by definition are difficult to predict and understand. We will make mistakes. And we can learn from those mistakes to become even wiser. 

---

### Many Models and the Opioid Epidemic 

To give some sense of the scale of the opioid epidemic in 2015, in the state of Massachusetts over 4% of the population above age 11 had an opioid use disorder according to one estimate. Nationwide, in 2016, doctors wrote more than 200 million prescriptions for opioids, between 10 and 12 million people misused opioids, over 2 million people were classified as having an opioid use disorder, and more than 30,000 people died from opioid-related causes. The primary reason that so many opioids were prescribed was that they work: they reduce pain. Given the 100 million Americans with chronic pain, opioids had an enormous potential market. The danger with opioids was, of course, the potential for people to become addicted. To make sense of how opioids received approval and how the epidemic arose, we apply four models to generate some core intuitions as to how the crisis came to be. The first model, the multi-armed bandit model, explains why opioids were approved for use. When seeking drug approval, a pharmaceutical company runs clinical trials to demonstrate drug efficacy and a lack of deleterious side effects. We can model a clinical trial as a multi-armed bandit problem where one arm corresponds to prescribing the new drug and the other arm corresponds to a placebo or the existing drug. 

---

## A Model of Opioid Approval 

 [[A Model of Opioid Approval]]

## Transition-to-Addiction Model 

 [[Transition-to-Addiction Model]]

## Paths to Heroin Addiction 

 [[Paths to Heroin Addiction]]

## Technology and Human Capital Model 

 [[Technology and Human Capital Model]]

## Positive Feedbacks to Talent 

 [[Positive Feedbacks to Talent]]

## CEO Political Capture 

 [[CEO Political Capture]]

## Rent-from-Capital Model (Piketty) 

 [[Rent-from-Capital Model (Piketty)]]

## Assortative Mating 

 [[Assortative Mating]]

## Intergeneration Income (Wealth) Dynamics 

 [[Intergeneration Income (Wealth) Dynamics]]

## Persistent Inequality (Durlauf) 

 [[Persistent Inequality (Durlauf)]]

# Notes 

I have too many colleagues and friends to thank properly. This book was improved by conversations about modeling with Eric Ball, Andrea Jones-Rooy, Michael Mauboussin, Carl Simon, John Miller, Lu Hong, Helene Landemore, Jim Johnson, Skip Lupia, Josh Berke, Patrick Grim, Bob Axelrod, PJ Lamberson, Jessica Steinberg, Jessica Flack, Charlie Doering, Michael Ryall, Robert Deegan, Jay Grusin, Sarah Silvestri, Zev Berger, Ken Kollman, Jean Clipperton, Michael Barr, Benjamin Bly, Elizabeth Bruch, Abbie Jacobs, Mark Newman, Cosma Shalizi, Kent Myers, and Josh Cooper Ramo. I would also like to thank the Guggenheim Foundation for funding a sabbatical as well as the faculty, staff, and students at INSEAD and the people of Fontainebleau, France. In Ann Arbor, the staffs at Lab Cafe, Mighty Good Coffee, and all four Sweetwaters Coffee and Tea locations provided coffee and quiet support. This book has also benefited from online conversations with thousands of people who gave feedback through Model Thinking. My agent, Max Brockman; editor, TJ Kelleher; and Melissa Veronesi kept me focused over the final year. Mita Gibson and Linda Wood provided unending support and encouragement, covering for my many lapses in scheduling as well as demonstrating facility with the printer, and, in the final stages, Lucy Fleming and John Burt solved vexing typesetting issues. 

---

### Chapter 1: The Many-Model Thinker 

1 See, for example, O’Neil (2016) for an account of how simple models based on data can ignore some segments of the population and can ignore the adaptive feedbacks we discuss Chapter 4. 

2 See Paarsch and Shearer 1999, which analyzes the timber industry. Raw data on tree planting shows that the piece rate is negatively correlated with the number of trees planted; the more someone is paid to plant a tree, the fewer trees that person plants. The inference runs counter to standard economic logic. If you pay planters more per tree, they should work harder. In Paarsch and Shearer’s model, timber companies pay workers a per-tree piece rate so that the hourly market wage equals $20 an hour. That assumption results in the following equation for dollars per tree: 

 $20 = Number of Trees Planted per Hour × Dollars per Tree. 

If a person can plant ten trees in an hour, then the pay per tree will equal $2. If a person can plant twenty trees in an hour, then the pay per tree will be $1. Thus, the model predicts that the piece rate will be _negatively correlated_ with the number of trees planted. It also predicts that the piece rate times the number of trees will equal a constant. 3 For evidence on models outperforming people, see Dawes 1979, Tetlock 2005, Silver 2012, and Cohen 2013. See Kahneman 2011 on biases. 

4 See Slaughter 2017 and Ramo 2016. 5 Studies show that the most impactful research and patents disproportionately draw ideas from multiple disciplines. An analysis of 35 million papers shows that in the long run, interdisciplinary papers have greater impact (Van Noorden 2015). A combination of ideas is not necessarily a combination of models, but in many cases it is; see Jones, Uzzi, and Wuchty 2008 and Wuchty, Jones, and Uzzi 2007. Freeman and Huang 2015 show that ethnic diversity also correlates with citations. If we interpret patents as evidence of 

---

innovation, then two separate strands of research link diversity of thinking to success. Shi, Adamic, Tseng, and Clarkson 2009 show that patents that cross categories produce more citations. Youn, Strumsky, Bettencourt, and Lobo 2015 show that a majority of patents include multiple subcategories. Interdisciplinary research has increased steadily to the point where, on average, social scientists cite more papers from other disciplines than from their own. 

6 See Box and Draper 1987. 7 See Page 2010a. 8 I am not equating knowledge with models. I am claiming that models can represent knowledge and provide a clear way to communicate those understandings. The term “knowledge” encompasses rather broad terrain and includes physically embedded and tacit skills such as how to play tennis, speak French, or negotiate a contract. I apply a narrower definition. For a broader conception, see Adler 1970. 9 You can arrive at this approximation by noting that falling skydivers reach terminal velocities of 200 mph. Terminal velocities scale with the inverse of mass. Assume that a skydiver has a mass 400 times larger than the stuffed cheetah. The square root of 400 equals 20. Therefore, the terminal velocity of the stuffed cheetah will equal 200 mph divided by 20, or 10 mph. 

10 He was correct. For the record, Fresno is 30% larger than Iceland. Ball and LuPima 2012 describe how one can take lessons from the academy to the business world. 11 See Lo 2012. For a general argument see Myerson 1992. 12 Versions of this story can be found in the writings of William James, Stephen Hawking, and Antonin Scalia. 

---

### Chapter 2: Why Model? 

1 See Epstein 2008 for a finer categorization of reasons to model. Lave and March (1975) describe three categories of use: to explain empirical phenomena, to predict other, new phenomena, and to build and design systems. Implicitly, they also advocate using models to explore. 2 See Harte 1988. This categorization borrows from Johnson’s 2014 treatise on the uses of models in the social sciences. These two approaches are also known as the _Galilean_ and _minimalist idealizations_. See Weisberg 2007. For more on analogies, see Pollack 2014 and Hofstadter and Sander 2013; the latter refers to analogies as the “fuel and the fire” of thinking. See also Schelling 1978, 87, for elaboration on classes of models. Daniel Little’s blog, _Understanding Society_ , provides an entree into the topic of the ontology of social science. 

3 See Arrow 1963. A collective ranking is possible if we limit the possible individual rankings. If, say, everyone had the same ranking, then the collective would as well. In general, we have no way of mapping individual rankings to a coherent collective ranking. 4 The best minds of my generation surely noticed that I borrowed “this actually happened" from _Howl_. See Bickel, Hammel, and O’Connell 1975. 

The figure below shows one of many possible examples of adding a node and reducing total edge length. The network on the left shows four points as corners of a square. The one on the right includes a fifth point in the center. If we set the length of a side of the square to 1, the edges in the graph on the left have a total length of 3, and those on the right have a total length equal to 4 _·_ 0.71, which is less than 3. 

 Simpson’s paradox arises when there are more men than women 

---

who apply to departments with higher admission rates. For example, consider a university with a medical school and a veterinary school. Suppose that 900 men apply to medical school and 480 (or 53%) are accepted, that 300 women apply and 180 (or 60%) accepted, that 100 men apply to veterinary school and 20 (or 20%) are accepted, and that 300 women apply and 90 (or 30%) are accepted. In each school, a larger percentage of women are accepted, but overall, 50% of men (500 out of 1,000) while only 45% of women (270 out of 600) are accepted. For an example of Parrondo’s paradox, suppose that the first bet always loses $1 and the second bet loses $2 in any period whose number is not divisible by three but wins $3 in periods 3, 6, 9, 12, etc. Each bet produced an expected loss, but if you make the second bet only in the periods when it wins and make the first bet in the other periods, you will win $1 every three periods. 5 See Kooti, Hodas, and Lerman 2014. 6 Suppose that each person makes the same income _I_ and pays a constant tax rate of _t_. Let _c_ denote the percentage reduction and _r_ denote the increase in income. Current government revenue equals _I · t_. After the tax cut, revenue equals _I_ (1+ _r_ ) _·t_ (1 _−c_ ). Revenue will increase if and only if _I ·t < I_ (1+ _r_ ) _t_ (1 _−c_ ). Rearranging terms gives _r > c_ (1 + _r_ ). 7 See Ledyard, Porter, and Wessen 2000 for a market-based mechanism that produces a better solution to multidimensional payload problems. 

8 I borrow the adjective “unreasonable” from physicist Eugene Wigner (1960), who described the mathematical models used in the physical sciences as _unreasonably effective_. 9 See Ziliak and McCloskey 2008 for a discussion of the ability of social science models to explain variation. 

10 See Porter and Smith 2007 for a history on the spectrum auction. 11 See Squicciarini and Voigtländer 2015. See Mokyr 2002 for a full historical account of the importance of knowledge transfer. 

 12 See http://www.treasury.gov/initiatives/financial

---

stability/Pages/default.aspx. 

13 For example, during the mid-1990s, about 60% of the restaurants that opened in Columbus, Ohio, failed. None received a government bailout, nor should they have. A healthy market economy includes failures. See Parsa et al. 2005. 14 Taken from the IMF’s 2009 _Global Financial Stability Report_. The strength of a connection was based on the correlation in portfolio values. That correlation was based on extreme events; days on which the institutions performed particularly well or particularly poorly. This measure was thought to capture the likelihood of one failure spreading to another. In point of fact, the correlations in performance could result from similarities in investment portfolios as well as one bank holding assets in another. 

15 See Geithner 2014. 16 See Weisberg 2012 for a description of the San Francisco Bay model and its usefulness in policy. 

 17 See Stone et al. 2014 for a full account. 18 I thank Josh Epstein for the first example. 19 See Dunne 1999 and Raby 2001. 

---

### Chapter 3: The Science of Many Models 

1 Levins 1966. 2 See Page 2007, 2017 for more detailed descriptions and derivation. 

3 See Suroweicki 2006 on the wisdom of crowds; Tetlock 2005 on how foxes outperform hedgehogs; Kalyvas 1999 on the failure of political science to predict the fall of the Soviet Union; and Patel et al. 2011 on ensemble methods in computer science. 4 Hong and Page 2009 show that independent models require a unique set of categorizations. That is, there exists only one way to create a set of independent predictions in a binary category model. 

5 See three of my earlier books— _The Difference_ (Page 2008), _Diversity and Complexity_ (Page 2010), and _The Diversity Bonus_ (Page 2017)—for elaboration on the diversity prediction theorem. For data on economic predictions, see Mannes, Soll, and Larrick 2014. 6 Consider the four bungalows _A_ , _B_ , _C_ , and _D_ in the figure below, along with their market values. Create two categories based on whether or not the bungalow contains a recording studio denoted by a circle above the door). Bungalows _A_ and _B_ do not contain recording studios, so they belong to one category, while bungalows _C_ and _D_ do contain studios, so they belong to the second category. 

Four Bungalows and Their Market Values We first compute the _total variation_ in the bungalows’ prices. This equals the sum of the squared differences from each value to the mean. We make all calculations in units of $1000. The mean value of the four bungalows equals 400, so total variation equals 100,000: Total Variation = (200 _−_ 400)^2 + (300 _−_ 400)^2 + (500 _−_ 400)^2 + (600 _−_ 

400)^2 = 100, 000. To calculate the _categorization loss_ , we assume that we know the true mean within each category: $250,000 for the first category and 

---

$550,000 for the second category (the bungalows that have been turned into recording studios). The categorization lumps together houses of different values. That remaining variation equals the 

**categorization loss** : Categorization Loss A & B = (200 _−_ 250)^2 + (300 _−_ 250)^2 = 5, 000 and Categorization Loss C & D = (500 _−_ 550)^2 

+ (600 _−_ 550)^2 = 5, 000. The total categorization loss equals the sum of these two numbers, or 10,000. To compute _valuation error_ , assume that the model predicts prices of $300,000 for bungalows _A_ and _B_ and $600,000 for bungalows _C_ and _D_. Valuation error equals the squared differences between the predictions for each category and the true mean. Valuation error A & B = (300 _−_ 250)^2 + (300 _−_ 250)^2 = 5, 000 and 

Valuation Error C & D = (600 _−_ 550)^2 + (600 _−_ 550)^2 = 5, 000. The total valuation error equals 10,000. Total _model error_ equals the squared differences between the predictions and the actual values: Model Error = (200 _−_ 300)^2 + (300 

_−_ 300)^2 + (500 _−_ 600)^2 + (600 _−_ 600)^2 = 20, 000. Notice that the model error equals the sum of categorization loss and valuation error. 7 See Brock and Durlauf 2001 for a spin-glass model of social interactions in two dimensions. Glaeser, Sacerdote, and Schenkman 1996 have a one-dimensional model used to examine crime. Fudenberg and Levine 2006 construct an economic model of the brain. 8 Niarchos was not the first shipper to attempt to exploit scale. In 1858, Isambard Kingdom Brunel, the legendary British engineer who built the Great Western Railway, launched a nearly 700-foot-long ship, the SS _Great Eastern_. That ship proved a failure. A lack of hydrodynamic models resulted in a poor overall design. The boat proved seaworthy at only the slowest of speeds. It finally found use laying transatlantic cables. See West 2017 for how multiple models aid in designing ships. 

9 BMI can also be written as 703 times weight (in pounds) divided by height (in inches) squared. 10 LeBron James stands 6 feet 8 inches and weighs around 250 

---

pounds, giving him a BMI of 27.5. Kevin Durant, who stands 6 feet 9 inches and weighs 235 pounds, has a BMI of 25.2. Aston Eaton, the 2012 and 2016 Olympic decathlon gold medalist, measures 6 feet 1 inch and weighs 185 pounds, resulting in a BMI of 24.4, on the cusp of being overweight. His predecessor, 2008 Olympic decathlon gold medalist Brian Clay, had a BMI of 25.8. 

11 See Flegal et al. 2012. 12 We assume a mouse 3 inches long, 1 inch high, and 1 inch wide, and an elephant 10 feet tall, 10 feet long, and 5 feet wide. The elephant has a surface area of 400 square feet, or 57,600 square inches. The elephant has a volume of 500 cubic feet, which equals 864,000 cubic inches. 

13 Geoffrey West and colleagues have constructed more elaborate and accurate models that predict that metabolism should scale with mass raised to the three-quarters power. See West 2017. 14 Controlled experiments that send identical resumes but change the name demonstrate that women receive lower salary offers and lower evaluations than men (Moss-Racusina et al 2012). 

15 The probability of a man becoming CEO equals the probability he receives fifteen promotions in a row, or. The probability that a man becomes a CEO relative to a woman, the _likelihood ratio_ , equals. Given our assumptions of 50% and 40%, the likelihood 

ratio equals (1.25)^15 = 28.4. 16 See Dyson 2004. 17 See Breiman 1996. 

---

### Chapter 4: Modeling Human Actors 

1 See Haidt 2006. 2 Assume the individual has a budget of _M_ , that the price of one unit of the consumption good, _C_ , is $1, and that the price of one unit of housing equals _PH_. We can write her budget constraint as _M_ = _C_ + 

_PH · H_. This implies _C_ = _M − PH · H_ , so that we can then write her 

utility as a function of _H_. 

To find the _H_ that maximizes utility, we take the derivative with respect to _H_ and set it equal to zero. This requires applying the chain rule for derivatives. 

Moving the first term to the other side of the equation and then cross multiplying gives the following: 

 2 PH · H = ( M − PH · H ) 

Substituting 2 _PH_ · _H_ for ( _M − PH · H_ ) in the budget constraint gives _M_ 

= 2 _PH · H_ + _PH · H_ , or that _M_ = 3 _PH · H_. It follows that the individual 

spends of her income on housing. 3 In the United States, this is a close approximation. Source: US Bureau of Labor Statistics 2013. 4 The formal theorem is written as follows: Let _X_ = { _A_ , _B_ , _C_ ,..., _N_ } denote a finite set of **outcomes,** and let a **lottery** be a probability distribution over outcomes: _L_ = ( _pA_ , _pB_ ,..., _pN_ ). If preferences ( ) 

over lotteries satisfy **completeness** : any two lotteries, _L_ and _M_ , can be compared; **transitivity** : if _L M_ , and _M N_ , then _L N_ ; **independence** : if _L M_ , then given any lottery _N_ and any probability _p >_ 0, the lottery _pL_ + (1 _− p_ ) _N pM_ + (1 _− p_ ) _N_ ; and 

---

**continuity** : if _L M_ and _M N_ , then there exists a probability _p_ such that _pL_ + (1 _− p_ ) _N_ ∼ _M_ , then preferences can be represented by a continuous utility function that assigns a real number, that is a utility, to each lottery. A sketch of the proof goes as follows: Assume that there exists a best outcome, _B_ , and a worst outcome, _W_. Set the utility of _B_ equal to 1 and the utility of _W_ to zero. Given any other outcome _A_ , by the _continuity axiom_ , there exists a probability _p_ that makes a person indifferent between receiving _A_ for sure and receiving _B_ with probability _p_ and _W_ with probability (1 _− p_ ). We write this as _A_ ∼ _pB_ + (1 _− p_ ) _W_. We then assign a utility of _A_ equal to _p_. A little introspection (and a bit of math) shows that the more a person likes an outcome (or lottery), the larger _p_ will be. And almost by magic, we have turned rankings into numbers. For a complete proof, see Von Neumann and Morgenstern 1953. 

5 See Rust 1987. 6 See Camerer 2003. 7 See Harstad and Selten 2013. 8 See Myerson1999 on the use of rational choice as a benchmark. 

9 See Camerer, Loewenstein, and Prelec 2005 for an early survey. 10 See Kahneman 2011 for an overview of this research. 11 The original paper by the Open Science Collaboration (2015) has led to more attempts at replication showing similar percentages. 12 See Medin, Bennis, and Chandler 2010 for the need for greater diversity in subject pools. 

13 See Berg and Gigerenzer 2010. They give full voice to this line of criticism, arguing that it undermines mathematically based psychological models. 14 Kahneman and Tversky 1979. 15 _Gain frame:_ Treatment _A_ will save 40% of the patients for certain. Treatment _B_ has a 50% chance of saving everyone. _Loss frame:_ Treatment _A′_ will cause 60% of the patients to die for sure. Under treatment _B′_ , there is a 50% chance that no one dies and a 50% chance that everyone dies. According to prospect theory, most 

---

doctors choose treatment _A_ in the gain frame and _B′_ in the loss frame. 

16 See Thaler 1981 and Laibson 1997 for early papers on the implications of hyperbolic discounting. 17 The formula for hyperbolic discounting can be written in the more general form 

18 See Gigerenzer and Selten 2002. 19 See Gode and Sunder 1993. 20 See Gigerenzer and Selten 2002. 21 In his Nobel Prize lecture, Vernon Smith notes that “Ecological rationality uses reason—rational reconstruction—to examine the behavior of individuals based on their experience and folk knowledge. People follow rules without being able to articulate them, but they can be discovered.” See Smith 2002. 

22 See Arthur 1994. 23 See Lucas 1976 and Campbell 1976. 24 See de Marchi 2005 for a discussion of how models illuminate what could happen. See Gilboa and Schmiedler 1995 and Bednar and Page 2007, 2018 for equationand rule-based models in which actors apply behaviors in similar games. 

---

### Chapter 5: Normal Distributions: The Bell Curve 

 1 Given a set of data { xi ,..., xN }, the variance equals the average 

squared distance to the mean, _μ_ , which is written as: 

The standard deviation equals the square root of the average squared distance to the mean, _μ_ : 

2 Any of several conditions are sufficient. One of the more common, the _Lindeberg condition_ , requires that the proportion of the total variation that comes from any one variable will converge to zero as the number of variables grows large. 

3 See Lango et al. 2010. 4 For the general case, assuming independent random variables, we have the following expressions: 

Setting _σi_ = _σ_ for all _i_ gives 

5 Wainer 2009 provides a more thorough analysis of the policy choices involved. 6 The threshold of two standard deviations (5% significance) is a convention open to criticism, but it is what social scientists generally use. A large coefficient significant at the 6% level is likely more worth 

---

noting than a small coefficient at 4.9% significance. See Ziliak and McCloskey 2008. 

7 See Gawande 2009. 8 Distributions of products of random variables are called lognormal because the logarithm of the distribution will be normally distributed. A sketch of the logic as to why goes as follows: First, we write a product of numbers, _y_ = _x_ 1 · _x_ 2 · _x_ 3 ··· · _xn_ , as a product of 

terms written as powers of 10: 

We then take the logarithm base 10 of both sides to obtain the following: 

 log 10 ( y ) = log 10 ( x 1 ) + log 10 ( x 2 ) + log 10 ( x 3 ) + ··· + log 10 ( xn ) 

Thus, the logarithm of the variable _y_ can be written as the sum of the logarithms of random variables. The logarithms of those random variables are also random variables, and so long as their variances satisfy the conditions of the central limit theorem, their sum, which is _log_ 10 ( _y_ ), will be normally distributed. 

 9 See Limpert, Stahel, and Abbt 2001. 10 This idea can be traced back to Gibrat 1931. 

---

### Chapter 6: Power-Law Distributions: Long Tails 

1 See Parrish 2017 for an account of the impact and cultural meanings of this flood. 

2 This numerical example assumes an exponent of 2 and is borrowed from Clauset, Young, and Gleditsch 2007. 3 For a technical description of the models presented in this chapter as well as references to many examples of power laws, see Newman 2005. 

4 See Newman 2005 and Piantadosi 2014 for surveys. 5 The constant _C_ makes the total probability over all outcomes equal to 1. Given this definition, power-law distributions satisfy _scale invariance_. If we change the units with which we measure outcomes, the shape of the distribution does not change. 

6 These probabilities can be calculated by first solving for the probability of the event not happening within a year. If an event has probability , the probability of that event not happening within a year equals (0.999)^365 = 0.69. So the probability of that event happening equals 31%. The probability of a one-in-a-million event not happening in a century is calculated similarly. 

7 See Cederman 2003; Clauset, Young, and Gleditsch 2007; Roberts and Turcotte 1998. The probability of a terrorist act with _x_ deaths can be written as a constant term of approximately .06 divided by _x_ squared. For a discrete distribution where _x_ only takes on integer values, the power-law distribution can be written _p_ ( _x_ ) = 0.608 _x_ -2. The coefficient 0.608 is chosen so that the probabilities sum to 1: = 1.644934. The product of 0.608 and 1.644934 equals 1. 

8 For the power law, we take logs of both sides and transform _y_ = _Cx-a_ into log( _y_ ) = log( _C_ ) _−a_ log( _x_ ), a linear equation for log( _y_ ) in terms of log( _x_ ). When we plot the values of log( _y_ ) and log( _x_ ) we obtain a 

straight line. For an exponential distribution, _y_ = _C ·A-x_. If we take logarithms of both sides, we obtain log( _y_ ) = log( _C_ ) _− x_ log( _A_ ), which means that log( _y_ ) is linear in _x_. That means that log( _y_ ) will decrease 

---

rapidly in log( _x_ ), creating a concave graph. 

9 If we take the logarithm of a lognormal distribution, we obtain an equation of the following form: log( _y_ ) = _C − b ·_ log( _x_ ) _−_ , where _σ_ is the natural logarithm of the standard deviation of the lognormal distribution, a proxy for the variance of the distribution. For large _σ_ 

the contribution of log( _x_ )^2 will be small until log( _x_ ) becomes sufficiently large value to cause a downturn in the graph. 10 To see how to formally distinguish between a lognormal and a power law see Broido and Clauset (2018), who show that many networks thought to have power-law distributions may not. 

11 See Piantadosi 2014 for a survey of Zipf’s law in word frequencies and a range of candidate models. If the event size distribution satisfies a power law, then so too do the ranks. A general proof goes as follows: A power-law distribution with exponent _a_ on the open interval [1, ∞) has the form _pa_ ( _x_ ) = _ax_ _a_. Assume 100 

events. Let _SR_ denote the expected size of the _R_ th largest event. 

The probability of an event larger than _SR_ must equal. For 

example, if _R_ = 3, then the probability of an event larger than _S_ 3 

must equal 3%. Therefore, 

Solving gives , which can be rewritten as: 

In the special case where _a_ = 2, this expression becomes . 12 See Bak 1996. How widely the model applies remains an open question. Scholars have used the concept to explain economic fluctuations, war deaths, terrorist acts, punctuated equilibria in evolution, and traffic jams. See, for example, Paczuski and Nagel 

---

1996, Sneppen et al. 1995. 

13 See Salganik, Dodd, and Watts 2006 for the original study, and Ormerod 2012 for an alternative analysis. A power-law distribution also implies a multitude of small events that constitute a large portion of the probability distribution. These small events can combine to produce economic value of the same magnitude as the large events. See Anderson 2008b. The internet has made it possible for retailers to stock enormous catalogs of books, movies, and music even though some items appeal to small numbers of people. A publisher that sells 5 million copies of a best-seller earns the same revenue as a publisher that sells 500 copies each of 10,000 different books. 14 For a specific model that shows how this could arise, see Denrell and Liu 2012. 

15 Geologists measure earthquake magnitudes using the Richter scale, which equals the logarithm of the size. An earthquake measuring 6 on the Richter scale is ten times as large as an earthquake measuring 5. See Merriam and Davis 2009 on using Zipf’s law to predict earthquake sizes but not their timing. 16 See Eliot, Golub, and Jackson 2014 for an explicit model of how increasing connectedness can lead to a decreased likelihood of failure. 

17 See May, Levin, and Sugihara 2008 for the full argument. 18 See Stock and Watson 2003. 19 The following explanation summarizes Carvalho and Gabaix 2003. 20 See Clarida, Galí, and Gertler 2000. 21 I thank Seth Lloyd for bringing this example to my attention. 22 We let distribution of salaries equal $100,000 times a random 

variable _x_ with _p_ ( _x_ ) = 2 _x_ -3 from 1 to ∞. The variable _x_ has a mean equal to 2, so the salary distribution has a mean value of $200,000. 23 See Weitzman 1979 for a model showing this result in more generality. 

 24 See Bell et al 2018. 

---

### Chapter 7: Linear Models 

1 Valuable vintages, such as Bordeaux wines, receive rankings by experts. These wines also get priced in the marketplace. Prices and rankings can function as proxies for quality. Ashenfelter has fit (log) linear models for Bordeaux quality based on the amount of the winter rainfall, harvest rainfall, and average temperature in September. See Ashenfelter 2010. A log linear model expresses the logarithm of the dependent variable as a linear sum of the logarithm of the independent variables: 

### log( y ) = b 0 + b 1 log( x 1 ) + b 2 log( x 2 ) 

This expression implies that the dependent variable can be written as a product of the independent variables. We can see this by making each side of the equation the exponent of _e_ , resulting in the following equation: 

By taking logarithms, multiplication becomes addition and one can apply the tools of linear regression. Using the price of the vintage as the dependent variable, Ashenfelter’s model has an _R-squared_ (that is, the percentage of variation that is explained) of 83%. Evidence shows it predicts wine prices more accurately than the judgments of more qualitative wine experts. His model even predicts changes in experts’ assessments. Robert Parker, a well-known wine evaluator, initially assigned scores of 95 (out of 100) to the Pomerol and St. Emilion 1975 vintages. Ashenfelter’s model predicted lower quality rankings. In 1983, Parker lowered his rankings to below average, as Ashenfelter predicted. See Storchmann 2011. 2 See Xie 2007. 3 See Ryall and Bramson (2013) for an introduction to causal models. 

 4 Mauboussin 2012 shows how the equation can guide sound 

---

managerial decision-making. 

5 See Bertrand and Mullainathan 2001. 6 See Shapiro, Meschede, and Osoro 2013. They are not conflating correlation and causality here. If two variables are not correlated, then we should not expect a causal relationship. 

7 To find the best line to classify data, many analysts use _support vector machines (SVMs),_ an approach similar to regression. The key difference is that SVMs find the line that maximizes the distance to the closest points in each set that separates the data into positives or negatives. If no such line exists, as will often be the case, penalties are assigned to violations. Regression, by comparison, considers the distance to all of the data points and minimizes total distance. 

---

### Chapter 8: Concavity and Convexity 

1 See Arthur 1994. 2 Thirty doublings equals 2^30 , which exceeds 1 billion. 3 See Karlsson (2016) for contextualization of Escobar’s hippos. 4 See Ebbinghaus 1885. 5 Brain researchers have found that even with chocolate, there exists an amount of consumption at which people begin to form an aversion (Small et al. 2001). 6 This, like many examples, I borrow from Lave and March 1975. 7 Suppose that you invest $3,000 a year. If the stock were a constant $15, then you could buy 200 shares each year. If the price alternated between $20 and $10, then in the high-price years you could buy 150 shares, and in the low-price years you could buy 300 shares. On average, you could buy 225 shares, which is more than you could buy with constant prices. 8 The key assumption is that the exponents in the Cobb-Douglas production function, _a_ and (1 _− a_ ), sum to 1. This implies that if we double the number of workers and the amount of capital, total output also doubles. 

### Output = Constant · (2 · Workers) a (2 · Capital)(1− a ) 

Expanding terms and some rearranging gives a doubling of output: 

### Output = 2 · Constant · Workers a Capital(1− a ) 

9 Output per day in the second year equals 100 = 141. In the third year, it equals 100 = 173. The growth rate equals the percentage increase in output from year to year. 10 The calculations are as follows: **Year 2:** machines: 290, output: 1,702 (= 100 ). Investment = (0.2) _·_ 1702 = 340, so consumption = 1362. Depreciation = (0.1) _·_ 290 = 29. **Year 3:** machines: 601, output: 2,453 (= 100 ). Investment = (0.2) _·_ 

---

2453 = 491, so consumption = 1962. Depreciation = (0.1) _·_ 601 = 60. 

 11 The long-run equilibrium can be solved for by solving for M ∗, 

such that 0.2 _·_ 100 = 0.1 _M_ ∗. This occurs at _M_ ∗ = 40, 000. 

12 The full Solow model replaces the square root functions with a parameter _a_ , as in the Cobb-Douglas model, and also includes a labor market. 13 To solve for the equilibrium, we set investment equal to depreciation:. Therefore, the equilibrium number 

of machines _K_ ∗ satisfies the equation. Placing this back into the output function, output equals. 

14 Gordon (2016) takes the pessimistic view that new technologies on the horizon will produce a large increase in _A_. More advanced growth models make technology a function of other variables. A model by Paul Romer (1986) assumes that growth arises from an increased variety of goods: as the economy grows, so does variety. Weitzman (1998) explicitly models the generation and recombination of ideas. 15 See Arthur 2011 on lags in technology. 16 For example, countries that never connected rural villages with telephone lines were able to build radio towers and provide cell phone service. Gerschenkron (1952) refers to this as the _advantage of backwardness_. 17 Easterly and Fischer 1995. 18 Piketty 2014 shows that world GDP has grown only 1.6% on average from 1700 to 2012 and that half of that growth is due to population growth. Applying the rule of 72 to an 0.8% growth rate, we find that over a 300-year period average standards of living increase about 10-fold. 

---

### Chapter 9: Models of Value and Power 

1 This value is found by multiplying the probability of the rower adding value times the rower’s expected added value, which equals · 10 plus · 2. Note that the Shapley values sum to 10, the total value of the game. 

2 Formal calculations are as follows: Of Arun’s six ideas, two are unique, one is also proposed by Betty, and three are proposed by everyone. If he enters first, which occurs with probability , he adds value 6. If he enters second, he adds two unique ideas, none of the ideas shared by all three, and has a one-in-two chance of arriving before Betty and adding one more idea. So, he adds 2.5 ideas. If he arrives third, he adds his two unique ideas. Thus, his Shapley value equals 3.5. Betty proposes four ideas shared with one other person and three proposed by everyone. Therefore, her Shapley value equals 3. Finally, Carlos proposes three ideas proposed by one other person along with the three proposed by everyone. His Shapley value equals 2.5. Note that the Shapley values sum to 9, the total number of ideas. 3 An alternative measure of voting power, the _Banzhaf-Penrose index_ , counts the total number of parties that can be pivotal given all possible winning coalitions and assigns a value to each party equal to the number of times it is pivotal divided by this number. See Banzhaf 1965. 

 4 See Groseclose and Snyder 1996 for the formal analysis. 

---

### Chapter 10: Network Models 

1 See Newman 2010 for comprehensive treatment of networks; see Jackson 2008 and Tassier 2013 for network effects in social science. 

2 Given any node, its minimal paths have length 1 to 4 nodes, minimal paths of length 2 to 4 nodes, and minimal paths of length 3 to 4 nodes, producing a total of 12 nodes on the minimal paths from each node. On average, the minimal paths from a node visit one other node. It follows that average betweenness for each node equals. By symmetry, all nodes must have the same betweenness. 3 See Newman 2010 for an overview of community detection algorithms. The partitions constructed by these algorithms likely differ because of the number of possibilities. A network with 100 nodes can be partitioned over 190 million ways. Due to randomness in the order in which edges are removed, the same algorithm will often produce different partitions. By applying multiple algorithms and applying each one multiple times, we increase the robustness of our inferences. 

4 From the central limit theorem, we know that the degrees will be normally distributed and that the mean will be , because each edge connects two nodes. 5 Watts and Strogatz 1998. 6 See Newman 2010 for formal analysis of network formation models. 7 Ugander et al. 2011. 8 Given a network with _N_ people, let _di_ equal the number of 

neighbors of node _i_ , that is, the degree. The average degree, , can be written as follows: 

---

The average degree, , equals the expected number of neighbors of a node. When counting the average number of neighbors of neighbors, a node with degree _di_ will be counted _di_ times, once for 

each neighbor. Therefore, the total number of neighbors of neighbors _N_ 2 of a node can be expressed as follows: 

To obtain the average degree of neighbors of a node we have to divide this by the total number of neighbors, which equals _N_. Therefore, it suffices to show 

This can be rewritten as 

The term on the left equals the variance in the degree distribution. If any two nodes have different degree, the degree distribution has positive variance, therefore, the average degree of neighbors of a node exceeds the average degree of a node. 9 See Eom and Jo 2014 for the formal model. 10 Dodds, Muhamad, and Watts 2003. 11 Newman 2010, Jackson 2008. 12 See Granovetter 1973. 13 The number of friends of degree four is calculated by summing the following eight sets of nodes: _C · R · C · R_ = 4, 000, 000, _C · R ·_ 

---

#### R · C = 4, 000, 000, R · C · R · C = 4, 000, 000, C · R · R · R = 800, 

#### 000, R · C · R · R = 800, 000, R · R · C · R = 800, 000, R · R · R · C 

= 800, 000, and _R · R · R · R_ = 160, 000. 

14 Albert, Albert, and Nakarado 2004. 15 See Groysberg 2012. Our model of streaks explains their lack of success as regression to the mean. 

16 See Burt 1995 on the value of filling structural holes. 17 See Frank et al. 2018 for a survey on the implications of teacher networks. 

18 The coalitions that have nonzero value are { _A_ , _B_ }, { _B_ , _C_ }, and { _A_ , _B_ , _C_ }. The value of each of the first two coalitions equals ten. The added value of the third coalition equals minus six. The coalition’s stand-alone value equals fourteen, but the coalition consists of both other coalitions, each of which has a value of ten. Therefore, the value of the coalition equals fourteen minus twenty: -6 = (14 _−_ 10 _−_ 10). We can then assign the following Shapley values for each player in each coalition: Coalition {1, 2}: Player 1: 5, Player 2: 5, Coalition {2, 3}: Player 2: 5, Player 3: 5, Coalition {1, 2, 3}: Player 1: -2, Player 2: -2, Player 3: -2. Summing these values produces Myerson values. 

---

### Chapter 11: Broadcast, Diffusion, and Contagion 

1 The models assume discrete time steps, like days or weeks, and use difference equations that describe the number of infected (or informed) people tomorrow as a function of the number infected (or informed) today. Continuous time models require differential equations and calculus. None of the results of our models would change qualitatively if we switch to continuous time. 

2 Plugging the first equation into the second gives the following expression: 36, 000 = 20, 000 + 20, 000 _− P_ broad _·_ 20, 000, which 

reduces to 4, 000 = _P_ broad _·_ 20,000, so _P_ broad = 0.2 and _N_ POP = 100, 

000. 3 See Griliches 1988. 4 Initial sales, _I_ , equal 100 for each app. First, set _P_ diffuse = 0.4 

and POP = 1000. New sales in period three equal 0.4 _·_ = 36. Similar calculations yield sales data for future periods. For the second set of data, let _P_ diffuse = 0.3 and POP = 1, 000, 000. New 

sales in the second period equal 0.3 _·_ = 30. Subsequent sales are solved for similarly. 5 Bass (1969) refers to the people who adopt the technology or buy the product as _innovators_ and the people who copy them as _imitators_. 

 6 The formal derivation of R 0 begins with the observation that for 

small numbers of infected people, the number of susceptible people is approximately equal to the size of the relevant population. To reduce the number of variables, we can substitute the number of susceptible people with the relevant population. We can then write the change in the number of infected people as a linear function of the number of initially infected people (see box). _R_ 0 can be derived 

formally as follows: when a new disease appears, it infects a small number of people. Denote this small amount by _I_ 0. Plugging into the 

SIR model, the number of infected people in period one equals 

---

Approximate _S_ 0 as _N_ POP and the expression becomes _I_ 1 = _I_ 0 + 

_P_ contact _· P_ spread _· I_ 0 − _P_ recover _I_ 0. It follows that the number of infected 

increases if and only if _P_ contact _· P_ spread _> P_ recover, which is equivalent 

to 

7 Quarantine cuts the probability of contact to near zero, lowering the basic reproduction number, but has high cost. In the early 1900s, tuberculosis ( _R_ 0 ≈ 3) caused over one hundred thousand deaths per 

year in the United States. States raised property taxes to build sanitariums to house patients because surgical techniques such as removing a lung and plumage, the collapsing of the lungs and subsequent refilling with ping-pong balls, proved ineffective. See Dubos 1987. 8 To solve for the vaccination threshold, we must take into account those vaccinated. For the disease to spread, there must be contact (probability _P_ contact) with an unvaccinated person (probability 

(1 _− V_ )) and the disease must spread ( _P_ spread), giving the following 

period one difference equation: 

Using the approximation _S_ 0 = _N_ POP, as in the derivation of _R_ 0 , this 

becomes 

 I 1 = I 0 + P contact · P spread · I 0 · (1 − V ) − P recover I 0 

The number of infected people increases if and only if _P_ contact _·_ 

_P_ spread _·_ (1 _− V_ ) _> P_ recover. This can be rewritten as _R_ 0 (1 _− V_ ) _≤_ 1. 

Expanding and rearranging terms gives _R_ 0 − 1 _< V · R_ 0. Dividing 

both sides by _R_ 0 gives the result. 

9 For an analysis of the SIR model and herd immunity see Tassier 2013. 

---

10 Stein 2011. 11 Updike 1960. 12 Tweedle and Smith 2012. 13 See Lamberson and Page 2012b. 14 Data source: wikinoticia.com. 15 See Christakis and Fowler 2009. 16 Centola and Macy (2007) refer to diffusion that requires multiple exposures as _complex contagion_. 

---

### Chapter 12: Entropy: Modeling Uncertainty 

1 See Smaldino 2013 for further elaboration. 2 The logarithm base 2 of a number _x_ equals the power to which 2 must be raised to produce _x_ , so log 2 (4) = 2 and log 2 (2 _N_ ) = _N_. In the 

general case, log _a_ ( _x_ ) equals the power that _a_ must be raised to in 

order to equal _x_. Thus, if _a y_ = _x_ , then log _a_ ( _x_ ) = log _a_ ( _a y_ ) = _y_. 

 3 We can write the information entropy in long form as follows: 

This simplifies to 

4 The _diversity index,_ the inverse of the sum of the squares of the probabilities, satisfies the first two axioms plus the multiplication axiom. Thus, the diversity index of a known outcome equals 1 and not 0 (Page 2007, 2010a). 5 See Wolfram 2001 or Page 2010a for a more detailed description. 

6 Alexander lists fifteen such properties in all. His ideas are presented along with beautiful photographs in four self-published books: _The Nature of Order, Book 1: The Phenomenon of Life_ (2002), _The Nature of Order, Book 2: The Process of Creating Life_ (2002), _The Nature of Order, Book 3: A Vision of a Living World_ (2005), and _The Nature of Order, Book 4: The Luminous Ground_ (2004). The second in this sequence is the most germane to the current discussion. 

---

### Chapter 13: Random Walks 

1 See Mlodinow 2009 for an engaging tour of random walks. 2 See Taleb 2001. 3 See Turchin 1998 and Suki and Frey 2017. 4 Note that the law of large numbers says that the mean proportion converges, whereas the central limit theorem tells us that the distribution over the proportion of white balls will be normal. 5 A player who makes 46% of his three-pointers has about a 

probability of making nine in a row (0.46^9 ). If that player keeps taking three-pointers, then in a ten-year NBA career (about 800 games), the odds of _not_ making nine in a row at least once (0.999^800 ) are about 47%. 

For over three decades, statisticians have pondered the question of whether basketball players and other professional athletes exhibit “hot hands,” that is, whether the probability of making any one shot or free throw is _not_ independent of the success of the previous attempt. See, for example, Chance 2009 for an analysis of Joe DiMaggio’s fifty-six game hitting streak. In considering the evidence for hot hands, we must take behavior into account. If a player believes he has a hot hand, he may attempt more difficult shots. Further, if the defense thinks the player has a hot hand, they can tighten their defense. These behavioral responses can be accounted for by coding shots by difficulty. Gilovich, Tversky, and Vallone (1985) found no evidence of hot hands. Miller and Sanjurjo (2015) discovered an inference error in previous calculations of conditional probabilities revealing that previous studies that purported to not show a hot hand actually support the hot hand hypothesis. The error in previous analysis stemmed from the sampling technique. Those studies gathered sequences of made and missed shots for multiple players. They then calculated the probability of a basket following a randomly selected sequence of baskets. This sampling procedure introduces a subtle statistical bias that can be seen by examining a situation in which many players each take exactly four shots and 

---

each shot has an equal likelihood of being made or missed. There exist sixteen possible sequences of makes and misses. Let _B_ represent a basket and _M_ a missed attempt. Of those sixteen sequences, six include two consecutive makes followed by another shot: _BBBB_ , _BBBM_ , _MBBB_ , _BBMB_ , _BBMM_ , and _MBBM_. These comprise the sample of cases for two consecutive baskets followed by a third shot. If _BBBB_ is drawn, then regardless of which sequence of two _B_ ’s is chosen, the probability of a basket equals 100%. If _MBBB_ is chosen, then the probability of a _B_ following a _BB_ also equals 100%. If _BBBM_ is chosen, the probability of an _M_ after _BB_ equals 50%. Last, if _BBMB_ , _BBMM_ , or _MBBM_ occurs, then an _M_ necessarily follows a _B_. Averaging across the six cases gives the conditional probability of an _M_ following a _B_ as 

The bias arises because there are two _BB_ ’s that could be chosen in the sequence _BBBB_ but only one in the other sequences such _BBMB_. The sampling procedure makes each of the two sequences in _BBBB_ half as likely to be chosen as the single sequence in _BBMB_. The implication of this bias is that if there were no hot hands, the sampling procedure would have shown misses more likely following made baskets. The fact that it did not means that made baskets were in fact more likely following made baskets. 6 Madoff announced 1.5% positive monthly returns to his clients for decades. He claimed that his investments rose each month regardless of changes in the broader market. Posting positive returns during a downturn is more difficult than outperforming the market. When the market falls, a person could beat the market yet still post negative returns. Madoff posted positive returns when the broader market fell in more than eighty months. If we make the heroic assumption that Madoff was somehow able to post positive returns even when the broader market fell three-fourths of the time, his odds of succeeding eighty periods in a row (0.75^80 ) are about 1 in 10 billion. 

7 We can solve for the standard deviation by recognizing that the value of a random walk is the sum of identical, independent random 

---

variables. Each of those random variables has a mean of zero and takes value either +1 or -1. Therefore, each has a standard deviation equal to 1. Setting _σ_ = 1 and applying the sigma square root formula for a sum gives the result. 

8 See Newman 2005 for a formal proof. 9 See Levinthal 1991 and Axtell 2001. 10 See Newman 2005 and Sneppen et al. 1995. 11 Lakes are measured by surface area. Our model produces a power-law diameter. Surface area equals a constant times the diameter squared, so area would also be power-law distributed. See Downing et al. 2006 for data. 

12 On a balanced roulette wheel, all pockets have equal likelihood. If the table has any slant, then the ball will more likely fall off the outer edge as it heads uphill. For an account of how J. Doyne Farmer, Norman Packard, and friends constructed a wearable computer to exploit this phenomenon and beat roulette, see [http://en.wikipedia.org/wiki/Eudaemons.](http://en.wikipedia.org/wiki/Eudaemons.) 13 After _N_ bets, the expected value of this random walk equals Given that the probability of winning is approximately , we can write the standard deviation of the value as The exact value equals 14 Peel and Clauset (2015) model each game as a single sequence and find that the sequences of scores exhibit _antipersistence_ : the team that scored last is less likely to score next. Given that the teams alternate possessions, this should be expected. 

15 Baxter 2009. 16 A proof of this result relies on computing the probability of returning to the starting point in _N_ steps and summing this up over all possible _N_. For a complete proof see: [http://www.math.cornell.edu/](http://www.math.cornell.edu/) ∼mec/Winter2009/Thompson/randomwalks.html. 

17 See Samuelson 1965. 18 See Grossman and Stiglitz 1980. 19 See Lo and MacKinlay 2007. Shiller 2005 shows that stocks with a relatively low price-to-earnings ratio outperform the market. 

---

20 See Mauboussin 2012. 21 This window from 1967 to 2017 happens to begin at a peak in the S&P 500. Over most windows, the stock prices grow faster than the economy. 

---

### Chapter 14: Path Dependence 

1 Hathaway 2001. 2 Pierson 2004. 3 Bednar and Page 2018. 4 See Page 2006. 5 Here is a sketch from Page 2006. It suffices to show that the probability of drawing _K_ white balls in the first _N_ periods equals There exist ( _N_ + 1) possibilities because _K_ could equal zero up to _N_. The probability of a given sequence of _K_ white balls in _N_ periods can be written as the product of _N_ fractions. The denominators of those fractions are the numbers 2 through _N_ +1. The numerators are the numbers 1 through _K_ (white balls) and 1 through ( _N − K_ ) (gray balls). The product of the numerators equals _K_! times ( _N − K_ )! and the product of the denominators equals ( _N_ + 1)!. That calculation gives the probability of a particular sequence of _K_ white balls. The number of possible ways to arrange _K_ balls across the _N_ periods equals Therefore, the total probability of exactly _K_ white balls equals 

6 The proof is by contradiction. Suppose the result does not hold and that in the long run, 60% of the outcomes are white. It follows that 60% of the balls in the urn will be gray. But this would imply that 60% of the outcomes will be gray, a contradiction. 

7 See Lamberson and Page 2012b for a more elaborate model that relies on entropy as a measure of uncertainty. 8 See Lamberson and Page 2012a. 9 See Page 1997 for how to make decisions on public projects with positive externalities. 10 VaR can also be calculated as the probability of losing more than $10,000 at any point during the year. 

11 These calculations follow from the fact that the standard deviation of the value of a random walk of length _N_ equals 2.5% 

---

corresponds to two standard deviations. 

---

### Chapter 15: Local Interaction Models 

1 In physics, the local majority model is known as the _Ising model_. The local majority model is a variant of the _voter model,_ which assumes randomly selected neighbors of various sizes. See Castellano, Fortunato, and Loreto 2009. 

2 For the cells along the four edges, we connect the top edge to the bottom edge, creating a cylinder, and then connect the left edge to the right edge to create a torus (a donut). 3 In alternative versions of the local majority model, cells can be activated simultaneously or according to the incentive to update, with the cells with the largest majority of neighbors in the opposite state moving first. If the cells update simultaneously, then the local majority model can produce cycles. 

4 See Miller and Page 2004 for a model of standing ovations. 5 See Bednar et al. 2010 for a model of culture that includes consistency of actions across domains. 

6 Here too, attaching the top to the bottom to first create a cylinder and then attaching the ends to create a skinny donut. 7 A class of models called _diffusion reaction models_ also produce stripes on narrow shapes and splotches on wider shapes. Using these models, scientists can predict which animals will have stripes, which will have splotches, and which will be a solid color. The answer depends on the size of the mammal’s embryo during the developmental stage when the patterns form and not on the animal’s adult size. Otherwise, elephants would have splotches. See Murray 1988. 

8 I thank Bernardo Huberman for this imagery. 9 Proving this involves writing a computer program that generates a random sequence of numbers or a random pattern and showing that the Game of Life mimics the computer program. The formal proof requires showing that the Game of Life is _universal_ in the set of cellular automaton. See Berlekamp, Conway, and Guy 1982. 

 10 See Dennett 1991 and Hawking and Mlodinow 2011. 

---

### Chapter 16: Lyapunov Functions and Equilibria 

1 See Nagel 1995 for the original experiments. 2 I thank Jenna Bednar for the example of races to the bottom within federal systems as well as several others scattered throughout the text. 3 See Page 2001 for a formal proof. 4 The presence of externalities, even negative ones, need not preclude the construction of a Lyapunov function. Both the local majority model and the route selection model contain negative externalities. In the local majority model, when a cell changes its state it imposes a negative externality on its neighbors who are in the opposite state. However, the positive externality that it creates with the neighbors it now matches is larger. 5 Guy 1983. If you are daring, start at 27. 

---

### Chapter 17: Markov Models 

1 A research article would use statistical techniques to estimate transition probabilities more exactly and calculate error ranges. It would also test to see if the transition rates remain fixed over the time period. They would not if transition probabilities depend on per capita income. See Przeworski et al. 2000. 

2 Flores and Nooruddin 2016. 3 See Tilly 1998. 4 The equilibrium percentage of people who have tile floors equals the probability of moving from linoleum to tile divided by the sum of the probabilities of moving from linoleum to tile or tile to linoleum. This equals A general model can be written 

as follows: Let _D_ denote the percentage of people who own a costly durable good and let _C_ denote those people who own a cheaper good. Let BUY( _C_ ) _>_ denote the probability that someone buys the cheaper good. Let REPLACE( _C_ ) and REPLACE( _D_ ) denote the probabilities of replacing the two types of products. If the following inequality holds: 

 REPLACE( C ) · (1 − BUY( C )) > REPLACE( D ) · BUY( C ) 

then more people buy the cheaper good but more people own the durable good. The first part of the claim holds by assumption. To prove the second part, we first solve for the transition probabilities. The probability that someone moves from _D_ to _C_ is _P_ ( _D_ , _C_ ) = REPLACE( _D_ ) _·_ BUY( _C_ ). The probability that someone moves from _C_ to _D_ is _P_ ( _C_ , _D_ ) = REPLACE( _C_ ) _·_ (1 _−_ BUY( _C_ )). In equilibrium, _D − D · P_ ( _D_ , _C_ ) + _CP_ ( _C_ , _D_ ) = _D_. Setting _C_ = (1 _− D_ ), we have _D_ = which is greater than 0.5 if _P_ ( _C_ , _D_ ) _> P_ ( _D_ , _C_ ). That inequality is equivalent to REPLACE( _C_ ) _·_ (1 _−_ BUY( _C_ )) _>_ REPLACE( _D_ ) _·_ BUY( _C_ ). 5 See McPhee 1963 and Ehrenberg 1969 for empirical evidence of double jeopardy. To prove the result, we need only show that consumers are equally likely to buy either product when switching 

---

brands. 

6 See Briggs and Sculpher 1998 for an overview. 7 See Schrodt 1998. 8 Khmelev and Tweedie 2001. 9 Khmelev and Tweedie 2001. 10 Reynolds and Saxonhouse 1995. 11 See [http://www.ams.org/samplings/feature-column/fcarc-](http://www.ams.org/samplings/feature-column/fcarc-) pagerank. 

12 Skillful construction of such models lies in defining useful states and assigning accurate transition probabilities. See Langville and Meyer 2012. 13 In a food web, a species links to those species it consumes. See Allesina and Pascual 2009. 

 14 See Russakoff 2015. 

---

### Chapter 18: Systems Dynamics Models 

1 See Sterman 2000 for a more general introduction. 2 See Wellman 1990 for an analysis of the value of qualitative systems dynamics models. 3 The model assumes that all hares die by being eaten by foxes. Adding variables for hare death would complicate the model without changing the results as it would just lower the growth range of hares. The expression ̇ _H_ denotes the rate of change in _H_ per unit of time, or The equilibrium occurs when the rates of changes in the number of both hares and foxes equal zero, To solve for the equilibrium take the equation _gH − aFH_ = 0 and divide by _H_. This gives _g − aF_ = 0. Solving for _F_ gives the result. Next, take the equation _bFH − dF_ = 0, and divide by _F_. This gives _bH − d −_ 0. Solving for _H_ gives the result. 

4 I thank Michael Ryall of the University of Toronto for this example. 5 The model’s findings are summarized in Meadows et al. 1972. 6 The suite of models are often referred to as the _Club of Rome models_ , as the Club of Rome, a group founded by David Rockefeller in 1968, funded reports on the models and promoted the models’ findings. 7 By manipulating more variables with small ranges, he can drive the model’s prediction to nearly 30 billion. See Miller 1998. 

8 On the first point, see Hecht 2008. On the second point, see MacKenzie 2012. 9 See Sterman 2006. 10 Glantz 2008. 

---

### Chapter 19: Threshold Models with Feedbacks 

1 See Granovetter 1978. 2 Airbnb’s founders paid the costs of going door-to-door by selling Obama O’s and Cap’n McCain’s cereal boxes during the 2008 presidential election. 3 See Jacobs 1989 for the revolving-door model. Empirical studies find that in jobs that require little formal education, bartending and gardening being examples, men leave (or choose not to enter) professions that include as little as 15% women (Pan 2015). 

 4 See Syverson 2007. 5 See Gammill and Marsh 1988 for a more detailed account. 6 See Easley et al. 2012. 

---

### Chapter 20: Spatial and Hedonic Choice Models 

1 See Clark, Golder, and Golder 2008. 2 See Martin and Quinn 2002 for analysis of judicial positions. 3 Hotelling (1929) studied geographic location, Lancaster (1966) expanded Hotelling’s model to study _hedonic competition_ , and Downs (1957) applied the model to politics. 

4 The _nominate model_ offers a more sophisticated approach to assigning ideologies based on this same idea (Poole and Rosenthal 1985). 5 The constant term ( _C_ in the expression) is chosen so as to make all of the payoffs positive. To accomplish this it can be set to the maximal possible distance between any ideal point and an alternative. 

6 In constructing the cut line in this way, we assume that consumers equally weight the two attributes. We could include difference in weights. If people value sweetness more than the amount of cocoa, we would slant the cut line counterclockwise. At one extreme, if people only value sweetness, the cut line would be horizontal and divide _A_ and _B_ evenly on the vertical axis. The spatial model provides a clean example of how we convert an intuition—we prefer things closer to our ideal—into a formal model. Once we plot the alternatives (the chocolate bars) and the consumer’s ideal point in space and define a preference ordering over alternatives (a ranking of the alternatives from best to worst) based on their distances from the ideal point, we have, in fact, written down a utility function based on the alternative. That utility of a product equals the inverse of the distance from the ideal point. 7 Havel 1978. 8 See Martin and Quinn 2002. 9 See McCarty 2011. These percentages could change with shifts in levels of party loyalty or if the types of bills put to a vote change. 

10 Formally, if we assume an odd number of voters and the existence of a single voter ideal point at the two-dimensional median, 

---

the condition requires that any line through the two-dimensional median divides the remaining voter ideal points in two equal-sized sets. See Plott 1967. 

11 McKelvey (1979) showed that a sequence of elections could result in any policy in two or more dimensions, a finding that some referred to as a “chaos result.” McKelvey was careful to state that his result was a statement about sequences of outcomes that were possible given preferences and not a prediction of what would happen in a series of elections. See Kollman, Miller, and Page 1997 for a computational version of the multidimensional spatial model in which candidates move to the center under a variety of behavioral assumptions. 12 The proposer may have to offer 41. 13 See McCarty and Meirowitz 2014 for a deeper analysis of this model and other models from game theory applied to politics. 14 See Tsebelis 2002 on the effect of veto players more generally. 

15 A study of housing prices in Los Angeles estimated the cost of commuting at around $28 per hour (Bajari and Kahn 2008). 16 This can be calculated as follows: Initial revenue equals price times quantity, _p · q_. In the first market, after the price drop, revenue falls by 10% and sales increase by 8%, so revenue equals 

 0.9 p · 1.08 q = 0.972 p · q 

In the second, more crowded market, quantity increases by 33%, so total revenue equals: 

 0.9 p · 1.33 q = 1.197 p · q 

---

### Chapter 21: Game Theory Models Times Three 

 1 The formal model and proof can be written as follows: Let Ei 

equal the effort level of player _i_. The payoff to player _i_ equals _M − Ei_ 

if she wins and _−Ei_ otherwise. Assume that the probability that player 

_i_ wins equals her proportion of total effort: 

To solve for the unique symmetric Nash equilibrium, we consider the effort of player _i_ assuming that all of the other players choose a common effort level _E_ ∗. Player _i_ ’s payoff equals 

The first derivative of this payoff function equals 

To find a maximum, we set the first derivative equal to zero, giving 

. In the symmetric 

equilibrium _Ei_ = _E_ ∗. Substituting in gives the result. To prove that the 

first derivative gives a maximum, we need only check that the second derivative of the payoff function is negative. 2 See Shalizi and Thomas 2011 on how to tease out network effects and on the difficulty of making claims about network effects with snapshot data. See Christakis and Fowler 2009 for many examples of clustered behaviors and attributes. 

---

### Chapter 22: Models of Cooperation 

1 See _Science_ magazine’s special 125th-anniversary edition, published in 2005. 

2 See Martin et al. 2008 and Biernaskie 2011. 3 See Zaretsky 1998. In the bank example, ATMs would lower profits if the banks had been earning substantial geographic rents, that is, extra profits because they could exploit customers’ costs of traveling across town to go to a competing bank. I thank Simon Wilkie for this example, among many others. 

4 Technically, we are showing that Grim Trigger is an equilibrium strategy in the probabilistically repeated Prisoners’ Dilemma. Other strategies, such as Tit for Tat, can also be equilibrium strategies when paired with Grim Trigger. 5 A player who defects against Grim Trigger earns a payoff of _T_ in the first period and can earn at most zero in any future interactions. If the player uses Grim Trigger against Grim Trigger, she earns a payoff of _R_ in each period in which the game is played. The probability of two periods of play is _P_ , the odds of three periods are 

_P_^2 , and the odds on _N_ periods are _PN−_ 1. Therefore, the expected payoff equals: 

The proof that (1 + _P_ + _P_^2 + _P_^3 +...) = can be shown as follows: Assume the result is true and then multiply both sides of the equation by (1 _− P_ ). The right-hand side equals 1. The left-hand side 

equals (1 + _P_ + _P_^2 + _P_^3 + ...) _−_ ( _P_ + _P_^2 + _P_^3 + ...), which also equals 1. 6 We need only redo the calculations for maintaining cooperation, and having _P_ fall to. If does not support cooperation, then neither will several periods with a continuation probability _P_ followed by a continuation probability. 7 Nowak and Sigmund (1998) refer to this as _image scoring_. See 

---

also Bshary and Grutter 2006. 

8 Both forms of aggression can be mapped to the defect action if one assumes that they would increase the size of the warbler’s domain. See Godard 1993. 9 Four pairs of outcomes merit elaboration. When TFT plays GRIM, both cooperate forever, earning each an average payoff of 3. When TROLL plays itself, both defect in the first two periods and then cooperate forever, for an average payoff of a little less than 2. When GRIM plays TROLL, GRIM cooperates in the first round and TROLL defects; in the second round, both defect; in rounds three and four, GRIM defects and TROLL cooperates; thereafter, both defect. GRIM’s sequence of payoffs can be written as 1, 2, 4, 4, and 

then a long sequence of 2s, for an average of 2+. TROLL’s sequence of payoffs can be written as 4, 3, 1, 1, and then a long sequence of 2s, for an average payoff of exactly 2. When TFT plays TROLL, TFT cooperates in round one, while TROLL defects. Both defect in round two. In round three, TROLL cooperates and TFT continues to defect. In round four, TROLL cooperates for the second time and TFT reverts to cooperation. Thereafter, both cooperate forever. Each receives one payoff of 1, one payoff of 4, one payoff of 2, and a long sequence of 3s, producing an average payoff of a little less than 3. 10 In fact, both All C and GRIM are _dominated_ by TFT. Against any strategy TFT does at least as well or better than either All C or GRIM. TFT dominates All C because TFT cannot be exploited by All D and TROLL. TFT dominates GRIM because it is able to cooperate with TROLL based on the fact that TFT forgives TROLL’s defections whereas GRIM does not. In a famous experiment, Robert Axelrod asked scholars to submit strategies for a repeated Prisoners’ Dilemma game with a continuation probability. Of the fourteen strategies submitted, TFT performed best. He then asked people to send in new strategies. This time sixty-two people submitted strategies. TFT won the second time as well. Axelrod chalks up the success of TFT to several properties of the strategy: it cooperates, it punishes, and it is also forgiving. GRIM is not forgiving, so GRIM is unable to reboot cooperation with TROLL. See Axelrod 1984. The 

---

table does not contain an average payoff against all of the strategies, as that would assume each strategy to be equally likely. One population may contain a majority of people who play TFT. Another may include a large proportion of TROLL. A third may include lots of All D and All C. 

11 Suppose, for example, that the temptation payoff equals four times the sucker payoff, _T_ = 4 _S_ , and that 5% of the population cooperates. Then _P_ must exceed. Maintaining cooperation requires only that _P_ exceeds. In the case where _T_ = 4 and _R_ = 3, evolving coordination requires. Maintaining cooperation requires _P ≥_. For the general proof assume that a proportion _θ_ of the population plays TFT (or GRIM) and a proportion (1 _− θ_ ) plays All D. Assume that each person plays against the entire population. TFT (or GRIM) playing against TFT earns a payoff of _R_ each period, producing an expected payoff of. TFT playing against All D receives a payoff of _S_. All D playing against All D receives a payoff of zero. And All D playing against TFT earns a payoff of _T_. Therefore, the average payoff for TFT equals , and All D earns an average payoff of outperforms All D if and only if 

. Therefore, TFT earns a higher payoff if and only if the following holds: 

If _θ_ is small, then will be large and the condition will not be likely to hold. See Boyd 2006 for an analysis of the difficulty of evolving cooperation relative to maintaining it. 12 We borrow this model and the analysis from Nowak (2006), who shows how repetition, reputation, and kin selection can also support cooperation. 13 The open node copies the action of the highest-performing neighbor. By assumption, all neighboring defectors earn payoffs equal to zero. The cooperating neighbor earns a payoff of _K · B − D · C_. This exceeds zero if and only if. 

 14 See Wilson 1975 for the foundations of group selection theory. 

---

Wilson has several books that take up group selection in greater detail. 

15 Traulson and Nowak’s model works as follows: Divide a population of _N_ individuals into _M_ distinct groups of equal size. Within each group, apply the _cooperative action model_ and assign a performance to each individual. Let the probability of choosing individual _i_ equal the performance of _i_ divided by the sum of the performances of all _N_ individuals. A clone of this individual is added to the same group. If the group’s size now exceeds a threshold , then with probability (1 _− q_ ), a random individual from that same group is removed, and with probability _q_ , the group splits into two groups with each member randomly placed in one of the groups. To keep the total number of groups constant, one of the existing groups is chosen at random and eliminated. For large _M_ and rare splitting (small _q_ ) the number of cooperators increases if and only if the following holds:. See Nowak 2006. 

16 When Michelle Peluso, an advocate of agile management, became the chief marketing officer at IBM, she created competing teams whose performance was transparent to other teams. She then rewarded the best teams (Dan 2018). This type of agile management practice borrows ideas from Agile programming, which replaces the standard waterfall approach of sequential construction with simultaneous code writing, testing, and interactions with users. 17 Another strategy, _Generous Tit for Tat,_ cooperates initially and punishes defections only part of the time. In one set of experiments with errors, this strategy outperforms both Tit for Tat and Win Stay, Lose Shift. See Rand et al. 2009 and Wu and Axelrod 1995. 

 18 See Axelrod, Axelrod, and Pienta 2006. 

---

### Chapter 23: Collective Action Problems 

1 See Hardin 1968 for an introduction to the tragedy of the commons. 2 See Diamond 2005. 3 See Ostrom 2005 and Ostrom, Janssen, and Anderies 2007. 4 To solve for the social optimum, suppose that each person spends _X_ on the public good. The total utility for the population equals 

Taking the derivative with respect to _X_ and setting it equal to zero gives 

Solving gives _X_ = _N_. 

To solve for the symmetric Nash equilibrium, we assume that each other person contributes the same amount to the public good; call this amount _A_. Let _Y_ denote the amount that the individual contributes. Her utility equals 

Taking the derivative with respect to _Y_ and setting it equal to zero gives = 1. Rearranging terms and squaring both sides gives [ _Y_ + ( _N −_ 1) _A_ ] = 1. In the symmetric equilibrium, where everyone contributes the same amount ( _Y_ = _A_ ), then _Y_ =. 5 Utilitarianism weights everyone’s lot equally. Rawls (1971) proposed an alternative: the _maxmin principle,_ in which the ideal social outcome maximizes the utility of the least well-off person. Rawls advocates evaluating outcomes from behind a _veil of ignorance_ so that we do not know whether we will be rich, famous, 

---

and endowed with great capacities or hindered by circumstances. 

 6 We can write individual j ’s utility as follows: 

To solve for the symmetric Nash equilibrium, we assume that every other person contributes an amount _A_ to the public good. Let _Y_ denote the amount that individual _j_ contributes. Let _I_ equal the common income level. Individual _j_ ’s utility equals 

Taking the derivative with respect to _Y_ and setting it equal to zero gives 

Rearranging terms gives:. In the symmetric equilibrium, _Y_ = _A_. It follows that. 

Squaring both sides gives [(1 _− α_ ) + _αN_ ]^2 = _NY_ , which implies 

7 See Cornes and Sandler 1996 for a detailed analysis. 8 A more realistic model would assume a nonlinear congestion cost, perhaps an S-shaped curve. That assumption would capture resources like roads, in which the first few other users have no effect on an individual’s benefit and in which at some point the resource is so overcrowded as to be useless. 9 The total utility from _M_ people using the resource equals ( _B − θ · M_ ). Taking the derivative with respect to _M_ and setting it equal to zero equals ( _B −_ 2 _Mθ_ ) = 0. Solving gives _M_ =. To solve for the Nash equilibrium, we set the value of abstaining equal to zero. People use the resource until the benefit equals the outside option: _M_ =. 10 Note: we set the maximal benefit _B_ equal to the population size _N_ to reduce the number of variables. To solve for the socially optimal outcomes and Nash equilibrium, we first note that total utility 

---

equals ( _N − M_ ) _· M_ + 3( _N −_ ( _N − M_ )) _·_ ( _N − M_ ), which reduces to 4( _N − M_ ) _M_. Taking the derivative with respect to _M_ gives 4 _N −_ 8 _M_ = 0. Solving gives _M_ =. Total utility equals. To solve for the equilibrium, we find an _M_ such that the marginal utilities at the two parks are equal. This occurs when ( _N − M_ ) = 3 _N −_ 3( _N − M_ ), which can be rewritten as _N_ = 4 _M_. Total utility is calculated by plugging in the values for _M_ and _N − M_ into the utility functions. 

11 To solve for equilibrium consumption, set _R_ ∗ = (1 _− g_ )( _R_ ∗ _− C_ ∗) and solve for _R_ ∗. 

12 See Kurlansky 1998. 13 To see why the variation does not cancel out, we can consider a two-period model. A growth rate of 20% in the first year results in only 96 units of the resource (80 _·_ 1.2 = 96). A growth rate in the second year of 30% results in 98.8 = (96 _−_ 20) _·_ (1.3) units of the resource. If we flip the growth rates, then after the first year, there exists 104 units of the resource, and after the second year there exists 100.8 = (104 _−_ 20) _·_ (1.2) units of the resource. 

14 Ostrom, Janssen, and Anderies 2007. 15 See Craine and Dybzinski 2013. 16 For a short overview see Ostrom 2010; for a more complete account see Ostrom 2004. 

---

### Chapter 24: Mechanism Design 

1 See Ledyard, Porter, and Rangel 1997. 2 For an example of Pareto efficiency, consider the following four payoff profiles for three people: 

 {(3, 3, 4), (9, 0, 0), (0, 8, 1), (2, 2, 3)} 

All except (2, 2, 3) are Pareto efficient. The allocation (2, 2, 3) is dominated by (3, 3, 4). 3 See Hurwicz and Schmeidler 1978. 4 The third bidder might might bid just above $60. To simplify the analysis, we assume $60 exactly. 

5 The proof we give here assumes a uniform distribution of values in [0, 1] but the result holds for a larger class of distributions. Suppose that the other ( _N −_ 1) bidders all bid their true values times 

. A bid _b_ will be higher than another bidder’s bid provided the other bidder’s value times is less than _b_. The probability that this will occur equals. It follows that the probability of being larger than all ( _N −_ 1) of the other bids equals this value raised to the ( _N −_ 1)th power. Therefore, if the bidder has a true value of _V_ , the expected payoff from bidding _b_ equals the value minus the bid ( _V − b_ ) times the probability of _b_ being the highest bid. The expected payoff can then be written as Expected Payoff = To maximize this value, we take the derivative with respect to _b_ and set it equal to zero, giving the following condition: 

Simplifying gives: _V_ ( _N −_ 1) _− Nb_ = 0, which can be rewritten as _b_ = 

. To show that the bidder with the highest bid pays a price equal to the expected value of the second-highest bidder’s bid, note that given _N_ random values drawn from a uniform distribution on the interval [0, 1], the expected value of the highest bid equals. The expected value of the second-highest bid equals The expected 

---

bid of the highest-value bidder therefore equals 

which equals the expected value of the second-highest bidder. 6 Roger Myerson was my PhD advisor and received the Nobel Prize in part for this result. 

7 In an all-pay auction, the optimal strategy when bidders’ values lie in the interval [0, 1] can be written as follows: A bidder with a value. So if there are three bidders, a bidder with a value of would bid. 

8 For experimental evidence, see Lucking-Reiley 1999. For evidence from eBay auction experiments, see Morgan and Hossain 

2006. And for the timber auction analysis, see Athey, Levin, and Seira 2011.     9 Ostrovsky, Edelman, and Schwarz 2007.     10 See Page 2012 for a brief survey. 

---

### Chapter 25: Signaling Models 

1 See Simler and Hanson 2018 for many examples of how status signaling drives behavior and choices. 

2 The cost of a weak type of signaling equals _MC_. The benefit of signaling equals given the assumption that all _S_ strong types signal. Therefore, no weak type will signal if _MC ≥_. In contrast, the strong types prefer to send the signal if their benefit from separating exceeds not signaling and all _N_ agents splitting the benefit. From the previous calculation, the minimal signal that will not cause a weak type to signal equals. It follows that if we let , then the weak types will not signal. For the strong types to prefer to send signal , we must have. We can divide both sides by _B_ and multiply by _C_ to obtain , which simplifies to ( , which can be rewritten as _C_ ( _N − S_ ) _≥ cN_. 3 This possibility was put forth by Michael Spence, who shared the Nobel Memorial Prize in Economic Sciences for constructing a job market model of educational signaling (Spence 1973). 4 Having huge tail feathers makes a peacock less fit than if the feathers were a more moderate size. See Zahavi 1975. 

 5 See Bird and Smith 2005. 6 See Smith, Bird, and Bird 2003. 

---

### Chapter 26: Learning Models 

1 The psychological study of learning encompasses a far broader set of contexts than we cover here. A person can learn a fact, such as what the capital of Arkansas is. A person can acquire tacit knowledge, such as how to bake bread, repair an engine, or program a computer. A person can also learn a corpus of knowledge, such as organic chemistry. 

2 See Thorndike 1911, 244. 3 See Rescorla and Wagner 1972. 4 The model that I describe builds from the original Rescorla and Wagner (1972) model as well as the models by Herrnstein (1970), Bush and Mosteller (1955), Cyert and March (1963), Bendor, Diermeier, and Ting (2003), and Epstein (2014). 5 The parameter _γ_ must be chosen so that the weight on an alternative remains positive. This will be true provided that _γ_ exceeds the inverse of the difference between the highest possible aspiration level and the minimal reward from any alternative. 

6 The presentation here follows Bendor and Swistak 1997. 7 If we construct a replicator dynamics model with a finite population in which subsequent populations are chosen randomly, then it is possible that the best alternative might not be reproduced. If so, then replicator dynamics would not locate the best alternative because it has no way of reintroducing alternatives into the population. 

8 See Fudenberg and Levine 1998 and Camerer 2003. 9 The game also has a mixed strategy equilibrium in which twothirds choose an economy car and one-third choose a gas guzzler, but that equilibrium is not stable under the learning rules that we are using, so we will ignore it. 

10 To show formally: P(Economy, 1) = 0.5, P(Guzzler, 1) = 0.5, Payoff(Economy, 1) = 1.5, Payoff(Guzzler, 1) = 2, Average Payoff = 1.75. Applying the replicator equation gives Prob(Economy, 2) = and Prob(Guzzler, 2) =. 

---

11 See Frank 1985 for a more in-depth analysis of these situations. 

12 See Waltz 1979. See also Powell 1991 for a model of relative and absolute gains in international relations. 13 See Vriend 2000, which analyzes a similar payoff structure and interprets it primarily as competition between firms who produce an identical product and simultaneously choose quantities. Economists call this the _Cournot competition model_. 

14 The _Roth-Erev learning model_ updates the weight _W_ ( _k_ , _t_ ) of an alternative _k_ in period _t_ by the following formula: _W_ ( _k_ , _t_ + 1) = (1 _− r_ ) _· W_ ( _k_ , _t_ ) + _Δ_ ( _k_ , _t_ , _e_ ). The parameter _r_ denotes the recency parameter, and _Δ_ ( _k_ , _t_ , _e_ ) = (1 _− e_ ) _·_ payoff( _k_ , _t_ ) if action _k_ was chosen and _Δ_ ( _k_ , _t_ , _e_ ) = _e ·_ payoff( _k_ , _t_ ) if action _k_ was not chosen. The parameter _e_ , the experimentation parameter, determines the weight on unchosen alternatives. 15 See Camerer and Ho 1999. 16 This analysis closely follows the behavioral spillover models of Bednar and Page (2007, 2018) and also borrows from Greif 2006. Bednar and Page stress the importance of initial actions on the equilibrium that emerges, while Grief focuses on the role of beliefs. See Gilboa and Schmeidler 1995 for an introduction to case-based decision theory. See also Akerlof and Kranton 2010 on the role of identity in economic choices. 17 The formal proof can be written as follows: Let _B_ denote the proportion of players who buy in and choose the innovative action initially. It is then a straightforward exercise to compute the following payoffs for each type of action: 

_Payoff to cultural action:_ (1 _− B_ ) _·_ 200 + _B ·_ 220. 

_Payoff to innovative strategic action:_ (1 _− B_ ) _·_ 180 + _B ·_ 300. 

To prove the result for replicator dynamics, note that the cultural action has a higher payoff if and only if the following holds: 

 (1 − B ) · 200 + B · 220 > (1 − B ) · 180 + 300 B 

---

Rearranging terms gives 20(1 − _B_ ) _>_ 80 _B_. Thus, applying replicator dynamics, the cultural action increases if and only if: 0.2 _> B_. 

---

### Chapter 27: Multi-Armed Bandit Problems 

1 See Bergemann and Valimaki 2008 for the relevance to economic phenomena. 

2 See Hills et al. 2015 for a survey. 3 See Scott 2010 for an analysis of the multi-armed bandit problem and various heuristics. 

4 Gittins and Jones (1972) first characterized the optimal rule. The Gittins index can be reformulated as a _Bellman equation,_ which applies to any problem that requires a sequence of choices that each produces a payoff. A Bellman equation relies on the construction of a value function that equals the sum of the sequence of payoffs, with future payoffs discounted according to an interest rate. 5 Roberts 2004. 6 For an analysis of an experiment with the United States Department of Agriculture’s Farm Service Agency (FSA) Microloan program see Bowers et al. 2017. 7 Data from _Washington Post_ 2012 and Dann 2016. 8 Al Gore, George H. W. Bush, and Hillary Clinton would have received more credit for economic prosperity had they been incumbents. See Markus 1988 for an analysis through the early part of this period, Fair 2012 for more recent evidence, and Campbell, Dettrey, and Yin 2010 for evidence on candidate-versus-party effect size. 

---

### Chapter 28: Rugged-Landscape Models 

1 See Page 2007 for a deeper elaboration of the value of diversity. 

2 See Kauffman 1993 for a full treatment of the NK model. 3 We can derive the expected value of the local peaks and the global peaks when _N_ = 20, _K_ = 19. The contribution of each attribute is uniformly distributed on [0, 1]. This distribution has a mean of and a variance of. The value of each alternative equals the average of the twenty attribute contributions. Therefore, by the central limit theorem, these values are normally distributed with mean and variance , so in the case of _N_ = 20, each standard deviation is of size. We can then estimate the average value of a local peak: 0.609. A local peak can be thought of as the best from among 21 random draws from this distribution. Therefore, its expected value will be approximately equal to that of a value drawn from the normal distribution such that of the alternatives have lower values. This will be a little less than two standard deviations above the mean. Using a normal distribution calculator, the expected average value equals 0.609. To estimate the expected value of the global peak, 0.759, we note that the global peak has the highest value of all 2^20 alternatives. Each alternative can be thought of as a value drawn from the distribution, so the expected value will be approximately equal to that of value drawn from the normal distribution such that of the alternatives have lower value. Using a normal distribution, the expected average value equals 0.759. The global peak has a higher value than would be expected in a million draws. 4 See Wright 2001, which argues that these positive-sum recombinations helped produce humans, societies, and the technical and scientific advancements of our age. 

5 See Kauffman 1993 and Miller and Page 2007. 6 The United States allows for seventeen years from the issue date if issuing the patent takes more than three years. 

---

7 Boldrin and Levine 2010. 

---

### Chapter 29: Opioids, Inequality, and Humility 

1 Given the probabilities, the exact statistical equilibrium is 70.7% in no pain, 19.5% on opioids, and 9.8% addicted. For the first case, the percentages are 76.3%, 21.5%, and 2.2% respectively. 

2 See Wakeland, Nielsen, and Geissert 2015. 3 I thank Abbie Jacobs for her commentary and insights on this section of the book. 

4 See Wilkinson and Pickett 2009. 5 Comments made at the Becker Friedman Institute at the University of Chicago, “Understanding Inequality and What to Do About It,” November 6, 2015. 

6 See Goldin and Katz 2008, Acemoglu and Autor 2011, and Murphy and Topel 2016. 7 See Mas-Colell, Whinston, and Green 1995 for how to prove such a result. 

8 See Kaplan and Rauh 2013a, and a model by Jones and Kim (2018) that uses ability as a proxy for the scalability of an entrepreneurial idea. See Frank 1996 for early research on how inequality has occurred within every profession. For a more recent study, see Xie, Killewald, and Near 2016. 9 See Ormerod 2012. 10 Ormerod 2012 describes in detail how our increased connectedness contributes to inequality. 11 See Cancian and Reed 1999 and Schwartz and Mare 2005. 12 See Greenwood et al. 2014 for the full model. 13 The estimate is that it would have been 0.34 rather than 0.43. See Greenwood et al. 2014. The _Gini coefficient_ measures the distance between the income distribution and an equal distribution. Let _S_ ( _P_ ) denote the total share of income (or wealth) earned (held) by the lowest _P_ % of the population (i.e., if the bottom 30% of the population earns 2% of the income, then _S_ (30) = 2): 

---

If income is evenly distributed, , and GINI = 0. If all of the income goes to the top 1%, _S_ ( _P_ ) = 0 for _P <_ 100, and _S_ (100) = 1, so GINI = 1. 14 The calculation can be made as follows: Children belong to the four categories with probabilities (0.6, 0.25, 0.1, 0.05). That is, 60% of the offspring of high-income earners, 20% of the offspring of upper-middle-income earners, 15% of the offspring of lower-middleincome earners, and 5% of the offspring of low-income earners have high income. The percentage of high-income grandchildren equals (0.6)(0.6) + (0.25)(0.2) + (0.1)(0.15) + (0.05)(0.05) = 0.4275 and the percentage of low-income grandchildren equals (0.6)(0.05) + (0.25) (0.1) + (0.1)(0.15) + (0.05)(0.7) = 0.105. 15 Pfeffer and Killewald 2017. 16 Kaplan and Rao 2013b. 17 See Farmer 2018. 

---

# Bibliography 

Acemoglu, Daron, and David Autor. 2011. “Skills, Tasks and Technologies: Implications for Employment and Earnings.” In Orley Ashenfelter and David Card, eds., _Handbook of Labor Economics,_ 4: 1043–1171. Amsterdam: Elsevier-North Holland. 

Acemoglu, Daron, and James Robinson. 2012. _Why Nations Fail: The Origins of Power, Prosperity, and Poverty_. Cambridge, MA: Harvard University Press. 

Adler, Mortimer Jerome. 1970. _The Time of Our Lives: The Ethics of Common Sense._ New York: Holt, Rinehart and Winston. 

Akerlof, G., and R. Kranton. 2010. _Identity Economics_. Princeton, NJ: Princeton University Press. 

Albert, Rika, Istvan Albert, and Gary L. Nakarado. 2004. “Structural Vulnerability of the North American Power Grid.” _Physical Review E_ 69: 025103. 

Allesina, Stefano, and Mercedes Pascual. 2009. “Googling Food Webs: Can an Eigenvector Measure Species’ Importance for Coextinctions?” _PLOS: Computational Biology_ 9, no. 4. 

Allison, Graham. 1971. _Essence of Decision: Explaining the Cuban Missile Crisis_. New York: Little, Brown. 

Alvaredo, Facundo, Anthony B. Atkinson, Thomas Piketty, and Emmanuel Saez. 2013. “The World Top Incomes Database.” https://www.inet.ox.ac.uk/projects/view/149. 

Anderson, Chris. 2008a. “The End of Theory: The Data Deluge Makes the Scientific Method Obsolete.” _Wired_ 16, no. 7. 

Anderson, Chris. 2008b. _The Long Tail: Why the Future of Business Is Selling Less of More._ New York: Hachette. 

---

Anderson, Phillip. 1972. “More Is Different.” _Science_ 177, no. 4047: 393–396. 

Arrow, Kenneth. 1963. _Social Choice and Individual Values_. New Haven, CT: Yale University Press. 

Arthur, W. B. 1994. “Inductive Reasoning and Bounded Rationality (The El Farol Problem).” _American Economic Review Papers and Proceedings_ 84: 406–411. 

Arthur, W. B. 2011. _The Nature of Technology: What It Is and How It Evolves._ New York: Free Press. 

Ashenfelter, Orley. 2010. “Predicting the Quality and Prices of Bordeaux Wine.” _Journal of Wine Economics_ 5, no. 1: 40–52. 

Athey, Susan, Jonathan Levin, and Enrique Seira. 2011. “Comparing Open and Sealed Bid Auctions: Evidence from Timber Auctions.” _Quarterly Journal of Economics_ 126, no. 1: 207–257. 

Austin, David. 2008. “Percolation: Slipping Through the Cracks.” American Mathematical Society. [http://www.ams.org/publicoutreach/feature-column/fcarc-percolation.](http://www.ams.org/publicoutreach/feature-column/fcarc-percolation.) 

Axelrod, Robert. 1984. _The Evolution of Cooperation._ New York: Basic Books. 

Axelrod, David, Robert Axelrod, and Kenneth J. Pienta. 2006. “Evolution of Cooperation Among Tumor Cells.” _Proceedings of the National Academy of Sciences_ 103, no. 36: 13474–13479. 

Axtell, Robert L. 2001. “Zipf Distribution of U.S. Firm Sizes.” _Science_ 293: 1818–1820. 

Bajari, Patrick, and Matthew E. Kahn. 2008. “Estimating Hedonic Models of Consumer Demand with an Application to Urban Sprawl.” In _Hedonic Methods in Housing Markets,_ 129–155. New York: Springer. 

Bak, Per. 1996. _How Nature Works: The Science of Self-Organized Criticality._ New York: Springer. 

Baldwin, Carliss Y., and Kim B. Clark. 2000. _Design Rules. Vol. 1, The Power of Modularity_. Cambridge, MA: MIT Press. 

Ball, Eric, and Joseph LiPuma. 2012. _Unlocking the Ivory Tower:_ 

---

 How Management Research Can Transform Your Business. Palo Alto, CA: Kauffman Fellow Press. 

Banzhaf, John F. 1965. “Weighted Voting Doesn’t Work: A Mathematical Analysis.” _Rutgers Law Review_ 19, no. 2: 317–343. 

Barber, Gerald M. 1997. “Sequencing Highway Network Improvements: A Case Study of South Sulawesi.” _Economic Geography_ 53, no. 1: 55–69. 

Bass, Frank. 1969. “A New Product Growth Model for Consumer Durables.” _Management Science_ 15, no. 5: 215–227. 

Baxter, G. William. 2009. “The Dynamics of Foraging Ants.” Paper presented at the annual meeting of the American Physical Society, March 16–20, abstract H40.00011. 

Bednar, Jenna. 2007. “Credit Assignment and Federal Encroachment.” _Supreme Court Economic Review_ 15: 285–308. 

Bednar, Jenna. 2008. _The Robust Federation: Principle of Design._ Cambridge: Cambridge University Press. 

Bednar, Jenna, Aaron Bramson, Andrea Jones-Rooy, and Scott E. Page. 2010. “Emergent Cultural Signatures and Persistent Diversity: A Model of Conformity and Consistency.” _Rationality and Society_ 22, no. 4: 407–444. 

Bednar, Jenna, and Scott E. Page. 2007. “Can Game(s) Theory Explain Culture? The Emergence of Cultural Behavior Within Multiple Games.” _Rationality and Society_ 19, no. 1: 65–97. 

Bednar, Jenna, and Scott E. Page. 2018. “When Order Affects Performance: Culture, Behavioral Spillovers and Institutional Path Dependence.” _American Political Science Review_ 112, no. 1: 82– 98. 

Bell, Alex, Raj Chetty, Xavier Jaravel, Neviana Petkova, and John Van Reenen. 2018 “Who Becomes an Inventor in America? The Importance of Exposure to Innovation: Executive Summary.” [http://www.equality-of-opportunity.org.](http://www.equality-of-opportunity.org.) 

Bendor, Jonathan, Daniel Diermeier, and Michael Ting. 2003. “A Behavioral Model of Turnout.” _American Political Science Review_ 97, no. 2: 261–280. 

---

Bendor, Jonathan, and Piotr Swistak. 1997. “The Evolutionary Stability of Cooperation.” _American Political Science Review_ 91: 290–307. 

Bendor, Jonathan, and Scott E. Page. 2018. “A Model of Team Problem Solving.” Unpublished manuscript. 

Berg, Nathan, and Gerd Gigerenzer. 2010. “As-If Behavioral Economics: Neoclassical Economics in Disguise?” _History of Economic Ideas_ 18, no. 1: 133–166. 

Bergemann, Dirk, and Juuso Välimäki. 2008. “Bandit Problems.” In _The New Palgrave Dictionary of Economics,_ 2nd ed., ed. Steven N. Durlauf and Lawrence E. Blume. London: Palgrave Macmillan. 

Berlekamp, Elwyn R., John H. Conway, and Richard K. Guy. 1982. “What Is Life?” In _Winning Ways for Your Mathematical Plays_. Vol. 2, _Games in Particular_. London: Academic Press. 

Bertrand, Marianne, and Sendhil Mullainathan. 2001. “Are CEOs Rewarded for Luck? The Ones Without Principles Are.” _Quarterly Journal of Economics_ 116: 901–932. 

Bickel, P. J., E. A. Hammel, and J. W. O’Connell. 1974. “Sex Bias in Graduate Admissions: Data from Berkeley.” _Science_ 187 (4175): 398–404. 

Biernaskie, Jay, M. 2011. “Evidence for Competition and Cooperation Among Climbing Plants.” _Proceedings of the Royal Society B_ 278: 1989–1996. 

Bird, Rebecca, and Eric Smith. 2004. “Signaling Theory, Strategic Interaction, and Symbolic Capital.” _Current Anthropology_ 46, no. 2: 222–248. 

Boldrin, Michele, and David Levine. 2010. _Against Intellectual Monopoly_. Cambridge: Cambridge University Press. 

Borges, Jorge Luis. 1974. _A Universal History of Infamy._ Trans. Norman Thomas de Giovanni. London: Penguin. 

Bowers, Jake, Nathaniel Higgins, Dean Karlan, Sarah Tulman, and Jonathan Zinman. 2017. “Challenges to Replication and Iteration in Field Experiments: Evidence from Two Direct Mail Shots.” _American Economic Review Papers & Proceedings_ 107, no. 5: 

---

#### 1–3. 

Bowles, Samuel, and Herbert Gintis. 2002. “The Inheritance of Inequality.” _Journal of Economic Perspectives_ 16, no. 3: 3–30. 

Box, George E. P., and Norman Draper. 1987. _Empirical ModelBuilding and Response Surfaces_. New York: Wiley. 

Boyd, Robert. 2006. “Reciprocity: You Have to Think Different.” _Journal of Evolutionary Biology_ 19: 1380–1382. 

Breiman, Leo. 1996. “Bagging Predictors.” _Machine Learning_ 24, no. 2: 123–140. 

Briggs, Andrew, and Mark Sculpher. 1998. “An Introduction to Markov Modeling for Economic Evaluation.” _Pharmaco Economics_ 13, no. 4: 397–409. 

Brock, William, and Steven Durlauf. 2001. “Discrete Choice with Social Interactions.” _Review of Economic Studies_ 68: 235–260. 

Broido, A. D., and A. Clauset. 2018. “Scale-Free Networks Are Rare.” Working paper. 

Bshary, R., and A. S. Grutter. 2006. “Image Scoring and Cooperation in a Cleaner Fish Mutualism.” _Nature_ 441, no. 7096: 975–978. 

Burt, Ronald. 1995. _Structural Holes: The Social Structure of Competition._ Cambridge, MA: Harvard University Press. 

Bush, Robert, and Frederick Mosteller. 1954. _Stochastic Models for Learning._ New York: John Wiley and Sons. 

Camerer, Colin F. 2003. _Behavioral Game Theory: Experiments in Strategic Interaction._ Princeton, NJ: Princeton University Press. 

Camerer, Colin, Linda Babcock, George Loewenstein, and Richard Thaler. 1997. “Labor Supply of New York City Cabdrivers: One Day at a Time.” _Quarterly Journal of Economics_ 112, no. 2: 407– 441. 

Camerer, Colin, and Tek Ho. 1999. “Experience-Weighted Attraction Learning in Normal Form Games.” _Econometrica_ 67, no. 4: 827– 

874. Camerer, Colin, George Loewenstein, and Drazen Prelec. 

2005. “Neuroeconomics: How Neuroscience Can Inform Economics.” _Journal of Economic Literature_ 43: 9–64. 

---

Campbell, Donald T. 1976. “Assessing the Impact of Planned Social Change.” Public Affairs Center, Dartmouth College. 

Campbell, James E., Bryan J. Dettrey, and Hongxing Yin. 2010. “The Theory of Conditional Retrospective Voting: Does the Presidential Record Matter Less in Open-Seat Elections?” _Journal of Politics_ 72, no. 4: 1083–1095. 

Cancian, Maria, and Deborah Reed. 1999. “The Impact of Wives’ Earnings on Income Inequality: Issues and Estimates.” _Demography_ 36, no. 2: 173–184. 

Carvalho, Vasco, and Xavier Gabaix. 2013 “The Great Diversification and Its Undoing,” _American Economic Review_ 103, no. 5: 1697– 1727. 

Castellano, Claudio, Santo Fortunato, and Vittorio Loreto. 2009. “Statistical Physics of Social Dynamics.” _Review of Modern Physics_ 81: 591–646. 

Cederman, Lars Erik. 2003. “Modeling the Size of Wars: From Billiard Balls to Sandpiles.” _American Political Science Review_ 97: 135–150. 

Centola, Damon, and Michael Macy. 2007. “Complex Contagions and the Weakness of Long Ties.” _American Journal of Sociology_ 113: 702–734. 

Chance, Donald. 2009. “What Are the Odds? Another Look at DiMaggio’s Streak.” _Chance_ 22, no. 2: 33–42. 

Christakis, N. A., and J. Fowler. 2009. _Connected: The Surprising Power of Our Social Networks and How They Shape Our Lives._ New York: Little, Brown. 

Churchland, Patricia, and Terry J. Sejnowski. 1992. _The Computational Brain._ Cambridge, MA: MIT Press. 

Chwe, Michael. 2013. _Jane Austen: Game Theorist_. Princeton, NJ: Princeton University Press. 

Clarida, Richard, Jordi Galí, and Mark Gertler. 2000. “Monetary Policy Rules and Macroeconomic Stability: Evidence and Some Theory.” _Quarterly Journal of Economics_ 115, no. 1: 147–180. 

Clark, Gregory. 2014. _The Son Also Rises: Surnames and the_ 

---

 History of Social Mobility. Princeton, NJ: Princeton University Press. 

Clark, William, Matt Golder, and Sona Nadenicheck Golder. 2008. _Principles of Comparative Politics._ Washington, DC: Congressional Quarterly Press. 

Clauset, Aaron, M. Young, and K. S. Gleditsch. 2007. “On the Frequency of Severe Terrorist Attacks.” _Journal of Conflict Resolution_ 51, no. 1: 58–88. 

Cohen, Tyler. 2013. _Average Is Over: Powering America Beyond the Age of the Great Stagnation._ New York: Dutton. 

Cooke, Nancy J., and Margaret L. Hilton, eds. 2014. _Enhancing the Effectiveness of Team Science._ Washington, DC: National Academies Press. 

Cornes, Richard, and Todd Sandler. 1996. _The Theory of Externalities, Public Goods, and Club Goods._ 2nd ed. Cambridge: Cambridge University Press. 

Craine, Joseph, and Ray Dybzinski. 2013. “Mechanisms of Plant Competition for Nutrients, Water and Light.” _Functional Ecology_ 27: 833–840. 

Cyert, Richard M., and James G. March. 1963. _A Behavioral Theory of the Firm_. Englewood Cliffs, NJ: Prentice-Hall. 

Dan, Avi. 2018. “How Michelle Peluso Is Redefining Marketing at IBM.” _Forbes,_ January 18. 

Dann, Carrie. 2016. “Pro-Clinton Battleground Ad Spending Outstrips Trump Team by 2.” NBC News, November 4. 

Dawes, Robyn. 1979. “The Robust Beauty of Improper Linear Models in Decision Making.” _American Psychologist_ 34: 571–582. 

de Marchi, Scott. 2005. _Computational and Mathematical Modeling in the_ 

_Social Sciences_. Cambridge: Cambridge University Press. 

DeMiguel, Victor, Lorenzo Garlappi, and Raman Uppal. 2009. “Optimal Versus Naive Diversification: How Inefficient Is the Portfolio Strategy?” _Review of Financial Studies_ 22, no. 5: 1915– 

---

#### 1953. 

Dennett, Daniel C. 1991. _Consciousness Explained_. Boston: Back Bay Books. 

Dennett, Daniel C. 1994. _Darwin’s Dangerous Idea: Evolution and the Meanings of Life._ New York: Simon & Schuster. 

Denrell, Jerker, and Chengwei Liu. 2012. “Top Performers Are Not the Most Impressive When Extreme Performance Indicates Unreliability.” _Proceedings of the National Academy of Sciences_ 109, no. 24: 9331–9336. 

Diamond, Jared. 2005. _Collapse: How Societies Choose to Fail or Succeed_. New York: Viking Penguin. 

Dodds, Peter, Robby Muhamad, and Duncan Watts. 2003. “An Experimental Study of Search in Global Social Networks.” _Science_ 301: 827–829. 

Downing, John A., et al. 2006. “The Global Abundance and Size Distribution of Lakes, Ponds, and Impoundments.” _Limnology and Oceanography_ 51, no. 5: 2388–2397. 

Dragulescu, Adrian, and Victor M. Yakovenko. 2001. “Exponential and Power-Law Probability Distributions of Wealth and Income in the United Kingdom and the United States.” _Physica A_ 299: 213– 221. 

Drucker, Peter. 1969. _The Age of Discontinuity: Guidelines to Our Changing Society._ New York: Harper and Row. 

Dubos, Jean. 1987. _The White Plague: Tuberculosis, Man and Society._ New Brunswick, NJ: Rutgers University Press. 

Dunne, Anthony. 1999. _Hertzian Tales: Electronic Products, Aesthetic Experience and Critical Design._ London: Royal College of Art. 

Dyson, Freeman. 2004. “A Meeting with Enrico Fermi.” _Nature_ 427: 297. 

Easley, David, and Jon Kleinberg. 2010. _Networks, Crowds, and Markets: Reasoning About a Highly Connected World._ Cambridge: Cambridge University Press. 

---

Easley, David, Marcos Lopez de Prado, and Maureen O’Hara. 2012. “Flow Toxicity and Liquidity in a High Frequency World.” _Review of Financial Studies_ 24, no. 5: 1457–1493. 

Easterly, William, and Stanley Fischer. 1995. “The Soviet Economic Decline.” _World Bank Economic Review_ 9, no. 3: 341–371. 

Ebbinghaus, Herman. 1885. _Memory: A Contribution to Experimental Psychology._ Online in _Classics in the History of Psychology_. [http://psychclassics.yorku.ca/Ebbinghaus/index.htm.](http://psychclassics.yorku.ca/Ebbinghaus/index.htm.) 

Ehrenberg, Andrew. 1969. “Towards an Integrated Theory of Consumer Behaviour.” _Journal of the Market Research Society_ 11, no. 4: 305–337. 

Einstein, Albert. 1934. “On the Method of Theoretical Physics.” _Philosophy of Science_ 1, no. 2: 163–169. 

Eliot, Matt, Ben Golub, and Matthew Jackson. 2014. “Financial Networks and Contagion.” _American Economic Review_ 104, no. 10: 3115–3153. 

Eom, Young-Ho, and Hang-Hyun Jo. 2014. “Generalized Friendship Paradox in Complex Networks: The Case of Scientific Collaboration.” _Scientific Reports_ 4: 4603. 

Epstein, Josh. 2006. _Generative Social Science: Studies in AgentBased Computational Modeling_. Princeton, NJ: Princeton University Press. 

Epstein, Joshua. 2008. “Why Model?” _Journal of Artificial Societies and Social Simulation_ 11, no. 4: 12. 

Epstein, Joshua. 2014. _Agent Zero: Toward Neurocognitive Foundations for Generative Social Science_. Princeton, NJ: Princeton University Press. 

Ericsson, K. A. 1996. “The Acquisition of Expert Performance: An Introduction to Some of the Issues.” In _The Road to Excellence: The Acquisition of Expert Performance in the Arts and Sciences, Sports, and Games,_ ed. K. A. Ericsson, 1–50. Mahwah, NJ: Erlbaum. 

Fair, Raymond. 2012. _Predicting Presidential Elections and Other Things._ 2nd ed. Stanford, CA: Stanford University Press. 

---

Farmer, J. Doyne 2018. “Collective Awareness: A Conversation with J. Doyne Farmer." _The Edge_. https://www.edge.org/conversation/j doyne farmer-collective-awareness. 

Feld, Scott L. 1991. “Why Your Friends Have More Friends than You Do.” _American Journal of Sociology_ 96, no. 6: 1464–1477. 

Flegal, Katherine M., Brian K. Kit, Heather Orpana, and Barry I. Graubard. 2012. “Association of All-Cause Mortality with Overweight and Obesity Using Standard Body Mass Index Categories: A Systematic Review and Meta-analysis.” _Journal of the American Medical Association_ 309, no. 1: 71–82. 

Flores, Thomas, and Irfan Nooruddin. 2016. _Elections in Hard Times: Building Stronger Democracies in the 21st Century._ Cambridge: Cambridge University Press. 

Florida, Richard. 2005. _Cities and the Creative Class_. New York: Routledge. 

Foster, Dean, and H. Peyton Young. 2001. “On the Impossibility of Predicting the Behavior of Rational Agents.” _Proceedings of the National Academy of Sciences_ 98, no. 22: 12848–12853. 

Frank, Kenneth, et al. 2018. “Teacher Networks and Educational Opportunity.” In _Handbook on the Sociology of Education,_ ed. Barbara Schneider and Guan Saw. New York: Oxford University Press. 

Frank, Robert. 1984. _Choosing the Right Pond_. Oxford: Oxford University Press. 

Frank, Robert. 1996. _The Winner-Take-All Society: Why the Few at the Top Get So Much More than the Rest of Us._ New York: Penguin. 

Freeman, Richard, and Wei Huang. 2015. “Collaborating with People Like Me: Ethnic Co-authorship Within the U.S.” _Journal of Labor Economics_ 33 no. S1: S289-S318. 

Fudenberg, Drew, and David Levine. 1998. _Theory of Learning in Games._ Cambridge, MA: MIT Press. 

Fudenberg, Drew, and David Levine. 2006. “A Dual-Self Model of Impulse Control.” _American Economic Review_ 96: 1449–1476. 

---

Gammill, James F., Jr., and Terry A. Marsh. 1988. “Trading Activity and Price Behavior in the Stock and Stock Index Futures Markets in October 1987.” _Journal of Economic Perspectives_ 2, no. 3: 25– 44. 

Gawande, Atul. 2009. _The Checklist Manifesto: How to Get Things Right_. New York: Henry Holt. 

Geithner, Timothy. 2014. _Stress Test: Reflections on Financial Crises._ New York: Crown. 

Gerschenkron, Alexander. 1952. “Economic Backwardness in Historical Perspective.” In _The Progress of Underdeveloped Areas_ , ed. B. F. Hoselitz. Chicago: University of Chicago Press. 

Gertner, Jon. 2012. _The Idea Factory: Bell Labs and the Great Age of American Innovation._ New York: Penguin. 

Gibrat, Robert. 1931. _Les inégalités economique_. Paris: Sirely. 

Gigerenzer, Gerd, and Reinhard Selten. 2002. _Bounded Rationality: The Adaptive Toolbox._ Cambridge, MA: MIT Press. 

Gigerenzer, Gerd, and Peter Todd. 2000. _Simple Heuristics That Make Us Smart._ New York: Oxford University Press. 

Gilboa, Itzhak, and David Schmeidler. 1994. “Case-Based Decision Theory.” _Quarterly Journal of Economics_ 110: 605–639. 

Gilovich, Thomas, Amos Tversky, and R. Vallone. 1984. “The Hot Hand in Basketball: On the Misperception of Random Sequences.” _Cognitive Psychology_ 17, no. 3: 295–314. 

Glaeser, Edward, Bruce Sacerdote, and Jose Scheinkman. 1996. “Crime and 

Social Interactions.” _Quarterly Journal of Economics_ 111, no. 2: 507– 548. 

Glantz, Andrew. 2008. “A Tax on Light and Air: Impact of the Window Duty on Tax Administration and Architecture, 1696–1851.” _Penn History Review_ 15, no. 2: 18–40. 

Glasserman, Paul, and H. Peyton Young. 2014. “Contagion in Financial Networks.” Office of Financial Research Working Paper. 

Godard, Renee. 1993. “Tit for Tat Among Neighboring Hooded 

---

 Warblers.” Behavioral Ecology and Sociobiology 33, no. 1: 45– 50. 

Gode, Dhananjay K., and Shyam Sunder. 1993. “Allocative Efficiency of Markets with Zero-Intelligence Traders: Market as a Partial Substitute for Individual Rationality.” _Journal of Political Economy_ 101, no. 1: 119–137. 

Goldin, Claudia, and Lawrence F. Katz. 2008. _The Race Between Education and Technology._ Cambridge, MA: Harvard University Press. 

Gordon, Robert J. 2016. _The Rise and Fall of American Growth: The U.S. Standard of Living Since the Civil War._ Princeton, NJ: Princeton University Press. 

Granovetter, Mark. 1973. “The Strength of Weak Ties.” _American Journal of Sociology_ 78, no. 6: 1360–1380. 

Granovetter, Mark. 1978. “Threshold Models of Collective Behavior.” _American Journal of Sociology_ 83, no. 6: 1360–1443. 

Greenwood, Jeremy, Nezih Guner, Georgi Kocharkov, and Cezar Santos. 2014. “Marry Your Like: Assortative Mating and Income Inequality.” _American Economic Review: Papers & Proceedings_ 104, no 5: 348-353. 

Greif, Avner. 2006. _Institutions and the Path to the Modern Economy: Lessons from Medieval Trade._ Cambridge: Cambridge University Press. 

Griliches, Zvi. 1957, 1988. “Hybrid Corn: An Exploration of the Economics of Technological Change.” In _Technology, Education and Productivity: Early Papers with Notes to Subsequent Literature_. New York: Basil Blackwell. 

Groseclose, Tim, and James Snyder. 1996. “Buying Supermajorities.” _American Political Science Review_ 90: 303– 315. 

Grossman, S., and J. Stiglitz. 1980. “On the Impossibility of Informationally Efficient Markets.” _American Economic Review_ 70, no. 3: 393–408. Groysberg, Boris. 2012. _Chasing Stars: The Myth of Talent and the Portability of Performance._ Princeton, NJ: 

---

 Princeton University Press. 

Guy, Richard. 1983. “Don’t Try to Solve These Problems.” _American Mathematical Monthly_ 90: 35–41. 

Haidt, Jonathan. 2006. _The Happiness Hypothesis: Finding Modern Truth in Ancient Wisdom._ Basic Books. New York: NY. 

Haldene, Andrew. 2012. “The Dog and the Frisbee.” Speech given at the Federal Reserve Bank of Kansas City’s 36th Economic Policy Symposium, Jackson Hole, WY. 

Haldene, Andrew. 2014. “The Dappled World.” Speech given at the University of Michigan Law School, Ann Arbor, October 23. 

Haldane, John B. S. 1928. “On Being the Right Size.” Online version available at [http://irl.cs.ucla.edu/papers/right-size.html.](http://irl.cs.ucla.edu/papers/right-size.html.) 

Hardin, Garret. 1968. “The Tragedy of the Commons.” _Science_ 162, no. 3859: 1243–1248. 

Harrell, Frank E. 2001. _Regression Modeling Strategies with Applications to Linear Models, Logistic Regression, and Survival Analysis_. New York: Springer. 

Harstad, Ronald M., and Reinhard Selten. 2013. “Bounded Rationality Models: Tasks to Become Intellectually Competitive.” _Journal of Economic Literature_ 51, no. 2: 496–511. 

Harte, John. 1988. _Consider a Spherical Cow._ Mill Valley, CA: University Science Books. 

Hathaway, Oona. 2001. “Path Dependence in the Law: The Course and 

Pattern of Change in a Common Law Legal System.” _Iowa Law Review_ 86. 

Havel, Václav. 1985. _The Power of the Powerless: Citizens Against the State in Central-Eastern Europe._ Ed. John Keane. Armonk, NY: M. E. Sharpe. 

Hawking, Stephen, and Leonard Mlodinow. 2011. _The Grand Design._ New York: Bantam. 

Hecht, Jeff. 2008. “Prophecy of Economic Collapse ‘Coming True.”’ _New Scientist_. November 17. 

---

Herrnstein, Richard J. 1970. “On the Law of Effect.” _Journal of the Experimental Analysis of Behavior_ 13: 243–266. 

Hills, Thomas, Peter M. Todd, David Lazer, A. David Redish, Iain D. Couzin, and the Cognitive Search Research Group. 2015. “Exploration Versus Exploitation in Space, Mind, and Society.” _Trends in Cognitive Science_ 19, no. 1: 46–54. 

Hofstadter, Douglas, and Emmanuel Sander. 2013. _Surfaces and Essences: Analogy as the Fuel and Fire of Thinking._ New York: Basic Books. 

Holland, John. 1975. _Adaptation in Natural and Artificial Systems._ Ann Arbor: University of Michigan Press. 

Hong, Lu, and Scott E. Page. 2009. “Interpreted and Generated Signals.” _Journal of Economic Theory_ 144: 2174–2196. 

Hotelling, Harold. 1929. “Stability in Competition.” _Economic Journal_ 39, no. 153: 41–57. 

Huffaker, Carl Burton. 1958. “Experimental Studies on Predation: Dispersion Factors and Predator-Prey Oscillations.” _Hilgardia_ 27, no. 14: 343–383. 

Hurwicz, Leo, and David Schmeidler. 1978. “Outcome Functions Which Guarantee the Existence and Pareto Optimality of Nash Equilibria.” _Econometrica_ 46: 144–174. 

Inman, Mason. 2011. “Sending Out an SOS.” _Nature Climate Change_ 1: 180–183. 

International Monetary Fund. 2009. _Global Financial Stability Report_. 

Jackson, Matthew. 2008. _Social and Economic Networks._ Princeton, NJ: Princeton University Press. 

Jackson, Matthew and Asher Wolinsky. 1996. “A Strategic Model of Social and Economic Networks.” _Journal of Economic Theory_ 71: 44–74. 

Jacob, Francois. 1977. “Evolution and Tinkering.” _Science_ 196: 1161–1166. 

Jacobs, Jane. 1989. _Revolving Doors: Sex Segregation and Women’s Careers_. Stanford, CA: Stanford University Press. 

---

Johnson, James. 2014. “Models Among the Political Theorists.” _American Journal of Political Science_ 58, no. 33: 547–560. 

Johnson-Laird, Philip. 2009. _How We Reason._ New York: Oxford University Press. 

Jones, Benjamin F., Brian Uzzi, and Stefan Wuchty. 2008. “MultiUniversity Research Teams: Shifting Impact, Geography and Social Stratification in Science.” _Science_ 322: 1259–1262. 

Jones, Charles, and Jihee Kim. 2018 “A Schumpeterian Model of Top Income Inequality.” _Journal of Political Economy._ Forthcoming. 

Kahneman, Daniel. 2011. _Thinking Fast and Slow_. New York: Farrar, Straus and Giroux. 

Kahneman, Daniel, and Amos Tversky. 1979. “Prospect Theory: An Analysis of Decisions Under Risk.” _Econometrica_ 47, no. 2: 263– 291. 

Kalyvas, Stathis. 1999. “The Decay and Breakdown of Communist One-Party Systems.” _Annual Review of Political Science_ 2: 323– 343. 

Kamin, Leon J. 1969. “Predictability, Surprise, Attention and Conditioning.” In _Punishment and Aversive Behavior,_ ed. B. A. Campbell and R. M. Church, 279–296. New York: AppletonCentury-Crofts. 

Kaplan, Steven, and Joshua D. Rauh. 2013a. “Family, Education, and Sources of Wealth Among the Richest Americans, 1982– 2012.” _American Economic Review Papers and Proceedings_ 103, no. 3: 158–162. 

Kaplan, Steven, and Joshua D. Rauh. 2013b. “It’s the Market: The Broad-Based Rise in the Return to Top Talent.” _Journal of Economic Perspectives_ 27, no. 3: 35–56. 

Karlsson, Bengt. 2016. “The Forest of Our Lives: In and Out of Political Ecology.” _Conservation and Society_ 14, no. 4: 380–390. 

Kauffman, Stuart. 1993. _The Origins of Order: Self-Organization and Selection in Evolution._ Oxford: Oxford University Press. 

Kennedy, John F. 1956. _Profiles in Courage_. New York: Harper & 

---

 Brothers. 

Khmelev, Dmitri, and F. J. Tweedie. 2001. “Using Markov Chains for Identification of Writers.” _Literary and Linguistic Computing_ 16, no. 4: 299–307. 

Kleinberg, Jon, and M. Raghu. 2015. “Team Performance with Test Scores.” Working paper, Cornell University School of Information. 

Knox, Grahame. n.d. “Lost at Sea.” _Insight_ , [http://insight.typepad.co.uk/lost_at_sea.pdf.](http://insight.typepad.co.uk/lost_at_sea.pdf.) 

Kollman, Ken, J. Miller, and S. Page. 1992. “Adaptive Parties in Spatial Elections.” _American Political Science Review_ 86: 929– 937. 

Kooti, Farshad, Nathan O. Hodas, and Kristina Lerman. 2014. “Network Weirdness: Exploring the Origins of Network Paradoxes.” Paper presented at the International Conference on Weblogs and Social Media (ICWSM), March. 

Kurlansky, Mark. 1998. _Cod: A Biography of the Fish That Changed the World._ New York: Penguin. 

Kydland, Finn E., and Edward C. Prescott. 1977. “Rules Rather than Discretion: The Inconsistency of Optimal Plans.” _Journal of Political Economy_ 85, no. 3: 473–491. 

Lai, T. L., and Herbert Robbins. 1985. “Asymptotically Efficient Adaptive Allocation Rules.” _Advances in Applied Mathematics_ 6, no. 1: 4–22. 

Laibson, David. 1997. “Golden Eggs and Hyperbolic Discounting.” _Quarterly Journal of Economics_ 112, no. 2: 443–477. 

Lamberson, P. J., and Scott E. Page. 2012a. “The Effect of Feedback Variability on Success in Markets with Positive Feedbacks.” _Economics Letters_ 114: 259–261. 

Lamberson, P. J., and Scott E. Page. 2012b. “Tipping Points.” _Quarterly Journal of Political Science_ 7, no. 2: 175–208. 

Lancaster, Kelvin J. 1966. “A New Approach to Consumer Theory.” _Journal of Political Economy_ 74: 132–157. 

Landemore, Helene. 2013. _Democratic Reason: Politics, Collective_ 

---

 Intelligence, and the Rule of the Many. Princeton, NJ: Princeton University Press. 

Lango, Allen H., et al. 2010. “Hundreds of Variants Clustered in Genomic Loci and Biological Pathways Affect Human Height.” _Nature_ 467, no. 7317: 832–838. 

Langville, Amy N., and Carl D. Meyer. 2012. _Who’s #1?: The Science of Rating and Ranking_. Princeton, NJ: Princeton University Press. 

Lave, Charles, and James G. March. 1975. _An Introduction to Models in the Social Sciences._ Lanham, MD: University Press of America. 

Ledyard, John, David Porter, and Antonio Rangle. 1997. “Experiments Testing Multiobject Allocation Mechanisms.” _Journal of Economics and Management Strategy_ 6, no. 3: 639– 675. 

Ledyard, John, David Porter, and Randii Wessen. 2000. “A MarketBased 

Mechanism for Allocating Space Shuttle Secondary Payload Priority.” _Experimental Economics_ 2, no. 3: 173–195. 

Levins, Richard. 1966. “The Strategy of Model Building in Population Biology.” _American Scientist_ 54: 421–431. 

Levinthal, Daniel A. 1997. “Adaptation on Rugged Landscapes.” _Management Science_ 43: 934–950. 

Levinthal, Daniel. 1991. “Random Walks and Organizational Mortality.” _Administrative Science Quarterly_ 36, no. 3: 397–420. 

Levitt, Steven, and Stephen Dubner. 2009. _SuperFreakonomics: Global Cooling, Patriotic Prostitutes, and Why Suicide Bombers Should Buy Life Insurance._ New York: William Morrow. 

Lewis, Michael. 2014. _Flash Boys: A Wall Street Revolt._ New York: W. W. Norton. 

Limpert, Eckhard, Werner A. Stahel, and Markus Abbt. 2001. “Lognormal Distributions Across the Sciences: Keys and Clues.” _BioScience_ 51, no. 5: 341–352. 

---

Little, Daniel. 1998. _Microfoundations, Method, and Causation: On the Philosophy of the Social Sciences._ Piscataway, NJ: Transaction Publishers. 

Lo, Andrew W., and A. Craig MacKinlay. 2007. _A Non-Random Walk Down Wall Street._ Princeton, NJ: Princeton University Press. 

Lo, Andrew W. 2012. “Reading About the Financial Crisis: A TwentyOne-Book Review.” _Journal of Economic Literature_ 50, no. 1: 151–178. 

Lucas, Robert. 1976. “Econometric Policy Evaluation: A Critique.” In _The Phillips Curve and Labor Markets,_ ed. K. Brunner and A. Meltzer, 19–46. Carnegie-Rochester Conference Series on Public Policy 1. New York: Elsevier. 

Lucking-Reiley, David. 1999. “Using Field Experiments to Test Equivalence Between Auction Formats: Magic on the Internet.” _American Economic Review_ 89, no. 5: 1063–1080. 

MacKenzie, Debora. 2012. “Boom and Doom: Revisiting Prophecies of Collapse.” _New Scientist_ , January. 

Mannes, Albert E., Jack B. Soll, and Richard P. Larrick. 2014. “The Wisdom of Select Crowds.” _Journal of Personality and Social Psychology_ 107: 276–299. 

Markowitz, Harold M. 1952. “Portfolio Selection.” _Journal of Finance_ 7, no. 1: 77–91. 

Markus, Greg B. 1988. “The Impact of Personal and National Economic Conditions on the Presidential Vote: A Pooled CrossSectional Analysis.” _American Journal of Political Science_ 32: 137–154. 

Martin, Andrew D., and Kevin M. Quinn. 2002. “Dynamic Ideal Point Estimation via Markov Chain Monte Carlo for the U.S. Supreme Court, 1953–1999.” _Political Analysis_ 10: 134–153. 

Martin, Francis, et al. 2008. “The Genome of _Laccaria bicolor_ Provides Insights into Mycorrhizal Symbiosis.” _Nature_ 452: 88– 92. 

Martinez Peria, Maria Soledad, Giovanni Majnoni, Matthew T. Jones, and Winfrid Blaschke. 2001. “Stress Testing of Financial 

---

 Systems: An Overview of Issues, Methodologies, and FSAP Experiences.” IMF Working Paper no. 01/88. 

Mas-Colell, Andreu, Michael D. Whinston, and Jerry R. Green. 1994. _Microeconomic Theory._ New York: Oxford University Press. 

Mauboussin, Michael. 2012. _The Success Equation: Untangling Skill and Luck in Business_. Cambridge, MA: Harvard University Press. 

May, Robert M., Simon A. Levin, and George Sugihara. 2008. “Ecology for Bankers.” _Nature_ 451: 893–895. 

McCarty, Nolan. 2011. “Measuring Legislative Preferences.” In _Oxford Handbook of Congress,_ ed. Eric Schickler and Frances Lee. New York: Oxford University Press. 

McCarty, Nolan, and Adam Meirowitz. 2014. _Political Game Theory: An Introduction_. Cambridge: Cambridge University Press. 

McKelvey, Richard. 1979. “General Conditions for Global Intransitivities in Formal Voting Models.” _Econometrica_ 47: 1085– 1112. 

McPhee, William N. 1963. _Formal Theories of Mass Behaviour._ New York: Free Press of Glencoe. 

Meadows, D., G. Meadows, J. Randers, and W. W. Behrens III. 

1972. _The Limits to Growth._ New York: Universe Books. 

Medin, Douglas, Will Bennis, and Michel Chandler. 2010. “The Home-Field Disadvantage.” _Perspectives on Psychological Science_ 5, no. 6: 708–713. 

Merriam, Daniel F., and John C. Davis. 2009. “Using Zipf’s Law to Predict Future Earthquakes in Kansas.” _Transactions of the Kansas Academy of Science_ 112, nos. 1&2: 127–129. 

Merton, Robert C. 1969. “Lifetime Portfolio Selection Under Uncertainty: The Continuous-Time Case.” _Review of Economics and Statistics_ 51, no. 3: 247–257. 

Merton, Robert K. 1963. “Resistance to the Systematic Study of Multiple Discoveries in Science.” _European Journal of Sociology_ 4, no. 2: 237–282. 

Milgrom, Paul, and John Roberts. 1986. “Pricing and Advertising 

---

 Signals of Product Quality.” Journal of Political Economy 94, no. 4: 796–821. 

Miller, John H. 1998. “Active Nonlinear Tests (ANTs) of Complex Simulation Models.” _Management Science_ 44, no. 6: 820–830. 

Miller, John H. 2015. _A Crude Look at the Whole_. New York: Basic Books. 

Miller, John H., and Scott E. Page. 2004. “The Standing Ovation Problem.” _Complexity_ 9, no. 5: 8–16. 

Miller, John H., and Scott E. Page. 2007. _Complex Adaptive Systems: An Introduction to Computational Models of Social Life_. Princeton, NJ: Princeton University Press. 

Miller, Joshua B., and Adam Sanjurjo. 2015. “Surprised by the Gambler’s and Hot Hand Fallacies: A Truth in the Law of Small Numbers.” IGIER Working Paper no. 552. 

Mitchell, Melanie. 1996. _An Introduction to Genetic Algorithms_. Cambridge, MA: MIT Press. 

Mitchell, Melanie. 2009. _Complexity: A Guided Tour._ Oxford: Oxford University Press. 

Mlodinow, Leonard. 2009. _The Drunkard’s Walk: How Randomness Rules Our Lives._ New York: Penguin. 

Mokyr, Joel. 2002. _The Gifts of Athena: Historical Origins of the Knowledge Economy._ Princeton, NJ: Princeton University Press. 

Morgan, John, and Tanjim Hossain. 2006. “... Plus Shipping and Handling: Revenue (Non)Equivalence in Field Experiments on eBay.” _Advances in Economic Analysis & Policy_ 6, no. 2: 3. 

Moss-Racusin, Corinne, John F. Dovidio, Victoria L. Brescoll, Mark J. Graham, and Jo Handelsman. 2012. “Science Faculty’s Subtle Gender Biases Favor Male Students.” _Proceedings of the National Academy of Sciences._ 1647–1649. 

Munger, Charles. 1994. “A Lesson on Elementary, Worldly Wisdom as It Relates to Investment Management & Business.” University of Southern California Business School. 

Murphy, Kevin M., and Robert H. Topel. 2016. “Human Capital 

---

 Investment, Inequality and Growth.” Journal of Labor Economics 34: 99–127. 

Murray, J. D. 1988. “Mammalian Coat Patterns: How the Leopard Gets Its Spots.” _Scientific American_ 256: 80–87. 

Myerson, Roger B. 1999. “On the Value of Game Theory in Social Science." _Rationality and Society_ 4: 62–73. 

Myerson, Roger B. 1999. “Nash Equilibrium and the History of Economic Theory.” _Journal of Economic Literature_ 37, no. 3: 1067–1082. 

Nagel, Rosemarie. 1995. “Unraveling in Guessing Games: An Experimental Study.” _American Economic Review_ 85, no. 5: 1313–1326. 

Newman, Mark E. 2005. “Power Laws, Pareto Distributions and Zipf’s Law.” _Contemporary Physics_ 46: 323–351. 

Newman, Mark E. 2010. _Networks: An Introduction._ Oxford: Oxford University Press. 

Nowak, Martin. 2006. “Five Rules for the Evolution of Cooperation.” _Science_ 314, no. 5805: 1560–1563. 

Nowak, Martin A., and Karl Sigmund. 1998. “Evolution of Indirect Reciprocity by Image Scoring.” _Nature_ 393: 573–577. 

Olson, Mancur. 1965. _The Logic of Collective Action: Public Goods and the Theory of Groups_. Cambridge, MA: Harvard University Press. 

O’Neil, Cathy 2016. _Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy._ New York, NY: Crown. 

Open Science Collaboration. 2015. “Estimating the Reproducibility of Psychological Science.” _Science_ 349: 6251. 

Organization for Economic Co-operation and Development. 1996. _The Knowledge Based Economy_. Paris: OECD. 

Ormerod, Paul. 2012. _Positive Linking: How Networks Can Revolutionise the World._ London: Faber and Faber. 

Ostrom, Elinor. 2004. _Understanding Institutional Diversity_. 

---

 Princeton, NJ: Princeton University Press. 

Ostrom, Elinor. 2010. “Beyond Markets and States: Polycentric Governance of Complex Economic Systems.” _Transnational Corporations Review_ 2, no. 2: 1–12. 

Ostrom, Elinor, Marco A. Janssen, and John M. Anderies. 2007. “Going Beyond Panaceas.” _Proceedings of the National Academy of Sciences_ 104: 15176–15178. 

Ostrovsky, Michael, Benjamin Edelman, and Michael Schwarz. 2007. “Internet Advertising and the Generalized Second Price Auction: Selling Billions of Dollars Worth of Keywords.” _American Economic Review_ 97, no. 1: 242–259. 

Paarsch, Harry J., and Bruce S. Shearer. 1999. “The Response of Worker Effort to Piece Rates: Evidence from the British Columbia Tree-Planting Industry.” _Journal of Human Resources_ 34, no. 4: 643–667. 

Packer, Craig, and Anne E. Pusey. 1997. “Divided We Fall: Cooperation Among Lions.” _Scientific American,_ May, 52–59. 

Paczuski, Maya, and Kai Nagel. 1996. “Self-Organized Criticality and 1 _/f_ Noise in Traffic.” arXiv: cond-mat/9602011. 

Page, Scott E. 1997. “An Appending Efficient Algorithm for Allocating Public Projects with Complementarities,” _Journal of Public Economics_ 64, no 3: 291–322. 

Page, Scott E. 2001. “Self Organization and Coordination.” _Computational Economics_ 18: 25–48. 

Page, Scott E. 2006. “Essay: Path Dependence.” _Quarterly Journal of Political Science_ 1: 87–115. 

Page, Scott E. 2007. _The Difference: How the Power of Diversity Creates Better Groups, Teams, Schools, and Societies_. Princeton, NJ: Princeton University Press. 

Page, Scott E. 2010a. _Diversity and Complexity_. Princeton, NJ: Princeton University Press. 

Page, Scott E. 2010b. “Building a Science of Economics for the Real World.” Presentation to the House Committee on Science and Technology Subcommittee on Investigations and Oversight, July 

---

#### 20. 

Page, Scott E. 2012. “A Complexity Perspective on Institutional Design.” _Politics, Philosophy and Economics_ 11: 5–25. 

Page, Scott E. 2017. _The Diversity Bonus_. Princeton, NJ: Princeton University Press. 

Pan, Jessica. 2014. “Gender Segregation in Occupations: The Role of Tipping and Social Interactions.” _Journal of Labor Economics_ 33, no. 2: 365–408. 

Parrish, Susan Scott. 2017. _The Flood Year 1927: A Cultural History_. Princeton, NJ: Princeton University Press. 

Parsa, H. G., John T. Self, David Njite, and Tiffany King. 2005. “Why Restaurants Fail.” _Cornell Hospitality Quarterly_ 46, no. 3: 304– 322. 

Patel, Kayur, Steven Drucker, James Fogarty, Ashish Kapoor, and Desney Tan. 2011. “Using Multiple Models to Understand Data.” _Proceedings of the International Joint Conference on Artificial Intelligence_ , 1723-1728. 

Peel, L., and A. Clauset. 2014. “Predicting Sports Scoring Dynamics with Restoration and Anti-Persistence.” _Proceedings of the International Conference on Data Mining_. Philadelphia: SIAM. 

Pfeffer, Fabian T., and Alexandra Killewald. 2017. “Generations of Advantage: Multigenerational Correlations in Family Wealth.” _Social Forces,_ 1–31. 

Piantadosi, Steven. 2014. “Zipf’s Word Frequency Law in Natural Language: A Critical Review and Future Directions.” _Psychonomic Bulletin & Review_ 21, no. 5: 1112–1130. 

Pierson, Paul. 2004. _Politics in Time: History, Institutions, and Social Analysis_. Princeton, NJ: Princeton University Press. 

Piketty, Thomas. 2014. _Capital in the 21st Century._ Trans. Arthur Goldhammer. Cambridge, MA: Belknap Press. 

Pollack, John. 2014. _Shortcut: How Analogies Reveal Connections, Spark Innovation, and Sell Our Greatest Ideas._ New York: Gotham. 

---

Poole, Keith T., and Howard Rosenthal. 1984. “A Spatial Model for Legislative Roll Call Analysis.” _American Journal of Political Science_ 29, no. 2: 357–384. 

Porter, David, and Vernon Smith. 2007. “FCC Spectrum Auction Design: A 12-Year Experiment.” _Journal of Law, Economics, and Policy_ 3, no. 1: 63–80. 

Powell, Robert. 1991. “Absolute and Relative Gains in International Relations Theory.” _American Political Science Review_ 85, no. 4: 1303–1320. 

Przeworski, Adam, Jose Antonio Cheibub, Michael E. Alvarez, and Fernando Limongi. 2000. _Democracy and Development: Political Institutions and Material Well-Being in the World, 1950–1990._ Cambridge: Cambridge University Press. 

Raby, Fiona. 2001. _Design Noir: The Secret Life of Electronic Objects_. Basel: Birkhauser. 

Ramo, Joshua Cooper. 2016. _The Seventh Sense: Power, Fortune, and Success, in the Age of Networks._ New York: Little, Brown and Company. 

Rand, David G., Hisashi Ohtsukia, and Martin A. Nowak. 2009. “Direct Reciprocity with Costly Punishment: Generous Tit-for-Tat Prevails.” _Journal of Theoretical Biology_ 256, no. 1: 45–57. 

Rapoport, Anatol. 1978. “Reality-Simulation: A Feedback Loop.” _Sociocybernetics,_ 123–141. 

Rauch, Jeffrey. 2012. _Hyperbolic Partial Differential Equations and Geometric Optics._ Graduate Studies in Mathematics. Providence, RI: American Mathematical Society. 

Rawls, John. 1971. _A Theory of Justice_. Cambridge, MA: Harvard University Press. 

Rescorla, Robert, and Allan Wagner. 1972. “A Theory of Pavlovian Conditioning: Variations in the Effectiveness of Reinforcement and Non-reinforcement.” In _Classical Conditioning II,_ ed. A. H. Black and W. F. Prokasy, 64–99. New York: Appleton-CenturyCrofts. 

Reynolds, Noel B., and Arlene Saxonhouse. 1994. _Three_ 

---

 Discourses. Chicago: University of Chicago Press. 

Roberts, D. C., and D. L. Turcotte. 1998. “Fractality and SelfOrganized Criticality of Wars.” _Fractals_ 6: 351–357. 

Roberts, Seth. 2004. “Self-Experimentation as a Source of New Ideas: Ten Examples About Sleep, Mood, Health, and Weight.” _Behavioral and Brain Sciences_ 27, no. 2: 227–262 

Romer, Paul. 1986. “Increasing Returns and Long-Run Growth.” _Journal of Political Economy_ 94: 1002–1037. 

Rosen, Sherwin. 1981. “The Economics of Superstars.” _American Economic Review_ 71: 845–858. 

Roth, Alvin, and Ido Erev. 1995. “Learning in Extensive Form Games: Experimental Data and Simple Dynamic Models in the Intermediate Term.” _Games and Economics Behavior_ 8: 164– 212. 

Russakoff, Dale. 2015. _The Prize: Who’s in Charge of America’s Schools?_ Boston: Houghton Mifflin Harcourt. 

Rust, Jon. 1987. “Optimal Replacement of GMC Bus Engines: An Empirical Model of Harold Zurcher.” _Econometrica_ 55, no. 5: 999–1033. 

Ryall, Michael D., and Aaron Bramson _Inference and Intervention: Causal Models for Business Analysis._ New York: Routledge. 

Salganik, Matthew, Peter Dodds, and Duncan J. Watts. 2006. “Experimental Study of Inequality and Unpredictability in an Artificial Cultural Market.” _Science_ 311: 854–856. 

Samuelson, Paul. 1964. “Proof That Properly Anticipated Prices Fluctuate Randomly.” _Industrial Management Review_ 6: 41–49. 

Schiller, Robert. 2004. _Irrational Exuberance._ 2nd ed. Princeton, NJ: Princeton University Press. 

Schrodt, Philip. 1998. “Pattern Recognition of International Crises Using Hidden Markov Models.” In _Non-Linear Models and Methods in Political Science,_ ed. Diana Richards. Ann Arbor: University of Michigan Press. 

Schwartz, Christine R., and Robert D. Mare. 2004. “Trends in 

---

 Educational Assortative Marriage from 1940 to 2003.” Demography 42, no. 4: 621–646. 

Schelling, Thomas. 1978. _Micromotives and Macrobehavior_. New York: W. W. Norton. 

Scott, Steven L. 2010. “A Modern Bayesian Look at the Multi-Armed Bandit.” _Applied Stochastic Models in Business and Industry_ 26: 639–658. Shalizi, Cosma, and Andrew C. Thomas. 2011. “Homophily and Contagion Are Generically Confounded in Observational Social Network Studies.” _Sociological Methods and Research_ 40: 211–239. 

Shapiro, Thomas, Tatjana Meschede, and Sam Osoro. 2013. “The Roots of the Widening Racial Wealth Gap: Explaining the BlackWhite Economic Divide.” Research and Policy Brief, Institute on Assets and Social Policy, Brandeis University, Waltham, MA. 

Shi, Xiaolin, Lada A. Adamic, Belle L. Tseng, and Gavin S. Clarkson. 

2009. “The Impact of Boundary Spanning Scholarly Publications and Patents.” _PLoS ONE_ 4, no. 8: e6547. 

Silver, Nate. 2012. _The Signal and the Noise: Why So Many Predictions Fail—but Some Don’t._ New York: Penguin. 

Simler, Kevin, and Robin Hanson. 2018. _The Elephant in the Brain: Hidden Motives in Everyday Life_. Oxford: Oxford University Press. 

Simmons, Matthew, Lada Adamic, and Eytan Adar. 2011. “Memes Online: Extracted, Subtracted, Injected, and Recollected.” Paper presented at the International Conference on Web and Social Media. 

Slaughter, Ann Marie. 2017. _The Chessboard and the Web: Strategies of Connection in a Networked World._ New Haven, CT: Yale University Press. 

Smaldino, Paul. 2013. “Measures of Individual Uncertainty for Ecological Models: Variance and Entropy.” _Ecological Modelling_ 254: 50–53. 

Small, Dana M., Robert J. Zatorre, Alain Dagher, Alan C. Evans, and Marilyn Jones-Gotman. 2001. “Changes in Brain Activity Related 

---

 to Eating Chocolate: From Pleasure to Aversion.” Brain 124, no. 9: 1720–1733. 

Smith, Eric, Rebecca Bliege Bird, and D. Bird. 2003. “The Benefits of Costly Signaling: Meriam Turtle Hunters.” _Behavioral Ecology_ 14: 116–126. 

Smith, Vernon. 2002. “Constructivist and Ecological Rationality.” Nobel Prize lecture. 

Sneppen, Kim, Per Bak, Henrik Flyvbjerg, and Mogens Jensen. 

1994. “Evolution as a Self-Organized Critical Phenomenon.” _Proceedings of the National Academy of Sciences_ 92: 5209– 5213. 

Solow, Robert M. 1956. “A Contribution to the Theory of Economic Growth.” _Quarterly Journal of Economics_ 70, no. 1: 65–94. 

Spence, A. Michael. 1973. “Job Market Signaling.” _Quarterly Journal of Economics_ 87, no. 3: 355–374. 

Squicciarini, Mara, and Nico Voigtländer. 2015. “Human Capital and Industrialization: Evidence from the Age of Enlightenment.” _Quarterly Journal of Economics_ 30, no. 4: 1825–1883. 

Starfield, Anthony, Karl Smith, and Andrew Bleloch. 1994. _How to Model It: Problem Solving for the Computer Age._ Minneapolis, MN: Burgess International. 

Stein, Richard A. 2011. “Superspreaders in Infectious Diseases.” _International Journal of Infectious Diseases_ 15, no. 8: e510– e513. 

Sterman, John D. 2000. _Business Dynamics: Systems Thinking and Modeling for a Complex World_. New York: McGraw-Hill. 

Sterman, John. 2006. “Learning from Evidence in a Complex World.” _American Journal of Public Health_ 96, no. 3: 505–515. 

Stiglitz, Joseph. 2013. _The Price of Inequality: How Today’s Divided Society Endangers Our Future._ New York: W. W. Norton. 

Stock, James H., and Mark W. Watson. 2003. “Has the Business Cycle Changed and Why?” In _National Bureau of Economic Research Macroeconomics Annual 2002_ , vol. 17, ed. Mark Gertler and Kenneth Rogoff, 159–218. Cambridge, MA: MIT 

---

 Press. 

Stone, Lawrence D., Colleen M. Keller, Thomas M. Kratzke, and Johan P. Strumpfer. 2014. “Search for the Wreckage of Air France Flight AF 447.” _Statistical Science_ 29, no. 1: 69–80. 

Storchmann, Karl. 2011. “Wine Economics: Emergence, Developments, Topics.” _Agrekon_ 50, no. 3: 1–28. 

Suki, Bela, and Urs Frey. 2017. “A Time Varying Biased Random Walk Model of Growth: Application to Height from Birth to Childhood.” _Journal of Critical Care_ 38: 362–370. 

Suroweicki, James. 2006. _The Wisdom of Crowds_. New York: Anchor Press. 

Syverson, Chad. 2007. “Prices, Spatial Competition, and Heterogeneous Producers: An Empirical Test.” _Journal of Industrial Economics_ 55, no. 2: 197–222. 

Taleb, Nassim. 2001. _Fooled by Randomness_. New York: Random House. Taleb, Nassim. 2007. _The Black Swan: The Impact of the Highly Improbable_. New York: Random House. 

Taleb, Nassim. 2012. _Antifragile: Things That Gain from Disorder_. New York: Random House. 

Tassier, Troy. 2013. _The Economics of Epidemiology._ Amsterdam: Springer. 

Tetlock, Phillip. 2005. _Expert Political Judgment: How Good Is It? How Can We Know?_ Princeton, NJ: Princeton University Press. 

Thaler, R. H. 1981. “Some Empirical Evidence on Dynamic Inconsistency.” _Economic Letters_ 8, no. 3: 201–207. 

Thompson, Derek. 2014. “How You, I, and Everyone Got the Top 1 Percent All Wrong: Unveiling the Real Story Behind the Richest of the Rich.” _Atlantic,_ March 30. 

Thorndike, Edward L. 1911. _Animal Intelligence._ New York: Macmillan. 

Tilly, Charles. 1998. _Durable Inequality_. Berkeley: University of California Press. 

Tsebelis, George. 2002. _Veto Players: How Political Institutions_ 

---

 Work. Princeton, NJ: Princeton University Press. 

Turchin, Peter. 1998. _Quantitative Analysis of Movement: Measuring and Modeling Population Redistribution in Animals and Plants._ Sunderland, MA: Sinauer Associates. 

Tweedle, Valerie, and Robert J. Smith. 2012. “A Mathematical Model of Bieber Fever: The Most Infectious Disease of Our Time?” In _Understanding the Dynamics of Emerging and Re-Emerging Infectious Diseases Using Mathematical Models,_ ed. Steady Mushayabasa and Claver P. Bhunu. Cham, Switzerland: Springer. 

Ugander, Johan, Brian Karrer, Lars Backstrom, and Cameron Marlow. 2011. “The Anatomy of the Facebook Social Graph.” arXiv:1111.4503. 

Updike, John. 1960. “Hub Fans Bid Adieu.” _New Yorker,_ October 22. 

US Bureau of Labor Statistics. 2013. _Consumer Expenditures in 2011_. Report 1042, April. Washington, DC: BLS. 

Uzzi, Brian, Satyam Mukherjee, Michael Stringer, and Ben Jones. 

2013. “Atypical Combinations and Scientific Impact.” _Science_ 342: 468–471. 

Van Noorden, Richard. 2015. “Interdisciplinary Research by the Numbers.” _Nature,_ September 16. 

von Neumann, John, and Morgenstern, Oskar. 1953. _Theory of Games and Economic Behavior._ Princeton, NJ: Princeton University Press. 

Vriend, Nicolaas J. 2000. “An Illustration of the Essential Difference Between Individual and Social Learning, and Its Consequences for Computational Analyses.” _Journal of Economic Dynamics and Control_ 24: 1–19. 

Wainer, Howard. 2009. _Picturing the Uncertain World._ Princeton, NJ: Princeton University Press. 

Wakeland, W., A. Nielsen, and P. Geissert. 2015. “Dynamic Model of Non-medical Opioid Use Trajectories and Potential Policy Interventions.” _American Journal of Drug and Alcohol Abuse_ 41, no. 6: 508–518. 

---

Waltz, Kenneth. 1979. _Theory of International Politics_. New York: McGraw-Hill. 

_Washington Post_. 2012. “Mad Money: TV Ads in the 2012 Presidential Campaign.” [http://www.washingtonpost.com/wp-](http://www.washingtonpost.com/wp-) srv/special/politics/track-presidential-campaign-ads-2012. 

Watts, Duncan. 2011. _Everything Is Obvious Once You Know the Answer_. New York: Crown Business. 

Watts, Duncan, and Steven Strogatz. 1998. “Collective Dynamics of ‘Small-World’ Networks.” _Nature_ 393, no. 6684: 440–442. 

Weisberg, Michael. 2007. “Three Kinds of Idealization.” _Journal of Philosophy_ 104, no. 12: 639–659. 

Weisberg, Michael. 2012. _Simulation and Similarity: Using Models to Understand the World._ Oxford: Oxford University Press. 

Weisberg, Michael, and Muldoon, Ryan. 2009. “Epistemic Landscapes and the Division of Cognitive Labor.” _Philosophy of Science_ 76, no. 2: 225–252. 

Weitzman, Martin L. 1979. “Optimal Search for the Best Alternative.” _Econometrica_ 77: 641–654. 

Weitzman, Martin L. 1998. “Recombinant Growth.” _Quarterly Journal of Economics_ 2: 331–361. 

Wellman, Michael. 1990. “Fundamental Concepts of Qualitative Probabilistic Networks.” _Artificial Intelligence_ 44: 257–303. 

Wellman, Michael. 2013. “Head to Head: Does US High-Frequency Trading Need Stricter Regulatory Oversight? (YES).” _International Financial Law Review,_ September. 

West, Geoffrey. 2017. _Scale: The Universal Laws of Growth, Innovation, Sustainability, and the Pace of Life in Organisms, Cities, Economies, and Companies_. New York: Penguin. 

Whittle, Peter. 1979. “Discussion of Dr Gittins’ Paper.” _Journal of the Royal Statistical Society, Series B_ 41, no. 2: 148–177. 

Whitty, Robin W. 2017. “Some Comments on Multiple Discovery in Mathematics.” _Journal of Humanistic Mathematics_ 7, no. 1: 172– 188. 

---

Wigner, Eugene. 1960. “The Unreasonable Effectiveness of Mathematics in the Natural Sciences.” _Communications in Pure and Applied Mathematics_ 13, no. 1. 

Wilkinson, Richard, and Kate Pickett. 2009. _The Spirit Level: Why Greater Equality Makes Societies Stronger_. London: Bloomsbury. 

Wilson, David Sloan. 1975. “A Theory of Group Selection.” _Proceedings of the National Academy of Sciences_ 72, no. 1: 143–146. 

Wolfram, Stephen. 2001. _A New Kind of Science_. Champaign, IL: Wolfram Media. 

Wright, Robert. 2001. _Nonzero: The Logic of Human Destiny._ New York: Vintage. 

Wu, Jianzhong, and Robert Axelrod. 1995. “How to Cope with Noise in the Iterated Prisoner’s Dilemma.” _Journal of Conflict Resolution_ 39, no. 1: 183–189. 

Wuchty, Stefan, Benjamin F. Jones, and Brian Uzzi. 2007. “The Increasing Dominance of Teams in the Production of Knowledge.” _Science_ 316, no. 5827: 1036–1039. 

Xie, Yu. 2007. “Otis Dudley Duncan’s Legacy: The Demographic Approach to Quantitative Reasoning in Social Science.” _Research in Social Stratification and Mobility_ 25: 141–156. 

Xie, Yu, Alexandra Killewald, and Christopher Near. 2016. “Betweenand Within-Occupation Inequality: The Case of High Status Professions.” _Annals of the American Academy of Political and Social Science_ 663, no. 1: 53–79. 

Youn, Hyejin, Deborah Strumsky, Luis Bettencourt, and José Lobo. 

2015. “Inventions as a Combinatorial Process: Evidence From US Patents.” _Journal of the Royal Society Interfaces_ 12: 0272. 

Zagorsky, Jay. 2007. “Do You Have to Be Smart to Be Rich? The Impact of IQ on Wealth, Income and Financial Distress.” _Intelligence_ 35: 489–501. 

Zahavi, Amotz. 1974. “Mate Selection: A Selection for a Handicap.” _Journal of Theoretical Biology_ 53, no. 1: 205–214. 

Zak, Paul, and Stephen Knack. 2001. “Trust and Growth.” _Economic_ 

---

 Journal 111, no. 470: 295–321. 

Zaretsky, Adam. 1998. “Have Computers Made Us More Productive? A Puzzle.” _Regional Economist,_ Federal Reserve Bank of St. Louis. 

Ziliak, Stephen T., and Deirdre N. McCloskey. 2008. _The Cult of Statistical Significance: How the Standard Error Costs Us Jobs, Justice, and Lives._ Ann Arbor: University of Michigan Press. 

---

# Index 

academic papers, 5 act, using models to, 15 in REDCAPE, 21–23 adaptive exploration rate heuristic, 321 adaptive rules, 43 , 57 added value, 109 additivity, 110 adjustment, rate of, 307 adoption curve, 136 (fig.) r-shaped, 133 (fig.) Age of Enlightenment, 21 agency, 46 lack of, 47 agenda control, 234–236 agent-based models, 213 aggregation, 283 AIG. _See_ American International Group Air France, 23–24 Airbnb, 215–216 Alexander, Christopher, 151 algorithmic riots, 224 algorithms, 92 Allison, Graham, 10 Allstate insurance, 4 alternative reality approach, 14 alternative uses test, Shapley value and, 111–112, 112 (fig.) alternatives 

---

in hedonic competition model, 237 learning-the-best-alternative framework, 308 in spatial competition model, 230 altruism parameter, 273–274 Amazon, 4 American International Group (AIG), 21–22 Anasazi, 270 Anderson, Elizabeth, 213 Arab Spring, 30 Aristotle, 30 ARPANET, 104 Arrow’s theorem, 16 aspiration, 307 assortative mating, 350 attributes hedonic, 227 , 241 numbers of, 230–231 spatial, 227 , 230 in spatial competition model, 230–231 valence, 237 auctions ascending-bid, 287–289 first-price, 288 second-price, 288 Austen, Jane, 7–8 average degree in a network, 118 

backward induction, 247 Bacon, Francis, 21 bacteria, 97 bagging, many-model thinking and, 41–42 Baker, James, 224 balancing process, 166–167 Ball, Eric, 8–9 bargain threshold rule, 224 Bartlett, Robert, 321 

---

basic growth model, output in, 102 (fig.) basic reproduction number, defining, 138 basins of attraction, 330 , 332 (fig.) basketball, 157 Bass model, 136–137 Bayesian multi-armed bandit problems, 321–324 Beatles, 132 Bednar, Jenna, 283 behavioral rules, 284 belief-based learning rule, 316 beliefs, 14 in rational-actor model, 48 benchmarks rational choice and, 50 in rational-actor model, 51 Berkshire Hathaway, 154 Berlin Observatory, 24 Bernoulli bandit problems, 320–321 Bernoulli urn model, 154–155, 163 betweenness network structure and, 118 score, 119 bias immediacy, 52 psychological, 51–53 selection, 89 big coefficient, 89–90 big rocks first, 17 bin packing problem, 17 binary categorization model, 30–31 binary classifications, of data, 92–93 Bitcoin, 241–242 BlackRock, 4 block entropy, 326 blocks, 177 body mass index (BMI), 37–38 

---

Boldrin, Michele, 336–337 bootstrap aggregation, 42 Borges, Jorge Luis, 33 Botswana, 96 Box, George, 6 Boyle’s law, 19 broadcast model, 132–134 data and, 134 defined, 132 r-shaped adoption curve and, 133 (fig.) budget balance, 285 , 293 Buffett, Warren, 154 burning money, 304 Burt’s structural holes, 130 

Camerer, Colin, 316 Campbell’s law, 57 _Capital in the Twenty-First Century_ (Piketty), 348 capitalists, 348 carbon, 97–98 Carnegie, Andrew, 329 Castro, Fidel, 10 catastrophes, long-tailed distributions and, 76–77 categories data and, 34 models, 326 _The Categories_ (Aristotle), 30 categorization error, decreasing, 35 categorization models, 27 binary, 30–31 defining, 30–31 causation, correlation and, 86–87 Cavic, Milroad, 88 central limit theorem defining, 62 logic and, 62 

---

centrality, 130 CEO political capture, 347 chain store paradox, 247 chair trading, 187 China, 9 economic dominance of, 105 Churchill, Frank, 8 Clark, Gregory, 352 cleaner fish, 259 clique friends, 125 , 126 clustering bootstraps cooperation, 265 clustering coefficient, 119 network structure and, 118 coalitions, 108 Cobb-Douglas model, 99–100, 344 defining, 100 cod, 278 cognitive closure, many-model thinking and, 56–58 Cold War, 313 Collatz conjecture, 188 collective action problems defining, 271 solved, 280–281 unsolved, 280–281 Collins, Jim, 162 commodities, 239 common network structures, 121–122 communicable models, 14 communication, 15 in REDCAPE, 20–21 communities, 120 compatibility, incentive, 285–286, 288 , 293 competition. _See specific models_ completeness, in rational-actor model, 49 computational costs, 283 concave functions, 98–99 

---

concavity, 273 diversity and, 99 risk aversion and, 99 conditionality, 17 Condorcet jury theorem, 27 , 33 , 40 defining, 28 configurations, 182 conformity effect, 309 congestion, 185 model, 275–277 Congress, US, 229 , 230 (fig.), 233 conservatism, 89–90 consistency rational choice and, 50 in rational-actor model, 51 conspicuous consumption, 297 consumption, rational-actor model of, 48 consumption-investment equation, 101 content, 3 continuity, in rational-actor model, 49 continuous action games, 247–248 continuous function, entropy and, 146 continuous signals, 300 separation with, 301 convexity, 95–98 risk-loving and, 99 cooperation, 255 clustering bootstraps, 265 group selection and, 266 repetition and, 256–259 reputation and, 256–259 cooperative action model, 262–267 defining, 263 cooperative advantage, ratio of, 263 cooperative games, 108–110 defining, 108 

---

coordination model, 241 paradoxes of, 174 , 175 correlation, causation and, 86–87 costless signals, 298 craft traditions, 303 Craigslist, 105 _Crime and Punishment_ (Dostoyevsky), 8 critical states, 74 Croson, Rachel, 243 crowded markets, 239 price competition in, 239 (fig.) crowds, wisdom of, 30 Cuban missile crisis, 9 , 10 culture/strategy game, 318–319 cyclic, 147 

data, 12 binary classifications of, 92–93 broadcast model and, 134 categories and, 34 dimensionality of, 31 in identification problem, 250 interpretation of, 2 many-model thinking and, 3–4 mining, 86 organization of, 2 overfitting, 41 on piece-rate work, 3–4 in wisdom hierarchy, 7 death rule, 176 decision problems, public project, 292 decisions, 47 Markov models, 199 trees, 93 decomposability, of entropy, 146 

---

defection, 255 degeneration, 120 degree average, 118 of network formation, 123 in network structure, 118 of node, 118 degree squaring, 139–140 Deloitte, 4 Dennett, Daniel, 177–178 dependent variables, 84 depreciation rate, 101 design, 15 in REDCAPE, 20 Dewey, John, 305 Diamond, Jared, 269 , 278 diffusion model, 134–137 diffusion probability, 135 dimensionality, of data, 31 diminishing returns, 98 discounting, hyperbolic, 52 discrete dynamical systems, 182 discrete signals, 298–300 Disney World, 185 distribution defining, 59 exponential, 149 , 150 functions and, 63–66 lognormal, 60 , 66–67 long-tailed, 59 , 75–79 normal, 59–61, 61 (fig.), 65–66, 150 power-law, 69–73, 71 (fig.) uniform, 149 , 150 distributional assumptions, entropy and, 148–150 diversity, 46 , 58 concavity and, 99 

---

preference for, 99 diversity prediction theorem, 27 , 40 defining, 29 dominant strategies, 245 implementable, 285 Dostoyevsky, Fyodor, 8 double riots, 215–216 Dow Jones Industrial Average, 224 Downs, Anthony, 36 Downsian model, 229 , 231–240 due diligence, 9–10 Durlauf, Steven, 352–353 Dyson, Freeman, 41 

economic dominance, of China, 105 economic forecasts, 32 economic growth, 21 models, 4 , 99–105 eczema, 64 efficient markets hypothesis, 160 random walk models and, 159–161 effort game, equilibrium in, 248 Einstein, Albert, 15 electrical engineering, 24 Eliot, T. S., 7 embodiment approach, 13–14 emergent phenomena, 177 empathy, 58 empirical plots, 131 empirical studies, of prediction, 32 endogenous aspirations, 308 Enlightenment, Age of, 21 entropy axiomatic foundations of, 146–147 block, 326 

---

continuous function and, 146 decomposability of, 146 defining, 143 distributional assumptions and, 148–150 information, 144–146 maximal, 148–150 maximization and, 146 measures, 146 normative implications of, 150–151 outcomes and, 147–148 positive implications of, 150–151 symmetry and, 146 zero property of, 146 environmental noise, 85 equilibrium, 147 , 172 , 273 consumption level, 278 in effort game, 248 extinction, 205 interior, 205 in local majority model, 173 (fig.) long-run equilibrium output, 103 Nash, 244 , 262 , 275–277 subgame perfect, 246–247 suboptimal, 173 equilibrium path dependence, 164 equilibrium processes, 6 , 57 equity, long-tailed distributions and, 75–76 Erdos, Paul, 188 ergodicity, Perron-Frobenius theorem and, 193 error categorization, 35 measurement, 85 out-of-sample, 41 term, 84 valuation, 35 Escobar, Pablo, 97 

---

_Essence of Decision_ (Allison), 10–11 Euclid’s axioms, 16 experiments, 87 explanation, 15 prediction and, 24 in REDCAPE, 19 exploration, 15 REDCAPE and, 24–25 exponential distribution, 149 , 150 exponential growth model, 96 exponents, defining, 70 externalities, 20 extinction equilibrium, 205 

fairness, 111 Farmer, J. Doyne, 354 El-Farol problem, 55 fast thinking, 51 FDA. _See_ Food and Drug Administration, US Federal Reserve, US, 32 feedback negative, 201 , 211 , 220–222 positive, 69–70, 209–210, 345–346 Ferdinand, Franz, 167 Fermi, Enrico, 41 Ferrante, Elena, 83 Feynman, Richard, 59 financial collapse of 2008, 9 financial systems, systems dynamics models of, 209 (fig.) first fit algorithm, 18 first things first, 17 first-price auction, 288 fish, 280 fitness landscape model, 327–329 fixed transition rule, Perron-Frobenius theorem and, 193 flash crash, 225 

---

Flores, Thomas, 192 Food and Drug Administration, US (FDA), 64 Ford, Henry, 329 forest fire model, defining, 74 forests, 93 formalism, 18 Forrester, Jay Wright, 201 Frank, Anne, 253 free ride, 139 Freedom House, 192 (fig.) friendship paradox, 16 , 17 (fig.) defining, 124 full allocation, 111 functional signals, 302 functions, distribution and, 63–66 fundamental preferences, 240 

Game of Life, 14 , 171 , 176–178, 187 , 201 blinker in, 177 (fig.) patterns, 178 (fig.) games, 47 continuous action, 247–248 cooperative, 108–110 culture/strategy, 318–319 effort, 248 generous/spiteful, 313–315 Guzzler Game, 310–31 1 learning in, 310–313 Market Entry Game, 243 , 246 Minimize Risk Game, 245 normal-form zero-sum, 244–245 pure coordination, 174 repeated game model, 256 sequential, 246–247 subgame perfect equilibrium, 246–247 theory, 11–12 

---

Gates Foundation, 4 , 63 gender ratios, 218 generous/spiteful game, 313–315 geographic network, 119 (fig.), 120 , 122 (fig.) giant component, 127 Gilded Age, 104 Gittins index, 322 gliders, 177 global peak, 330 _Good to Great: Why Some Companies Make the Leap and Others Don’t_ (Collins), 162 Google, 4 , 32 , 195 , 196 , 295 gradient heuristic, 330 Granovetter’s model, 213–220 granularity, model, 222–223 granularity question, 33–35 graphs, spaghetti, 42 the Great Moderation, 78 Grim Trigger, 256–258, 262 Grossman and Stiglitz paradox, 160 group selection, 265–267 cooperation and, 266 growth. _See specific models_ growth rates, 278–279, 279 (fig.) Guzzler Game, 310–31 1 

habituation, 307 Haidt, Jonathan, 47 Haldane, J. B. S., 8 half or triple plus one rule (HOTPO), 188 half-life model, 97 defining, 98 Hamilton, Alexander, 195 Harry Potter series, 69 Havel, Václav, 232 Hawking, Stephen, 178 

---

Hawthorne, Nathaniel, 259 hedonic attributes, 227 model, 241 hedonic competition model, 236–240 alternatives in, 237 defining, 237 individual preferences in, 237 payoffs in, 237 valence attributes in, 237 weights in, 237 Heraclitus, 163 herd immunity, 139 heroin addiction, 342 heterogenous thresholds, relocations and, 218 (fig.) hierarchy, wisdom, 7–12 high-fidelity models, 33 high-performance, 64 hill-climbing algorithm, 330 HIV, 138 Ho, Tek, 316 Hotelling, 228–229, 228 (fig.) HOTPO. _See_ half or triple plus one rule hub-and-spoke network, 119 (fig.), 120 , 139 human capital model, 345 humility, 58 hybrid model of product competition, 238–240 hyperbolic discounting, 52 

Iceland, 8–9 ideal point, in spatial competition model, 230 identification problem data in, 250 sorting models in, 250 ideological polarization, 229 , 230 (fig.), 232 immediacy bias, 52 incentive compatibility, 285–286, 288 

---

efficiency, 293 income taxes, 17 independence, 32 in rational-actor model, 49 independent lies, many-model thinking and, 28–30 independent variable, 84 indifference, principle of, 149 individual learning, reinforcement and, 306–308 individual preferences, in hedonic competition model, 237 individually rational, 293 individuals, in spatial competition model, 230 induction, backward, 247 Industrial Revolution, 97 inequality, 5 many-model thinking for, 343–354 information, 12 , 283 in wisdom hierarchy, 7 information entropy, 144–146 defining, 145 innovation multiplier, 103 instrumental preferences, 240 intergenerational income, 351–352 interior equilibrium, 205 International Monetary Fund, 22 International Olympic Committee (IOC), 166–167 investment rule, 101 investment-depreciation equation, 101 IOC. _See_ International Olympic Committee iterative elimination, 245 

Jay, John, 195 JPMorgan Chase, 4 

Kahneman, D., 51–52 Kakutani, Shizuo, 153 , 157 Kennedy, John F., 10 

---

Khrushchev, Nikita, 10 , 11 , 104 kingmaker mechanism, 286–287 Kingston, Maxine Hong, 5 knowledge patenting, 336–337 Plato on, 8 

lagged cycles, 206 Lancaster model, 236 last-on-the-bus (LOTB) value, 108 , 115 law of effect, 307 law of large numbers, 154 le Clos, Chad, 88 Le Verrier, Urbain, 24 learning, 46 belief-based, 316 combining models, 315–318 in games, 310–313 rational choice and, 50 social, 308–310 learning-the-best-alternative framework, 308 Lehman Brothers, 10 , 22 Levine, David, 336–337 Levins, Richard, 28 Libby, Willard, 98 linear classifications, 92 linear functions, 83 linear models, 83–86, 105 defining, 84 multivariable, 87–90 linear regression model, 84 , 236 lines, 203 Lo, Andrew, 9–10 local majority model, 172–175 defining, 172 equilibrium in, 173 (fig.) 

---

stable lines in, 176 (fig.) location, 30 logic, 16 central limit theorem and, 62 network formation and, 122–123 power laws and, 73–75 structure-logic-function organization, 60 log-log plot, 72 lognormal distribution, 60 multiplying shocks and, 66–67 Long Term Capital Management (LTCM), 161 long-run equilibrium output, 103 long-tailed distributions, 59 catastrophes and, 76–77 contemplation of, 78–79 equity and, 75–76 implications of, 75–78 volatility and, 77–78 loss aversion, 52 LOTB value. _See_ last-on-the-bus value Lotka-Volterra equations, 202 , 205 , 207 Lotka-Volterra model, 205 LTCM. _See_ Long Term Capital Management Lucas critique, 57 , 58 Lyapunov functions, 181–183, 186 models without, 187–188 

Madison, James, 195 magnitude, 84 defining, 85 majority rule, 286–287 majority-vote equal sharing, 292 Mallon, Mary, 140 Malthus, Thomas, 97 , 209 many-model thinking, 40 bagging and, 41–42 

---

blind spots and, 2–3 classes in, 2 cognitive closure and, 56–58 data and, 3–4 defining, 1 independent lies and, 28–30 for inequality, 343–354 need for, 5–7 opioid epidemic and, 339–342 separability and, 11–12 for value, 241–242 maoi, 269–270 market creation, 215–216 Market Entry Game, 243 , 246 Markov model, 341 decision, 199 examples, 190–192 one-to-many and, 194–197 Matching Pennies, 244 Matthew effect, 70 Mauboussin, Michael, 88 maximal entropy, 148–150 maximization, entropy and, 146 Maybach Landaulet, 297 Mayer, Marissa, 227 McCarthy, Tom, 98 McDonald’s, 9 McKinsey, 4 mean in normal distribution, 60 regression to, 87 measurement error, 85 mechanism design, 283 median voter theorem, 232 medical school, 80 Merton, Robert, 69–70, 73 

---

message space, 284 metabolic rates, 38–39 micro-macro loop, 55 _Micromotives and Macrobehavior_ (Schelling), 184 Microsoft, 167 Milgram, Stanley, 124 Miller, John, 209–210 Minimize Risk Game, 245 Mirzakhani, Maryam, 181 Mississippi River Basin Model Waterways Experimentation Station, 23 model error decomposition theorem, defining, 35 model granularity, 222–223 modeling and models characteristics of, 6 of people, 46–47 power laws and, 73–75 practice of, 5 types of, 13–15 uses of, 15 models, of social phenomena, 44 monotonic ordering, 16 Monte Carlo method, for random networks, 121 Moore, Marianne, 131 Mount Fuji landscape, 328 , 328 (fig.), 334 Mount-Reiter diagram, 284–286 multi-armed bandit problems, 319 , 326 , 340 Bayesian, 321–324 multiple congestible goods, 277 multiple-variable regression, 88–89 multivariable linear models, 87–90 Munger, Charlie, 1 music lab experiments, 76 Myerson value, 130 myopic best response, 174 

---

Nash equilibrium, 244 , 262 , 275–277 National Institutes of Health, 4 National Milk Day, 229 nations failure of, 104–105 success of, 104–105 negative externality, 186–187 negative feedbacks, 201 systems dynamics models and, 211 threshold models with, 220–222 negatives, 92 neorealism, 313 net payoff, 288 network formation functions and, 123–126 logic and, 122–123 model, 123 quality and degree, 123 network robustness, 127–128 network size, random walk models and, 158–159, 158 (fig.) network structure betweenness and, 118 clustering coefficient and, 118 common, 121–122 defining, 118 degree in, 118 geographic, 119 (fig.), 120 , 122 (fig.) hub-and-spoke, 119 (fig.), 120 , 139 path length in, 118 power-law, 121 , 122 (fig.) random, 121 , 122 (fig.) rectangular grid, 139 small-world, 121 , 122 (fig.) new-reality thinking, 89–90 Newton’s first law, 5 Niarchos, Stavros, 37 

---

NK model, 331–334 defining, 332 Nobel Prize, 161 node failure, 127 (fig.) noise environmental, 85 traders, 224 non-excludability, 272 nonlinear classifications, 92–93 nonlinear models, 105–106 non-rivalry, 272 Nooruddin, Irfan, 192 normal distribution, 59 , 150 mean in, 60 Six Sigma methods, 65–66 with standard deviation, 61 (fig.) structure in, 60–61 symmetry of, 61 variance in, 60–61 normal random walk, 156 normal-form zero-sum games, 244–245 

objects, 332 Ocala, 241–242 Ockham, William, 15 Ockham’s Razor, 15 O’Keeffe, Georgia, 27 Olympics, 88 omitted variables, 84–85 Omnibus Budget Reconciliation Act, 20 one-to-many approach, 141–142 defining, 36 Markov model and, 194–197 one-to-many property, 27 online bubbles, 120 opioid epidemic, many-model thinking and, 339–342 

---

opportunity, 80–81 opposite proverbs, 18 ordering, preferences, 49 Oscars, 29 Ostrom, Elinor, 43 , 281 outcome function, 284 outcome path dependence, 164 outcomes, 164 , 165 (fig.) classes of, 147–148 entropy and, 147–148 out-of-sample error, 41 

PageRank, 195 , 197 (fig.) paradoxes chain store, 247 of coordination, 174 , 175 friendship, 16 , 17 (fig.), 124 Grossman and Stiglitz, 160 Parrondo’s, 16 sales-durability, 194 Simpson’s, 16 of skill, 88 Pareto domination, 284 Pareto efficiency, 284 Parrondo’s paradox, 16 partial pooling, 299 patenting, 336–337 path dependence, 167–168 tipping point and, 168 (fig.) path length, in network structure, 118 payoffs in hedonic competition model, 237 to neighbors, 264 (fig.) net, 288 in Prisoners’ Dilemma, 261 in spatial competition model, 230 

---

sucker’s, 256 peer effect models, 250 people, modeling, 46–47 percentage, of variance, 34 Perron-Frobenius theorem, 192–194 defining, 193 ergodicity and, 193 fixed transition rule and, 193 noncyclic, 193 states in, 193 persistent inequality model, 352–353 Phelps, Michael, 88 Piaget, Jean, 13 Piketty, Thomas, 348 ping-pong model, 220 defining, 221 response threshold in, 221 system state in, 221 time series for, 222 (fig.) pivot mechanism, 293 , 294 placebos, 65 Plato, on knowledge, 8 players, 108 Plott’s no-winner result, 234 pluralism, 104 Polya process, 163–166, 198 applications, 168–169 defining, 164 extension of, 166 pooling, 299 population, doubling, 209–210 positioning, 30 positive feedbacks, 69–70, 209–210 model, 345–346 potentials, 203 poverty traps, 353 

---

power seats and, 113 (fig.) Shapley-Shubik index of, 112–114 power laws logic and, 73–75 models and, 73–75 power-law distributions, 69 defining, 70 structure of, 70–73 World Wide Web and, 71 (fig.) power-law network, 121 , 122 (fig.) predator-prey model, 204–207 systems dynamics models of, 205 prediction, 15 empirical studies of, 32 explanation and, 24 REDCAPE and, 23—24 predictive models, 241–242 preferences, 14 fundamental, 240 instrumental, 240 ordering, 49 preferential attachment model, 73 presidential elections, 326 price competition in crowded markets, 239 (fig.) in sparse markets, 239 (fig.) Princip, Gavrilo, 167 Prisoners’ Dilemma, 2 , 255–262, 255 (fig.) payoffs in, 261 probabilities contact, 135 diffusion, 135 sharing, 135 transition, 190 , 191 product competition, hybrid model of, 238–240 

---

production function, 101 program trading, 225 property rights, 104 proposer effects, 236 (fig.) prospect theory, defining, 52 psychological biases, in rational-actor model, 51–53 public goods, 272–275 public projects decision problems, 292 mechanisms for, 292–294 pure coordination games, 174 pure exchange economies, 186–187 p-value, 85–86 

quality and degree network formation, 123 quantity, 30 quantum computing, 80 

Race to the Bottom, 2 , 181 , 182 radial symmetry, 233 random, 147 random friends, 125 , 126 random mixing, 135 random networks, 122 (fig.) Monte Carlo method for, 121 random walk models, 155–158 efficient markets and, 159–161 network size and, 158–159, 158 (fig.) normal, 156 simple, 155 , 156 (fig.) rational actors, 43 , 45 , 56 rational choice arguments for, 50 benchmarks and, 50 consistency and, 50 learning and, 50 

---

stakes and, 50 uniqueness and, 50 rational-actor model, 10 , 11 beliefs in, 48 benchmarks in, 51 completeness in, 49 consistency in, 51 of consumption, 48 continuity in, 49 defining, 47–48 independence in, 49 psychological biases in, 51–53 transitivity in, 49 rationality, 45 individual, 293 realism, 14 messiness and, 50 reason, in REDCAPE, 15–18 rectangular grid network, 139 REDCAPE, 13 , 355 communication in, 20–21 defining, 15 design in, 20 explanation and, 19 exploration and, 24–25 prediction and, 23—24 reason in, 15–18 regression line, 85 (fig.) regression to the mean, 87 reinforcement, individual learning and, 306–308 relocations, 218 heterogenous thresholds and, 218 (fig.) in Schelling’s segregation model, 220 (fig.) renewable resource extraction, 277–280 rent-from-capital model, 348 repeated game model, 256 

---

repetition, cooperation and, 256–259 replicator dynamics, 308–310, 312 replicator equation, 309 reputation, cooperation and, 256–259 resource extraction, renewable, 277–280 response threshold, in ping-pong model, 221 revenue equivalence theorem, 289–292 revolving-door model, 218 rewards, 307 distributions, 322 effect, 309 Richter scale, 71 riots, 213–214 algorithmic, 224 double, 215–216 model, 214–220 threshold, 214 risk aversion, concavity and, 99 risk dominance, 313 risk-loving, convexity and, 99 Rockefeller, John D., 329 Rometty, Ginni, 107 routine, 185 Rowling, J. K., 69 R-pentomino, 177 r-shaped adoption curve, broadcast model and, 133 (fig.) rugged landscapes, 330–331, 334–335 peaks, 331 (fig.) rule of 72, 96 , 105 , 349 rule of law, 104 rule-based actors, 43 rule-based behavior, 45 rule-playing behaviors, 259–262 

salaries in search model, 80–81 sales-durability paradox, 194 

---

sample-then-greedy, 320 , 321 Samuelson, Paul, 36 , 160 sand pile model, defining, 74 savings rate, 101 Saxonhouse, Arlene, 195 scatterplot, 85 (fig.) Schelling, Thomas, 184 , 216 Schelling’s party model, 216 defining, 217 Schelling’s segregation model, 353 relocations in, 220 (fig.) tolerance threshold in, 219 seats, power and, 113 (fig.) second-price auction, 288 segregation models of, 216–220 production of, 217 (fig.) _See also_ Schelling’s segregation model selection bias, 89 self-organization, 75 , 184–186 self-organized criticality model, 74 self-organizing activities model, 185 separability, many-model thinking and, 11–12 separation, 298 , 299 with continuous signals, 301 sequential games, 246–247 sets testing, 87 training, 87 Shapley, Lloyd, 110 Shapley value, 107 , 108 alternative uses test and, 111–112, 112 (fig.) axiomatic basis for, 110–111 defining, 109 Shapley-Shubik index, 112–114 sharing probability, 135 

---

Shelley, Percy Bysshe, 189 shocks lognormal distribution and, 66–67 multiplication of, 66–67 sign, defining, 85 signals uses of, 301–302 value of, 301–302 significance, defining, 85 simple growth model, 101 simple random walk, 155 plot of, 156 (fig.) Simpson’s paradox, 16 sinks, 202 SIR model, 2 , 131 , 137–142 Six Degrees of Separation, 124 defining, 126 Six Sigma methods, normal distribution, 65–66 skill, paradoxes of, 88 skill-luck equation, 87–88 Slaughter, Anne-Marie, 117 slow thinking, 51 small-world network, 121 , 122 (fig.) social choice correspondence, 284 social learning, 308–310 social mobility, 351 social phenomena, models of, 44 socially optimal, 277 Solow* growth model, 102–104 defining, 103 sorting models, 250 Soviet Union, 11 , 104–105, 268 S&P 500, 154 spaghetti graph, 42 sparse markets, 239 price competition in, 239 (fig.) 

---

spatial attributes, 227 in spatial competition model, 230 spatial competition model, 228–229, 326 alternatives in, 230 attributes in, 230–231 defining, 230 Downsian, 231–240 ideal point in, 230 individuals in, 230 payoffs in, 230 spatial attributes in, 230 with Voronoi neighborhoods, 231 (fig.) square root rules, 63 stable lines, in local majority model, 176 (fig.) stakes, rational choice and, 50 standard deviation defining, 61 normal distribution with, 61 (fig.) stark probabilistic model, 32 State Farm insurance, 4 states, 190 statistical equilibrium, 189 status quo effects, 234–236 Stevens, Wallace, 339 stick, value as a shovel, 329 Stigler, George, 241 strong types, 299 , 301 structure, in normal distribution, 60–61 structure-logic-function organization, 60 stuffed-cheetah problem, 8–9 subgame perfect equilibrium, 246–247 suboptimal equilibrium, 173 substance, 30 success equation, 87 , 129 sucker’s payoff, 256 superspreaders, 139–140 

---

supertankers, 36–37, 37 (fig.) surprise principle, 307 symmetry, 111 entropy and, 146 of normal distribution, 61 radial, 233 system state, in ping-pong model, 221 systems dynamics models components of, 202 (fig.) of financial systems, 209 (fig.) guides to action and, 207–208 negative feedbacks and, 211 parts of, 202–204 of predator-prey model, 205 

Taleb, Nassim, 153 TARP. _See_ Troubled Asset Relief Program taxes, 211 Taylor, Frederick, 329 Taylorism, 329 temptations, 256 testing sets, 87 thinking fast, 51 slow, 51 Thoreau, Henry David, 171 Thorndike, Edward, 306–307 threshold models, with negative feedbacks, 220–222 time series, for ping-pong model, 222 (fig.) tipping point, 138 , 167–168 path dependence and, 168 (fig.) tolerance threshold, 217 in Schelling’s segregation model, 219 total disagreement, 183 , 184 (fig.) total value, 108 _Tractatus Logico-Philosophicus_ (Wittgenstein), 6 

---

training sets, 87 transition probabilities, 190 , 191 , 351 transition rule, 182 transition-to-addiction model, 341 transitivity, in rational-actor model, 49 TROLL, 260 Troubled Asset Relief Program (TARP), 21–22 truth-telling, 285 TurboTax, 76 Tversky, Amos, 51–52 two-dimensional median, 233 typhoid, 140 

uncertainty, 144 unconditional generosity, 303 uniform distribution, 149 , 150 uniqueness, rational choice and, 50 United States Air Force, 10–11 utility functions, 48–49 

vaccination threshold, 138 valence attributes, in hedonic competition model, 237 valuation error, defining, 35 value, 332 last-on-the-bus, 108 , 115 many-model thinking for, 241–242 of signals, 301–302 value at risk (VaR), 170 value function, 108 VaR. _See_ value at risk variables dependent, 84 independent, 84 multiple-variable regression, 88–89 multivariable linear models, 87–90 omitted, 84–85 

---

variance in normal distribution, 60–61 percentage of, 34 veto players, 234–236 Vinlanders, 270 volatility long-tailed distributions and, 77–78 VaR and, 170 voluntary participation, 285 von Neumann, John, 95 Voronoi neighborhoods, 231 spatial competition model with, 231 (fig.) 

Wainer, Howard, 63 Walmart, 78 Waltz, Kenneth, 313 Warbler males, 260 wasteful subsistence behavior, 303 weak ties, 125 weak types, 299 , 301 weights, 307 in hedonic competition model, 237 West, Geoffrey, 69 Wilhelm, Kaiser, 167 William III (King), 211 Williams, Serena, 319 wisdom hierarchy, 8–12 data in, 7 information in, 7 wisdom of crowds, 30 Wittgenstein, Ludwig, 6 Wolfram’s classes, 147 , 148 (fig.) _The Woman Warrior_ (Kingston), 5 women CEOs, 39 workers, 348 World War I, 167 

---

World War II, 37 World Wide Web, 195 , 196 (fig.) power-law distributions and, 71 (fig.) WORLD3 model, 208–210 proponents of, 210 

zero intelligence agents, 56 zero property, 111 of entropy, 146 zero-sum games, normal-form, 244–245 Zimbabwe, 96 Zipf’s law, defining, 72 Zuckerberg, Mark, 198 Zurcher, Harold, 50 

