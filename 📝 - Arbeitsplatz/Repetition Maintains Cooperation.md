In the repeated Prisoners’ Dilemma, Grim Trigger maintains cooperation if the probability of continued play, P , exceeds the ratio of the difference in the temptation payoff, T , and the reward payoff, R , to the temptation payoff:^5 

The result tells us that if the temptation payoff exceeds triple the reward payoff, _T >_ 3 _R_ , the game must be repeated with a probability in excess of two-thirds. The inequality also tells us that cooperation becomes easier to maintain if the reward increases, the probability of continued play increases, or the temptation to defect decreases. Each of these implications reveals an intuitive route to more cooperation: increase the reward, make continued interaction more probable, and reduce the temptation to defect. Though these are quite straightforward inferences, they might not have been at top of mind prior to writing the model. In pondering the necessary condition for cooperation, we can also infer less straightforward insights. The expression implies that if players thought that the probability of continuation would fall below the threshold in the future, then rational players would stop cooperating before the probability change occurs, not when the change occurs.^6 The logic that repetition supports cooperation among rational players hinges on a particular feature of the model: a probability of continuing play. If, instead, we had assumed a fixed number of repetitions—say, that the game was to be played three times— rational players would not cooperate, which we can prove by backward induction. Suppose that the game is only played three 

---

times and that the first player announces that she will play Grim Trigger. Assume that _T_ = 3, _R_ = 2, and _S_ = 1. Given these payoffs, if the second player cooperates in all three rounds, she earns a total payoff of 6. We need to check that no other strategy generates a higher payoff. Defecting in the first round produces a payoff of only 2, because after her defection the first player will defect in the last two rounds. Defecting in the second round produces a payoff of 5. Neither would be rational. Defecting in the third round, though, produces a payoff of 7: 2 in each of the first two periods, and 3 in the last period. Therefore, a rational player defects in the last round. The first player, who played Grim Trigger, should recognize the defection will occur in the third round and also defect. It then follows that the other player would realize that both players are going to defect in the third round and so would defect in the second round of the game. By the same logic, the first player would also defect. This unraveling would continue to the first round. The same reasoning applies if we repeat the game any finite number of times. In the last round played, rational players defect. As result, both have an incentive to defect in the second-to-last round, and so on and so on. The only rational strategy is to always defect. Our analysis so far considers two players in isolation. It does not take into account how a person’s defection might influence how others treat that person in future interactions. In effect, we drew a boundary around the two people playing the game. We can extend the model to include a community of people who monitor the behavior of one another and punish people who deviate. To do this formally, we assume that each day people randomly form pairs and play Prisoners’ Dilemma games. The members of the community believe that these games will go on forever, so the probability of future play equals 1. Under these assumptions, an individual will not be likely to play against the same person the next day, so the incentive to defect will be higher. However, we allow for the possibility that a defection can be recognized by the community. If so, the person earns a bad reputation and, by agreement, no one in the community will cooperate with that individual in the future. If 

---

we let _PD_ denote the probability that a person gets caught defecting, 

earns a reputation as a defector, and is punished in all future games, then the condition for cooperation to be maintained through reputations, , is identical to the condition for repetition to 

maintain cooperation, except that _PD_ , the probability that a person 

has been caught defecting, replaces _P_ , the probability of repeated play. In the reputation model, the community enforces cooperation. Someone who has defected and has been caught will be defected against by all future players. Here again, individuals calculate the benefits and costs of defecting. They must also believe that others will adhere to the punishment, which in this case means that all others will defect. For that to be true, individuals must either know one another or have some method of identifying or tagging past defenders. It follows that, all else equal, people in small communities should be better able to enforce cooperation through repetition. In small northern towns, people leave their cars running in store parking lots during the winter. They do not fear the car being stolen (a defection) because they know everyone in the town. Anyone who stole a car, even as a prank, would incur a reputation loss. Physical tags can make reputations public information in order to maintain cooperation. In Nathaniel Hawthorne’s novel _The Scarlet Letter,_ Hester Prynne is forced to wear a scarlet _A_ for committing adultery. Some cultures amputate the hands of convicted thieves, a rather costly tag. Tagging of defectors even occurs in other species. The cleaner fish, _Labroides dimidiatus,_ can clean parasites from other fish (cooperate) or consume tastier alternatives (defect). If a fish cooperates, its neighbors will be free of parasites. The lack of parasites is observable to other fish. The cleanliness of neighboring fish becomes a tag, a visual reputation.^7 

---