“As if”: Intelligent rule-based behavior may be indistinguishable from optimal or near-optimal behavior. 

 Learning: In situations that are repeated, people should approach optimal behavior. 

 Large stakes: On important decisions, people gather information and think slowly. 

 Uniqueness: Optimal behavior is often unique, making the model testable. 

 Consistency: Optimal behavior creates a consistent model. If people learn the model, they will not change their behavior. 

 Benchmark: Optimal behavior provides a benchmark as an upper bound on people’s cognitive abilities. 

Fifth, the rational-actor assumption guarantees internal consistency. If a model assumes suboptimal behavior and the model is in the public domain, the model can be learned. People can change their behavior. They might not optimize, but any assumption other than optimality is subject to the criticism that it is not consistent. We return to this point in the discussion at the end of the chapter. Last, and some would argue most important, rationality can function as a benchmark.^8 When designing a policy, making a prediction, or choosing an action, we should consider what would happen if people had rational preferences and optimized. That exercise may point to flaws in our thinking. We should also be open to the possibility that the exercise will lead us to conclude that the 

---

rational-actor model does not apply and that we should privilege other models instead. To this list we might add a seventh reason: many-model thinking. If people apply many models, they are less likely to make mistakes. 

---

### Psychological Biases 

The rational-actor model has been challenged by psychologists, economists, and neuroscientists, who note that it does not match up with how humans behave. Empirical findings from laboratory and natural experiments show that people suffer a variety of biases, including a status quo bias. We ignore base rates when making probability calculations, we attach too much significance to sure things, and we are loss-averse. As researchers begin to link behavior and beliefs to processes within the brain, evidence of hardwired biases becomes more compelling. For example, neuroeconomics uses brain imaging studies to study economically relevant behaviors such as attitudes toward risk, levels of confidence, and responses to information.^9 Kahneman argues that what we know so far supports making a distinction between two types of thinking: quick, intuitive rules ( _fast thinking_ ) and deliberate contemplation ( _slow thinking_ ). Fast thinking 

is more likely to be subject to the aforementioned biases.^10 In the long run, we may be able to infer some behavioral patterns from brain structures, but we should keep in mind that the brain has tremendous plasticity. It is capable of overcoming biases by thinking slowly. Further, we should be cautious about accepting as universal any finding documented in just a handful of studies. Many psychological findings have not proven robust. A recent study failed to replicate half of one hundred findings published in leading psychology journals.^11 Furthermore, replicability need not imply universality. Subject pools for many studies lack economic and cultural 

diversity.^12 We might expect that more diverse subject pools would produce fewer behavioral regularities, providing even greater reason to avoid generalizations about behavior. Last, in attempting to make more realistic models, we must keep tractability in mind. More realistic models may require more sophisticated mathematics.^13 None of these concerns is so 

---

persuasive to suggest abandoning models with psychologically realistic behaviors, but collectively they imply that we proceed with caution and emphasize well-documented behavioral regularities. Two deviations that have been replicated many times are loss aversion and hyperbolic discounting. _Loss aversion_ states that people are risk-averse over gains and risk-loving over losses. Kahneman and Tversky refer to this general theory of behavior as 

_prospect theory_.^14 Loss aversion does not at first appear irrational, but it implies that people choose different actions when an identical scenario is presented as a potential loss as opposed to a potential gain. For example, people prefer winning $400 for certain rather than entering a lottery with an even chance of winning $1,000. Yet they will enter a lottery with an even chance of losing $1,000 rather than lose $600 for certain. This same inconsistency extends to nonmonetary domains. Doctors given choices framed as gains are risk-averse. When choices are presented as losses, doctors take more risks.^15 

---