Assumption: An individual’s utility from general consumption, C , and housing, H , can be written as follows: 

 Result: A utility-maximizing individual (a rational actor) spends exactly one-third of her income on housing.^2 

In the model, the proportion of income a person spends on housing does not depend on the price of housing or on income. Both results are reasonable approximations of the data.^3 Other than people at the extremes of the income distribution, most people spend about a third of their income on housing. The finding has policy implications: if housing prices fall by 10%, people will buy 10% more housing. The finding also provides a justification for assuming identical agents. If people spend a fixed percentage of income on housing, total spending on housing depends only on average income. Using a utility function makes our models analyzable, testable, and tractable. We can estimate the functions with data, we can derive optimal actions, and we can ask “what if” questions by changing parameter values. In assuming a utility function, we imply a coherence to preferences that may not exist. For preferences to be representable by a utility function, they must satisfy certain axioms. Theorems that prove the existence of utility functions assume a set of alternatives along with a _preference ordering_. Imagine that we can list all possible bundles of goods a person might buy. A preference ordering ranks these bundles from most to least favored. A person might prefer coffee with milk to tea with lemon; if so, she ranks the bundle {coffee, milk} above the bundle {tea, lemon}. A utility function represents preferences if it assigns a higher 

---

value to bundle _A_ than bundle _B_ if and only if the preference ordering ranks _A_ above _B_. For preferences to be consistent with a utility function they must satisfy completeness, transitivity, independence, and continuity. _Completeness_ requires that the preference ordering is defined over all pairs of alternatives. _Transitivity_ rules out preference cycles. If someone prefers bundle _A_ to bundle _B_ and bundle _B_ to bundle _C_ , she must also prefer _A_ to _C_. In other words, if a person prefers apples to bananas and bananas to cheese, then she must also prefer apples to cheese. This condition rules out inconsistent preferences. _Independence_ requires that people evaluate the outcomes in a lottery separately. A lottery is a probability distribution over alternatives, such as a 60% probability of _A_ and a 40% probability of _B_. Preferences satisfy independence if when _A_ ranks above _B_ , then in any lottery that includes _B_ as an outcome, the person prefers an alternative lottery in which we replace _B_ with _A_. Independence rules out strong risk aversion. A risk-averse person might rank a trip to New Orleans over a trip to Disney World but prefers knowing for certain that he will be going to Disney World over entering a lottery that sends him to New Orleans with probability and to Disney World 

otherwise. The final condition, _continuity,_ requires that if a person ranks _A_ above _B_ and _B_ above _C_ , then there exists a lottery in which she gets _A_ with probability _p_ and _C_ with probability (1 _− p_ ) that she likes exactly as much as _B_. This assumption also rules out strong preferences for certain outcomes.^4 The assumptions of independence and transitivity, which people violate, on top of the dubious claim that people optimize leads many to question the widespread use of the rational-actor model, particularly by economists. Yet there exist good reasons to assume rationality. First, people may act “as if” they optimize. They may apply rules that produce nearly optimal behavior. When people play pool, catch a Frisbee, or drive a car, they do not write down mathematical equations. The mathematics required to time a leap to catch a Frisbee would overwhelm almost anyone. Yet people catch Frisbees. So, by the way, do dogs. Thus, both people and dogs act 

---

as if we solve a difficult optimization problem. This same logic extends to high-dimensional problems. An analysis of the actions of Harold Zurcher, the superintendent of maintenance for the Metropolitan Bus Company in Madison, Wisconsin, found that he made near optimal decisions about when 

and whether to replace bus engines.^5 Though Zurcher did not write down any mathematics, he relied on heuristics. Those heuristics, informed by experience, meant that he acted (almost) as if he were a rational actor. Second, even if people do make mistakes, in cases where a situation is repeated, our capacity to learn should push us toward optimal actions. Third, in cases where the stakes are large, people should put in the time and energy to make near-optimal choices. People may overpay 30% for coffee or AAA batteries, but they do not overpay 30% for cars or houses. The claim that learning and higher stakes increase rationality has ample empirical and experimental support.^6 A fourth reason for adopting the rational-actor model, paradoxically, is that it simplifies the analysis. Most utility functions will have a unique optimal action. A person can behave suboptimally in thousands of ways. Saying that people do not optimize opens an enormous box of possibilities. If we assume people make choices to maintain their identities or to enforce cultural norms, we may lack a single clear answer. Rational choice is not realistic, but realism comes at the cost of messiness. An answer, even if it is known to be wrong, can be more useful then having no answer at all, as it allows us to bring the model to data and to work through the effects of 

changes in variables.^7 

---