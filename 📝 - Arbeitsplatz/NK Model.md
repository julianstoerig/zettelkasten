An object consists of N bits, s ∈ {0, 1} N. 

 The value of an object is V ( s ) = Vk 1 ( s 1 , { s 1 k }) + Vk 2 ( s 2 , { s 2 k }) + ··· + Vk 2 ( s 2 , { s 2 k }) where { sik } equals a randomly selected set of k bits other than i , and Vk 1 ( s 1 , { s 1 k }) is a random number drawn from the interval [0, 1]. 

 K = 0 : Results in a linear function of the bits. 

 K = N − 1 : Any bit change produces a new random contribution from each bit. 

The NK model framework provides a wonderful space to explore ideas and ask questions. The first question we ask is how the number of local optima depends on the number of interaction terms. We then ask how the height of the global optimum depends on the number of interaction terms. At the moment, both of those questions are ill-posed because we have yet to define how we are searching the space of possibilities, that is what heuristic we are using. Recall that what the set of peaks depend on our choice of heuristic. In what follows, we rely on the _single-flip algorithm_. This algorithm chooses each attribute in sequence and switches the attribute’s state. If changing this attribute results in a higher value, the switch is adopted. Otherwise the attribute is returned to its original state. The choice of this algorithm can be motivated in two ways. It can be interpreted as a crude model of genetic mutation, where good variants take over in the population and bad ones die. It is also the most natural way to represent a hill-climbing algorithm in this space. We first evaluate the NK model with _N_ = 20 and _K_ = 0. When _K_ = 0, each attribute’s contribution to the total value is independent of the 

---

other attributes. The single-flip algorithm can identify the better state for each attribute and the global optimum. Thus _K_ = 0, no interactions, corresponds to a Mount Fuji landscape. Each state’s value is uniformly distributed in the interval [0, 1]. It can be shown that the higher of two random draws from a uniform distribution has an expected value of. If we average the contributions across twenty 

attributes, the global optimum will also have an expected value of. At the other extreme, ( _N_ = _K_ − 1), each attribute is connected to every other attribute. When the state of an attribute is switched, the contribution of every attribute will change. It will be a new random number drawn uniformly from the interval [0, 1]. The value of the object will be the sum of these twenty new random numbers (one for each attribute), meaning that each flip of an attribute results in a value for the entire object that is uncorrelated with the earlier value. Thus, the landscape will be incredibly rugged—just as likely to go up at any point as it is to go down. By applying that insight, we can derive the expected number of local peaks. If we start from any alternative, the single-flip algorithm compares that alternative to each of _N_ alternatives. For example, starting from the alternative with all bits taking value zero, the algorithm will evaluate the _N_ alternatives in which exactly one bit takes value one. 

A local peak must have a higher value than each of these _N_ alternatives. The probability that the original alternative has the highest value equals. Therefore, the number of local peaks 

approximately equals the number of possible alternatives, 2 _N_ , divided by _N_. For _N_ = 20, that calculation yields fifty thousand local peaks. With so many local optima, the single-flip algorithm rarely locates the global peak. The relevant question is not the number of these local optima, but their values. It remains only to compare the expected average value 

---

of these local optima with the expected value of the global optimum. That comparison will determine how well the single-flip algorithm performs. To calculate theses values, we can use the central limit theorem. It is not difficult to show that the expected value of a local optimum equals approximately 0.6 while the expected value of the 

global optimum equals a little more than 0.75.^3 Comparing these to the global optimum for the case _K_ = 0, which equals , reveals that the local peaks on the rugged landscape have lower values than on Mount Fuji, but the global peak has a higher value. This begs the question of what happens in between these two extremes, as we increase the number of attribute interactions, _K_ , from zero to _N_ −1. The answer is that we see both effects. The increased number of interactions produces a higher global peak, but more, and therefore lower-value, local peaks. Assuming that the search uses the single-flip algorithm, then computational investigations of this model show that for small _K_ , the benefit of the interactions—a higher global peak—outweighs the increase in local peaks. So initially, the expected value of a local peak increases in _K_. The growing number of local peaks means that the average value will decrease. So if you were stuck using the single-flip algorithm, you would prefer a relatively small _K_ value, around, say, 3 or 4. But why should we be constrained to use this simple heuristic of switching a single attribute? Evolution by mutation may be constrained to this heuristic, but we are not. We could switch the state of two attributes or even three. A more sophisticated algorithm will reduce the number of local optima. 

---

### Ruggedness and Dancing Landscapes 

The NK model implies that we want a moderate degree of interdependence as that creates higher peaks. Many-model thinking demands that we step out from the particular assumptions of the model and consider the logic that drives that result. We find that the logic consists of two parts. The first rests on combinatorics: the number of pairs of combinations increases with the square of the number of pairs and the cube of the number of triples. Thus, interdependent effects create more possibilities of beneficial interactions. The second part rests on the fact that we need only keep the better combinations. Imagine grabbing any four food items to make a snack. Four items implies six possible combinations of two items. Suppose that we grab the following set of four: { _pickles, bananas, chicken, caramel_ }. Of the resulting six pairs—bananas and pickles, pickles and chicken, caramel and pickles, bananas and chicken, caramel and bananas, and caramel and chicken—only one sounds remotely appealing. We only need choose that option. We enjoy the caramel bananas. We ignore the rest.^4 A similar logic applies in evolutionary systems. Phenotypic combinations that produce positive interactions—a hard shell and short sturdy legs—remain in the population, while survival of the fittest works against combinations that produce negative interactions. We do not encounter many slow-footed, tasty animals with vibrant colors. If they ever existed, they have been caught and eaten. We encountered a similar intuition in our model of search. When we have an abundance of possibilities, we prefer variation. The same logic applies here: combining pairs (and triples) produces abundant possibilities. And we would have preferred that these many possibilities had high variation in value. We then have a greater likelihood that one of them has a very high value. Given that interdependent effects increase variation, on the whole they are advantageous, but only up to a point. As we have just seen, too many make the landscape random. Ideally, then, we have a 

---

moderate number of interactions. Some argue that if the number and size of interactions can evolve or adapt, then systems should naturally evolve to rugged landscapes with high peaks. This would suggest that systems tend toward complexity and not equilibrium or 

randomness.^5 When and whether that is true is exactly the sort of question that is fun to explore with models. One final point: We have taken the landscape as fixed. In ecological and social systems, the landscape that a species or firm confronts depends on the actions and attributes of others. An adaptation by a competing species, or a change in strategy by another firm, will shift and rearrange the fitness landscapes of competitors. We can now reinterpret our earlier models of spatial and hedonic competition as movements on dancing landscapes. Those movements could lead to an equilibrium, where each player stands on a local or global peak, or, competition on dancing landscapes may lead to complex patterns of actions and outcomes. Even a cursory glance at ecosystems, politics, and economics suggests that we see more of the latter. One reason that we see so much complexity may well be that much of our world consists of adaptive and purposive actors maneuvering on dancing landscapes. To make sense of that complexity, we need many models. 

---

---